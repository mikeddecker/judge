{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# from colorama import Fore, Style\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from managers.DataRepository import DataRepository\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "load_dotenv()\n",
    "STORAGE_DIR = os.getenv(\"STORAGE_DIR\")\n",
    "CROPPED_VIDEOS_FOLDER = \"cropped-videos\"\n",
    "# IMAGES_FOLDER = \"images\"\n",
    "# LABELS_FOLDER = \"labels\"\n",
    "SUPPORTED_VIDEO_FORMATS = os.getenv(\"SUPPORTED_VIDEO_FORMATS\")\n",
    "SUPPORTED_IMAGE_FORMATS = os.getenv(\"SUPPORTED_IMAGE_FORMATS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import ImageSequenceClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/miked/Elements/Judge/FINISHED-DB-READY\n",
      "cropped-videos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(STORAGE_DIR), print(CROPPED_VIDEOS_FOLDER)\n",
    "# computervision/labeled_frame_nrs_to_imgs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER), exist_ok=True)\n",
    "\n",
    "def get_video_path(repo, videoId):\n",
    "    return os.path.join(STORAGE_DIR, repo.VideoNames.loc[videoId, \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established, loading frame paths\n",
      "relative paths of framelabels loaded\n"
     ]
    }
   ],
   "source": [
    "repo = DataRepository()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/miked/code/judge/runs/detect/train7'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltrainround = 7\n",
    "modelpath = f\"/home/miked/code/judge/runs/detect/train{modeltrainround}\" if modeltrainround > 0 else f\"/home/miked/code/judge/runs/detect/train\"\n",
    "modelpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://docs.ultralytics.com/modes/predict/#key-features-of-predict-mode\n",
    "# Load a model\n",
    "model = YOLO(os.path.join(modelpath, \"weights\", \"best.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[676]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[676]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************676******************************\n",
      "MoviePy - Building video /media/miked/Elements/Judge/FINISHED-DB-READY/cropped-videos/224_676_v3.mp4.\n",
      "MoviePy - Writing video /media/miked/Elements/Judge/FINISHED-DB-READY/cropped-videos/224_676_v3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /media/miked/Elements/Judge/FINISHED-DB-READY/cropped-videos/224_676_v3.mp4\n"
     ]
    }
   ],
   "source": [
    "DIM = 224\n",
    "# videoIds = repo.get_dd3_videoIds()[\"id\"].to_list()\n",
    "videoIds = [676]\n",
    "PEOPLE = 3 # TODO : provide as a parameter or solve when skippers are entering the field\n",
    "\n",
    "for videoId in videoIds:\n",
    "    print(\"*\"*30 + str(videoId) + \"*\"*30)\n",
    "\n",
    "    videoPath = get_video_path(repo, videoId=videoId)\n",
    "    videoOutputPath = os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER, f\"{DIM}_{videoId}_opencv.mp4\")\n",
    "    videoOutputPathCorrect = os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER, f\"{DIM}_{videoId}_v3.mp4\")\n",
    "    videoOutputPathCorrect = os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER, f\"{DIM}_{videoId}.mp4\")\n",
    "    videoOutputPathCorrectOK = os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER, \"OK\", f\"{DIM}_{videoId}.mp4\")\n",
    "    videoOutputPathCorrectNOK = os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER, \"OK_NET_NIET_PERFECT\", f\"{DIM}_{videoId}.mp4\")\n",
    "    videoOutputPathCorrectAlmostOK = os.path.join(STORAGE_DIR, CROPPED_VIDEOS_FOLDER, \"SLECHT\", f\"{DIM}_{videoId}.mp4\")\n",
    "\n",
    "    \n",
    "    if os.path.exists(videoOutputPathCorrect) or os.path.exists(videoOutputPathCorrectOK) or os.path.exists(videoOutputPathCorrectAlmostOK) or os.path.exists(videoOutputPathCorrectNOK):\n",
    "        continue\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    wait_time = int(333 / fps - 7)\n",
    "    padding_x = width // 30\n",
    "    padding_y = height // 35\n",
    "    N = 4\n",
    "    avgIOUlastNseconds = 0.0\n",
    "    secondary_avgIOUlastNseconds = 0.0\n",
    "    N_FRAMES = N * fps\n",
    "    SQRT = 8\n",
    "\n",
    "    smootval = 0.87\n",
    "    smootval_shrink = 0.955\n",
    "    smooted_x1_min = None\n",
    "    smooted_y1_min = None\n",
    "    smooted_x2_max = None\n",
    "    smooted_y2_max = None\n",
    "    predictions = {\n",
    "        \"x1\": [],\n",
    "        \"y1\": [],\n",
    "        \"x2\": [],\n",
    "        \"y2\": [],\n",
    "        \"frameNr\" : [],\n",
    "    }\n",
    "    \n",
    "    max_w = 0\n",
    "    max_h = 0\n",
    "    min_w = width\n",
    "    min_h = height\n",
    "    max_wh = max(width, height)\n",
    "\n",
    "    times_with_no_jumper = 0\n",
    "    cropping_started = False\n",
    "    frames = []\n",
    "    i = 0\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')    # fourcc = 0x00000021\n",
    "    # out = cv2.VideoWriter(videoOutputPath, fourcc, fps, (DIM, DIM))\n",
    "    ret, frame = cap.read()\n",
    "    while ret:\n",
    "        # i += 1\n",
    "        result = model(frame, verbose=False)\n",
    "        xyxy_boxes = result[0].boxes.xyxy\n",
    "        predictions[\"frameNr\"].append(i)\n",
    "        \n",
    "        if xyxy_boxes.shape[0] > 0:\n",
    "            cropping_started = True\n",
    "            x1_min = max(0, int(xyxy_boxes[:, 0].min().item()) - padding_x)\n",
    "            y1_min = max(0, int(xyxy_boxes[:, 1].min().item()) - padding_y)\n",
    "            x2_max = min(width, int(xyxy_boxes[:, 2].max().item()) + padding_x)\n",
    "            y2_max = min(height, int(xyxy_boxes[:, 3].max().item()) + padding_y)\n",
    "            times_with_no_jumper = 0\n",
    "        elif times_with_no_jumper < 8 and 'x1_min' in locals():\n",
    "            times_with_no_jumper += 1\n",
    "        else:\n",
    "            x1_min = 0\n",
    "            y1_min = 0\n",
    "            x2_max = width\n",
    "            y2_max = height\n",
    "            times_with_no_jumper += 1\n",
    "\n",
    "        if len(xyxy_boxes) > PEOPLE + 1:\n",
    "            def pairwise_distances(x):\n",
    "                diffs = x.unsqueeze(1) - x.unsqueeze(0)  # shape: (N, N, 4)\n",
    "                dists = torch.norm(diffs, dim=2)         # shape: (N, N)\n",
    "                return dists\n",
    "\n",
    "            dists = pairwise_distances(xyxy_boxes)\n",
    "\n",
    "            ratio = (x2_max-x1_min) / (y2_max - y1_min)\n",
    "            avg_dists = dists.mean(dim=1)\n",
    "            std = avg_dists.std()\n",
    "            mean = avg_dists.mean()\n",
    "\n",
    "            boxesNearOtherBoxes = avg_dists < mean + std * 1.25\n",
    "            boxesNearOtherBoxesIndexes = boxesNearOtherBoxes.nonzero(as_tuple=True)\n",
    "            xyxy_boxes = xyxy_boxes[boxesNearOtherBoxesIndexes]\n",
    "\n",
    "\n",
    "        if smooted_x1_min is None or smooted_x1_min == 1:\n",
    "            smooted_x1_min = int(x1_min)\n",
    "            smooted_y1_min = int(y1_min)\n",
    "            smooted_x2_max = int(x2_max)\n",
    "            smooted_y2_max = int(y2_max)\n",
    "            secondary_smooted_x1_min = x1_min\n",
    "            secondary_smooted_y1_min = y1_min\n",
    "            secondary_smooted_x2_max = x2_max\n",
    "            secondary_smooted_y2_max = y2_max\n",
    "\n",
    "        else:\n",
    "            intersection_width = max(0, min(x2_max, smooted_x2_max) - max(x1_min, smooted_x1_min))\n",
    "            intersection_height = max(0, min(y2_max, smooted_y2_max) - max(y1_min, smooted_y1_min))\n",
    "            intersection_area = intersection_width * intersection_height\n",
    "            area_new_box = (x2_max - x1_min) * (y2_max - y1_min)\n",
    "            area_smooted_box = (smooted_x2_max - smooted_x1_min) * (smooted_y2_max - smooted_y1_min)\n",
    "            union = area_smooted_box + area_new_box - intersection_area\n",
    "            iou = intersection_area / union\n",
    "            avgIOUlastNseconds = ((N_FRAMES - 1) * avgIOUlastNseconds + iou) / N / fps \n",
    "            avgSqrd = avgIOUlastNseconds*avgIOUlastNseconds\n",
    "            iou_threshold = avgSqrd * avgSqrd\n",
    "\n",
    "            # secondary\n",
    "            secondary_intersection_width = max(0, min(x2_max, secondary_smooted_x2_max) - max(x1_min, secondary_smooted_x1_min))\n",
    "            secondary_intersection_height = max(0, min(y2_max, secondary_smooted_y2_max) - max(y1_min, secondary_smooted_y1_min))\n",
    "            secondary_intersection_area = secondary_intersection_width * secondary_intersection_height\n",
    "            area_new_box = (x2_max - x1_min) * (y2_max - y1_min)\n",
    "            area_secondary_smooted_box = (secondary_smooted_x2_max - secondary_smooted_x1_min) * (secondary_smooted_y2_max - secondary_smooted_y1_min)\n",
    "            secondary_union = area_secondary_smooted_box + area_new_box - secondary_intersection_area\n",
    "            secondary_iou = secondary_intersection_area / secondary_union\n",
    "            secondary_avgIOUlastNseconds = ((N_FRAMES / 2 - 1) * secondary_avgIOUlastNseconds + secondary_iou) / N_FRAMES * 2 \n",
    "            secondary_avgSqrd = secondary_avgIOUlastNseconds*secondary_avgIOUlastNseconds\n",
    "            secondary_iou_threshold = secondary_avgSqrd * secondary_avgSqrd\n",
    "\n",
    "            # print(f\"{iou > iou_threshold} : {iou:.3f} - 2nd = {secondary_iou:.3f} - T = {secondary_iou_threshold:.3f} --> follow? = {secondary_iou > secondary_iou_threshold} - {secondary_avgIOUlastNseconds} - N preds = {len(xyxy_boxes)}\")\n",
    "            # print(i, iou, iou_threshold)\n",
    "            if iou > iou_threshold:\n",
    "                movement_corrector = iou ** (1/SQRT) # In order to just follow current predictions (when big movements are made)\n",
    "                smooted_x1_min = int((smootval * smooted_x1_min + (1-smootval) * x1_min if x1_min < smooted_x1_min else smootval_shrink * smooted_x1_min + (1-smootval_shrink) * x1_min) * movement_corrector + (1- movement_corrector) * x1_min)\n",
    "                smooted_y1_min = int((smootval * smooted_y1_min + (1-smootval) * y1_min if y1_min < smooted_x1_min else smootval_shrink * smooted_y1_min + (1-smootval_shrink) * y1_min) * movement_corrector + (1- movement_corrector) * y1_min)\n",
    "                smooted_x2_max = int((smootval * smooted_x2_max + (1-smootval) * x2_max if x2_max > smooted_x2_max else smootval_shrink * smooted_x2_max + (1-smootval_shrink) * x2_max) * movement_corrector + (1- movement_corrector) * x2_max)\n",
    "                smooted_y2_max = int((smootval * smooted_y2_max + (1-smootval) * y2_max if y2_max > smooted_y2_max else smootval_shrink * smooted_y2_max + (1-smootval_shrink) * y2_max) * movement_corrector + (1- movement_corrector) * y2_max)\n",
    "            \n",
    "\n",
    "\n",
    "        # Cutting the image\n",
    "        w_jumpers = smooted_x2_max - smooted_x1_min\n",
    "        h_jumpers = smooted_y2_max - smooted_y1_min\n",
    "        max_w = max(max_w, w_jumpers)\n",
    "        max_h = max(max_h, h_jumpers)\n",
    "        min_w = min(min_w, w_jumpers)\n",
    "        min_h = min(max_h, h_jumpers)\n",
    "\n",
    "\n",
    "        max_wh_jumpers = max(w_jumpers, h_jumpers)\n",
    "        offset_x = (max_wh_jumpers - w_jumpers) // 2\n",
    "        offset_y = (max_wh_jumpers - h_jumpers) // 2\n",
    "\n",
    "        leftover_pixels_x = smooted_x1_min - offset_x\n",
    "        if leftover_pixels_x < 0:\n",
    "            crop_x1 = 0\n",
    "            offset_x_left = abs(leftover_pixels_x)\n",
    "        else:\n",
    "            crop_x1 = leftover_pixels_x\n",
    "            offset_x_left = 0\n",
    "        \n",
    "        leftover_pixels_x_right = width - (smooted_x2_max + offset_x)\n",
    "        crop_x2 = width if leftover_pixels_x_right < 0 else min(smooted_x2_max + offset_x, width)\n",
    "\n",
    "        leftover_pixels_y = smooted_y1_min - offset_y\n",
    "        if leftover_pixels_y < 0:\n",
    "            crop_y1 = 0\n",
    "            offset_y_left = abs(leftover_pixels_y)\n",
    "        else:\n",
    "            crop_y1 = leftover_pixels_y\n",
    "            offset_y_left = 0\n",
    "        \n",
    "        leftover_pixels_y_right = width - (smooted_y2_max + offset_y)\n",
    "        crop_y2 = width if leftover_pixels_y_right < 0 else min(smooted_y2_max + offset_y, height)\n",
    "\n",
    "        predictions[\"x1\"].append(crop_x1)\n",
    "        predictions[\"y1\"].append(crop_y1)\n",
    "        predictions[\"x2\"].append(crop_x2)\n",
    "        predictions[\"y2\"].append(crop_y2)\n",
    "\n",
    "        cropped_frame = frame[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "        zeros = np.zeros((max_wh_jumpers, max_wh_jumpers, 3), dtype=np.uint8)\n",
    "        zeros[offset_y_left:offset_y_left+(crop_y2-crop_y1), offset_x_left:offset_x_left+(crop_x2 - crop_x1)] = cropped_frame\n",
    "        zeros = cv2.resize(zeros, (DIM, DIM))\n",
    "        zeros = cv2.cvtColor(zeros, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        frames.append(zeros)\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        i += 1\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    df_predictions = pd.DataFrame(predictions)\n",
    "    df_predictions[\"videoId\"] = videoId\n",
    "    df_predictions[\"locationChecked\"] = False\n",
    "    df_predictions[\"segmentsChecked\"] = False\n",
    "    df_predictions.to_sql(name=\"Predictions_Localization\", if_exists='append', con=repo.con, chunksize=500, index=False)\n",
    "    repo.con.commit()\n",
    "    \n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "    clip.write_videofile(videoOutputPathCorrect)\n",
    "\n",
    "    # To browser runnable codec\n",
    "    # os.system(f\"ffmpeg -i {videoOutputPath} -vcodec libx264 {videoOutputPathCorrect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>frameNr</th>\n",
       "      <th>videoId</th>\n",
       "      <th>locationChecked</th>\n",
       "      <th>segmentsChecked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>868</td>\n",
       "      <td>345</td>\n",
       "      <td>1460</td>\n",
       "      <td>937</td>\n",
       "      <td>0</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>868</td>\n",
       "      <td>345</td>\n",
       "      <td>1460</td>\n",
       "      <td>936</td>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>868</td>\n",
       "      <td>345</td>\n",
       "      <td>1460</td>\n",
       "      <td>936</td>\n",
       "      <td>2</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868</td>\n",
       "      <td>345</td>\n",
       "      <td>1460</td>\n",
       "      <td>936</td>\n",
       "      <td>3</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>868</td>\n",
       "      <td>345</td>\n",
       "      <td>1460</td>\n",
       "      <td>936</td>\n",
       "      <td>4</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>732</td>\n",
       "      <td>341</td>\n",
       "      <td>1203</td>\n",
       "      <td>811</td>\n",
       "      <td>2381</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>728</td>\n",
       "      <td>341</td>\n",
       "      <td>1202</td>\n",
       "      <td>814</td>\n",
       "      <td>2382</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>725</td>\n",
       "      <td>341</td>\n",
       "      <td>1200</td>\n",
       "      <td>816</td>\n",
       "      <td>2383</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>722</td>\n",
       "      <td>341</td>\n",
       "      <td>1198</td>\n",
       "      <td>817</td>\n",
       "      <td>2384</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>719</td>\n",
       "      <td>341</td>\n",
       "      <td>1196</td>\n",
       "      <td>818</td>\n",
       "      <td>2385</td>\n",
       "      <td>676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1   y1    x2   y2  frameNr  videoId  locationChecked  segmentsChecked\n",
       "0     868  345  1460  937        0      676            False            False\n",
       "1     868  345  1460  936        1      676            False            False\n",
       "2     868  345  1460  936        2      676            False            False\n",
       "3     868  345  1460  936        3      676            False            False\n",
       "4     868  345  1460  936        4      676            False            False\n",
       "...   ...  ...   ...  ...      ...      ...              ...              ...\n",
       "2381  732  341  1203  811     2381      676            False            False\n",
       "2382  728  341  1202  814     2382      676            False            False\n",
       "2383  725  341  1200  816     2383      676            False            False\n",
       "2384  722  341  1198  817     2384      676            False            False\n",
       "2385  719  341  1196  818     2385      676            False            False\n",
       "\n",
       "[2386 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
