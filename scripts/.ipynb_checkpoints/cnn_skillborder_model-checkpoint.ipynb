{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46cd2f2-ccd7-4a7e-8725-cab1b9b4c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras CNN predict air, between, ground or not jumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866d8eb0-81e5-493a-aac8-c56f0b4aeea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/miked/.local/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: packaging in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: setuptools in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/miked/.local/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: optree in /home/miked/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in /home/miked/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/miked/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/miked/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/miked/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/miked/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/miked/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/miked/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/miked/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/miked/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/miked/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec73ef6e-5e7e-4e46-be92-312f781394ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:25:02.175435: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-10 23:25:02.215609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 23:25:03.018995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from my_classes import DataGeneratorSkillBorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a6d6673-97aa-4ce5-96e8-99ac3c381e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_border_labels_path = 'data/df_video_border_labels.pkl'\n",
    "\n",
    "train_videos = [\n",
    "    'videos/20240201_atelier_001.mp4',\n",
    "    'videos/20240201_atelier_002.mp4',\n",
    "    'videos/20240201_atelier_003.mp4',\n",
    "    'videos/20240201_atelier_004.mp4',\n",
    "    'videos/20240201_atelier_005.mp4',\n",
    "    'videos/20240209_atelier_006.mp4',\n",
    "    'videos/20240209_atelier_007.mp4',\n",
    "    'videos/20240209_atelier_008.mp4',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6daf1-ef2e-43c1-95d8-2a960b07955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load_or_create(path, cols):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0f1b86-5e84-450c-9a2d-6c1d757739fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>frame</th>\n",
       "      <th>border</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>videos/20240209_atelier_006.mp4</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>videos/20240209_atelier_007.mp4</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>videos/20240201_atelier_002.mp4</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>videos/20240201_atelier_004.mp4</td>\n",
       "      <td>806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>videos/20240201_atelier_003.mp4</td>\n",
       "      <td>622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>videos/20240201_atelier_003.mp4</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>videos/20240201_atelier_002.mp4</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>videos/20240201_atelier_003.mp4</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>videos/20240201_atelier_005.mp4</td>\n",
       "      <td>2390</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>videos/20240209_atelier_006.mp4</td>\n",
       "      <td>382</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path  frame  border\n",
       "0    videos/20240209_atelier_006.mp4    745       0\n",
       "1    videos/20240209_atelier_007.mp4    103       0\n",
       "2    videos/20240201_atelier_002.mp4     91       0\n",
       "3    videos/20240201_atelier_004.mp4    806       2\n",
       "4    videos/20240201_atelier_003.mp4    622       2\n",
       "..                               ...    ...     ...\n",
       "653  videos/20240201_atelier_003.mp4    247       2\n",
       "654  videos/20240201_atelier_002.mp4    370       2\n",
       "655  videos/20240201_atelier_003.mp4    242       1\n",
       "656  videos/20240201_atelier_005.mp4   2390       9\n",
       "657  videos/20240209_atelier_006.mp4    382       2\n",
       "\n",
       "[658 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pickle_load_or_create(video_border_labels_path, [])\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8a2b2e-107a-4a68-b41c-6487480f38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.loc[df_labels.border == 5, 'border'] = 3\n",
    "df_labels.loc[df_labels.border == 9, 'border'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518bced6-0e6d-4e21-85ac-7cb83f28532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_frame(videos, grey=True, scale=1):\n",
    "    \"\"\"\n",
    "    videos: array of video_paths\n",
    "    df_video_border_labels: panda dataframe ['path', 'frame', 'borderlabel']\n",
    "        [ 0 : ground\n",
    "          1 : heels of ground\n",
    "          2 : air ]\n",
    "    \"\"\"\n",
    "    path = videos[np.random.randint(0, len(videos)-1)]\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_nr = np.random.randint(0, video_length-1)\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_nr)\n",
    "    res, frame = cap.read()\n",
    "    frame = cv2.resize(frame, dsize=(0,0), fx=scale, fy=scale)\n",
    "    # frame = cv2.cvtColor(frame, 7)\n",
    "    cap.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    return path, frame_nr, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5f5ad6-b1e3-47f7-96c1-805a5fc28362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 432, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = get_random_frame(train_videos, grey=True, scale=0.4)[2].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f00a61df-44c3-4d38-8e1b-7e6c83efe953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miked/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ced48a4-4077-4fc0-bf25-ebc558c8fc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,320</span> (220.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,320\u001b[0m (220.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,320</span> (220.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,320\u001b[0m (220.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ace776-ef47-4177-ba8a-74ebbd7ae68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 4, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = df_labels['border'].unique()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc15c154-93dc-467d-a960-088535f7310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04cb8221-dd3e-4c2f-9136-b1f657c0ffb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │       \u001b[38;5;34m147,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m85\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,877</span> (796.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,877\u001b[0m (796.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,877</span> (796.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m203,877\u001b[0m (796.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082d01b7-eeb3-4858-9418-8ac0ece0c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                path  frame  border\n",
      "74   videos/20240201_atelier_001.mp4    446       0\n",
      "464  videos/20240201_atelier_002.mp4    916       0\n",
      "29   videos/20240209_atelier_007.mp4    293       2\n",
      "304  videos/20240209_atelier_007.mp4    778       0\n",
      "320  videos/20240201_atelier_005.mp4    479       1\n",
      "..                               ...    ...     ...\n",
      "375  videos/20240209_atelier_007.mp4    666       0\n",
      "71   videos/20240209_atelier_006.mp4    854       4\n",
      "582  videos/20240209_atelier_007.mp4    491       2\n",
      "615  videos/20240201_atelier_003.mp4    312       0\n",
      "456  videos/20240201_atelier_004.mp4    627       1\n",
      "\n",
      "[526 rows x 3 columns]\n",
      "                                path  frame  border\n",
      "270  videos/20240201_atelier_003.mp4    277       2\n",
      "255  videos/20240209_atelier_007.mp4    763       0\n",
      "511  videos/20240201_atelier_004.mp4   2039       4\n",
      "304  videos/20240209_atelier_007.mp4    778       0\n",
      "172  videos/20240201_atelier_004.mp4   1398       0\n",
      "..                               ...    ...     ...\n",
      "188  videos/20240209_atelier_007.mp4    513       0\n",
      "76   videos/20240201_atelier_002.mp4    987       2\n",
      "101  videos/20240209_atelier_006.mp4    597       0\n",
      "1    videos/20240209_atelier_007.mp4    103       0\n",
      "429  videos/20240209_atelier_007.mp4    789       0\n",
      "\n",
      "[132 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from my_classes import DataGeneratorSkillBorders\n",
    "# Parameters\n",
    "params = {'dim': (64,64),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': len(unique_labels),\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'train': True}\n",
    "\n",
    "training_generator = DataGeneratorSkillBorders(df_labels, **params)\n",
    "test_generator = DataGeneratorSkillBorders(df_labels, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a794b1-90ff-4c09-828c-58d3c8492e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 261 ms, total: 13.8 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = training_generator.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76ab4052-80db-4918-8c15-b10bb3199a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 91.,  98., 104.],\n",
       "         [ 91.,  97., 106.],\n",
       "         [ 91.,  98., 109.],\n",
       "         ...,\n",
       "         [ 79.,  86.,  92.],\n",
       "         [ 85.,  90.,  96.],\n",
       "         [ 88.,  95., 101.]],\n",
       "\n",
       "        [[ 91.,  99., 108.],\n",
       "         [ 96., 102., 111.],\n",
       "         [ 92., 100., 107.],\n",
       "         ...,\n",
       "         [ 81.,  87.,  91.],\n",
       "         [ 85.,  91.,  95.],\n",
       "         [ 90.,  97.,  98.]],\n",
       "\n",
       "        [[ 89.,  95., 101.],\n",
       "         [ 92., 100., 109.],\n",
       "         [ 96., 104., 113.],\n",
       "         ...,\n",
       "         [ 77.,  84.,  90.],\n",
       "         [ 79.,  85.,  89.],\n",
       "         [ 88.,  92.,  96.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[154., 152., 151.],\n",
       "         [155., 155., 153.],\n",
       "         [159., 156., 155.],\n",
       "         ...,\n",
       "         [ 19.,  33.,  47.],\n",
       "         [ 21.,  34.,  50.],\n",
       "         [ 22.,  34.,  53.]],\n",
       "\n",
       "        [[150., 150., 148.],\n",
       "         [148., 148., 148.],\n",
       "         [150., 150., 150.],\n",
       "         ...,\n",
       "         [ 19.,  33.,  52.],\n",
       "         [ 17.,  32.,  48.],\n",
       "         [ 16.,  28.,  47.]],\n",
       "\n",
       "        [[138., 138., 138.],\n",
       "         [147., 144., 143.],\n",
       "         [146., 146., 146.],\n",
       "         ...,\n",
       "         [ 19.,  28.,  48.],\n",
       "         [ 14.,  29.,  45.],\n",
       "         [ 19.,  30.,  51.]]],\n",
       "\n",
       "\n",
       "       [[[ 69.,  74.,  74.],\n",
       "         [ 70.,  75.,  75.],\n",
       "         [ 70.,  75.,  75.],\n",
       "         ...,\n",
       "         [ 68.,  71.,  71.],\n",
       "         [ 71.,  74.,  74.],\n",
       "         [ 74.,  75.,  75.]],\n",
       "\n",
       "        [[ 77.,  80.,  80.],\n",
       "         [ 74.,  77.,  77.],\n",
       "         [ 68.,  73.,  73.],\n",
       "         ...,\n",
       "         [ 65.,  65.,  65.],\n",
       "         [ 70.,  73.,  73.],\n",
       "         [ 73.,  76.,  76.]],\n",
       "\n",
       "        [[ 70.,  75.,  75.],\n",
       "         [ 72.,  77.,  77.],\n",
       "         [ 82.,  87.,  87.],\n",
       "         ...,\n",
       "         [ 68.,  71.,  71.],\n",
       "         [ 73.,  76.,  76.],\n",
       "         [ 73.,  76.,  76.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[205., 199., 189.],\n",
       "         [189., 185., 175.],\n",
       "         [176., 172., 160.],\n",
       "         ...,\n",
       "         [ 10.,  16.,  27.],\n",
       "         [  7.,  19.,  31.],\n",
       "         [  8.,  19.,  34.]],\n",
       "\n",
       "        [[192., 184., 172.],\n",
       "         [184., 176., 164.],\n",
       "         [173., 165., 153.],\n",
       "         ...,\n",
       "         [  4.,  16.,  28.],\n",
       "         [  7.,  16.,  31.],\n",
       "         [ 11.,  20.,  35.]],\n",
       "\n",
       "        [[175., 170., 155.],\n",
       "         [168., 162., 150.],\n",
       "         [157., 150., 135.],\n",
       "         ...,\n",
       "         [  5.,  16.,  31.],\n",
       "         [  3.,  17.,  31.],\n",
       "         [  9.,  20.,  35.]]],\n",
       "\n",
       "\n",
       "       [[[ 70.,  75.,  75.],\n",
       "         [ 69.,  74.,  74.],\n",
       "         [ 71.,  74.,  74.],\n",
       "         ...,\n",
       "         [ 68.,  71.,  71.],\n",
       "         [ 70.,  73.,  73.],\n",
       "         [ 70.,  73.,  73.]],\n",
       "\n",
       "        [[ 75.,  78.,  78.],\n",
       "         [ 70.,  73.,  73.],\n",
       "         [ 70.,  73.,  73.],\n",
       "         ...,\n",
       "         [ 64.,  67.,  67.],\n",
       "         [ 68.,  71.,  71.],\n",
       "         [ 71.,  74.,  74.]],\n",
       "\n",
       "        [[ 69.,  72.,  72.],\n",
       "         [ 73.,  76.,  76.],\n",
       "         [ 83.,  86.,  86.],\n",
       "         ...,\n",
       "         [ 67.,  70.,  70.],\n",
       "         [ 74.,  74.,  74.],\n",
       "         [ 73.,  76.,  76.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[205., 199., 187.],\n",
       "         [191., 185., 175.],\n",
       "         [175., 171., 161.],\n",
       "         ...,\n",
       "         [ 10.,  17.,  31.],\n",
       "         [  8.,  19.,  34.],\n",
       "         [ 10.,  19.,  34.]],\n",
       "\n",
       "        [[190., 184., 172.],\n",
       "         [181., 175., 163.],\n",
       "         [169., 163., 153.],\n",
       "         ...,\n",
       "         [  3.,  15.,  27.],\n",
       "         [  7.,  16.,  31.],\n",
       "         [ 10.,  21.,  36.]],\n",
       "\n",
       "        [[174., 166., 154.],\n",
       "         [171., 161., 147.],\n",
       "         [155., 147., 133.],\n",
       "         ...,\n",
       "         [  6.,  15.,  30.],\n",
       "         [  7.,  17.,  29.],\n",
       "         [  9.,  20.,  34.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 68.,  71.,  71.],\n",
       "         [ 62.,  67.,  67.],\n",
       "         [ 64.,  69.,  69.],\n",
       "         ...,\n",
       "         [ 64.,  67.,  67.],\n",
       "         [ 68.,  71.,  71.],\n",
       "         [ 66.,  71.,  71.]],\n",
       "\n",
       "        [[ 70.,  73.,  73.],\n",
       "         [ 66.,  69.,  69.],\n",
       "         [ 61.,  66.,  66.],\n",
       "         ...,\n",
       "         [ 61.,  64.,  64.],\n",
       "         [ 65.,  68.,  68.],\n",
       "         [ 69.,  72.,  72.]],\n",
       "\n",
       "        [[ 62.,  65.,  65.],\n",
       "         [ 67.,  71.,  73.],\n",
       "         [ 77.,  80.,  80.],\n",
       "         ...,\n",
       "         [ 64.,  67.,  67.],\n",
       "         [ 69.,  72.,  72.],\n",
       "         [ 71.,  74.,  74.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[202., 196., 186.],\n",
       "         [189., 183., 173.],\n",
       "         [172., 168., 156.],\n",
       "         ...,\n",
       "         [ 10.,  15.,  27.],\n",
       "         [  5.,  17.,  29.],\n",
       "         [  5.,  16.,  31.]],\n",
       "\n",
       "        [[189., 181., 169.],\n",
       "         [180., 172., 160.],\n",
       "         [167., 159., 147.],\n",
       "         ...,\n",
       "         [  6.,  13.,  26.],\n",
       "         [  6.,  16.,  28.],\n",
       "         [  5.,  18.,  34.]],\n",
       "\n",
       "        [[171., 164., 149.],\n",
       "         [165., 157., 145.],\n",
       "         [151., 144., 129.],\n",
       "         ...,\n",
       "         [  6.,  12.,  28.],\n",
       "         [  6.,  16.,  28.],\n",
       "         [  7.,  18.,  33.]]],\n",
       "\n",
       "\n",
       "       [[[ 87.,  90.,  90.],\n",
       "         [ 88.,  91.,  91.],\n",
       "         [ 87.,  90.,  90.],\n",
       "         ...,\n",
       "         [ 79.,  82.,  82.],\n",
       "         [ 79.,  82.,  82.],\n",
       "         [ 77.,  80.,  80.]],\n",
       "\n",
       "        [[ 87.,  90.,  90.],\n",
       "         [ 89.,  94.,  94.],\n",
       "         [ 87.,  90.,  90.],\n",
       "         ...,\n",
       "         [ 83.,  86.,  86.],\n",
       "         [ 83.,  86.,  86.],\n",
       "         [ 83.,  83.,  83.]],\n",
       "\n",
       "        [[ 84.,  87.,  87.],\n",
       "         [ 84.,  89.,  89.],\n",
       "         [ 84.,  89.,  89.],\n",
       "         ...,\n",
       "         [ 84.,  87.,  87.],\n",
       "         [ 82.,  85.,  85.],\n",
       "         [ 82.,  85.,  85.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[191., 185., 175.],\n",
       "         [176., 169., 161.],\n",
       "         [169., 164., 156.],\n",
       "         ...,\n",
       "         [ 14.,  24.,  41.],\n",
       "         [ 15.,  25.,  42.],\n",
       "         [ 16.,  26.,  43.]],\n",
       "\n",
       "        [[185., 177., 165.],\n",
       "         [175., 167., 155.],\n",
       "         [164., 158., 146.],\n",
       "         ...,\n",
       "         [ 12.,  22.,  39.],\n",
       "         [ 14.,  24.,  41.],\n",
       "         [ 14.,  24.,  41.]],\n",
       "\n",
       "        [[179., 169., 155.],\n",
       "         [167., 159., 147.],\n",
       "         [158., 147., 136.],\n",
       "         ...,\n",
       "         [ 15.,  25.,  42.],\n",
       "         [ 14.,  24.,  41.],\n",
       "         [ 12.,  21.,  41.]]],\n",
       "\n",
       "\n",
       "       [[[ 71.,  75.,  75.],\n",
       "         [ 71.,  74.,  74.],\n",
       "         [ 70.,  75.,  75.],\n",
       "         ...,\n",
       "         [ 69.,  72.,  72.],\n",
       "         [ 71.,  74.,  74.],\n",
       "         [ 72.,  75.,  75.]],\n",
       "\n",
       "        [[ 75.,  78.,  78.],\n",
       "         [ 70.,  73.,  73.],\n",
       "         [ 68.,  71.,  71.],\n",
       "         ...,\n",
       "         [ 64.,  67.,  67.],\n",
       "         [ 70.,  73.,  73.],\n",
       "         [ 73.,  76.,  76.]],\n",
       "\n",
       "        [[ 71.,  72.,  72.],\n",
       "         [ 72.,  77.,  77.],\n",
       "         [ 78.,  83.,  83.],\n",
       "         ...,\n",
       "         [ 69.,  72.,  72.],\n",
       "         [ 73.,  76.,  76.],\n",
       "         [ 73.,  78.,  78.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[206., 200., 190.],\n",
       "         [192., 186., 176.],\n",
       "         [177., 173., 163.],\n",
       "         ...,\n",
       "         [  9.,  16.,  32.],\n",
       "         [  8.,  19.,  34.],\n",
       "         [  7.,  18.,  33.]],\n",
       "\n",
       "        [[195., 187., 175.],\n",
       "         [182., 176., 164.],\n",
       "         [172., 164., 152.],\n",
       "         ...,\n",
       "         [  5.,  16.,  31.],\n",
       "         [  7.,  18.,  33.],\n",
       "         [ 10.,  22.,  34.]],\n",
       "\n",
       "        [[176., 169., 154.],\n",
       "         [169., 164., 149.],\n",
       "         [158., 150., 138.],\n",
       "         ...,\n",
       "         [  5.,  17.,  30.],\n",
       "         [  5.,  16.,  31.],\n",
       "         [ 10.,  22.,  34.]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f683c31-77e9-471f-b857-4bb15857b735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 4, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2c862-5576-4999-a5a3-f20623910ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8e48c69-83b9-460f-9cba-b809b33d3d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:25:26.424855: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-06-10 23:25:39.804960: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 6 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:41\u001b[0m 34s/step - accuracy: 0.3125 - loss: 16.5645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:25:48.593686: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8s/step - accuracy: 0.3883 - loss: 6.8093 - val_accuracy: 0.4746 - val_loss: 1.3129\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:30:04.387273: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:13\u001b[0m 33s/step - accuracy: 0.3750 - loss: 1.4153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:30:25.353116: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 8s/step - accuracy: 0.5100 - loss: 1.3341 - val_accuracy: 0.4668 - val_loss: 1.3380\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:34:35.262414: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:26\u001b[0m 34s/step - accuracy: 0.5000 - loss: 1.2633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:34:56.529004: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 8s/step - accuracy: 0.5438 - loss: 1.2951 - val_accuracy: 0.5840 - val_loss: 1.2049\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:39:11.578760: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:27\u001b[0m 34s/step - accuracy: 0.5625 - loss: 1.2279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:39:32.264132: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 8s/step - accuracy: 0.5966 - loss: 1.1529 - val_accuracy: 0.6406 - val_loss: 1.0596\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:43:43.013870: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-06-10 23:44:00.133686: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 7 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:41\u001b[0m 34s/step - accuracy: 0.6875 - loss: 0.9797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:44:04.354547: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 8s/step - accuracy: 0.6297 - loss: 1.0517 - val_accuracy: 0.6523 - val_loss: 1.0551\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:48:20.103146: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:26\u001b[0m 34s/step - accuracy: 0.6250 - loss: 1.0990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:48:41.192769: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 8s/step - accuracy: 0.6401 - loss: 1.0323 - val_accuracy: 0.6211 - val_loss: 0.9996\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:52:50.113781: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:13\u001b[0m 33s/step - accuracy: 0.6875 - loss: 0.9484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:53:10.787057: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 8s/step - accuracy: 0.6708 - loss: 0.9735 - val_accuracy: 0.6484 - val_loss: 0.9595\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:57:23.363326: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-06-10 23:57:40.182373: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 7 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:45\u001b[0m 34s/step - accuracy: 0.6250 - loss: 1.0912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:57:44.462787: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 8s/step - accuracy: 0.6588 - loss: 0.9654 - val_accuracy: 0.6484 - val_loss: 0.9524\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 00:02:42.391168: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-06-11 00:02:53.330259: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 6 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:27\u001b[0m 74s/step - accuracy: 0.6875 - loss: 1.0535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 00:03:01.179089: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 8s/step - accuracy: 0.6093 - loss: 1.0127 - val_accuracy: 0.6660 - val_loss: 0.9331\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 00:07:15.921691: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-06-11 00:07:33.399465: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 7 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:10\u001b[0m 35s/step - accuracy: 0.6875 - loss: 1.0681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 00:07:37.976500: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 8s/step - accuracy: 0.6578 - loss: 0.9659 - val_accuracy: 0.6543 - val_loss: 0.8989\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_generator, epochs=10, \n",
    "                    validation_data=training_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b03e31c-ac8b-40fd-8699-b89181898d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (dataset iterations).\n",
       "\n",
       "Args:\n",
       "    x: Input data. It could be:\n",
       "        - A NumPy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "        - A tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "        - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "        - A `tf.data.Dataset`. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "        - A `keras.utils.PyDataset` returning `(inputs,\n",
       "        targets)` or `(inputs, targets, sample_weights)`.\n",
       "    y: Target data. Like the input data `x`,\n",
       "        it could be either NumPy array(s) or backend-native tensor(s).\n",
       "        If `x` is a dataset, generator,\n",
       "        or `keras.utils.PyDataset` instance, `y` should\n",
       "        not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.PyDataset`\n",
       "        instances (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided\n",
       "        (unless the `steps_per_epoch` flag is set to\n",
       "        something other than None).\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        \"auto\" becomes 1 for most cases.\n",
       "        Note that the progress bar is not\n",
       "        particularly useful when logged to a file,\n",
       "        so `verbose=2` is recommended when not running interactively\n",
       "        (e.g., in a production environment). Defaults to `\"auto\"`.\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `keras.callbacks`. Note\n",
       "        `keras.callbacks.ProgbarLogger` and\n",
       "        `keras.callbacks.History` callbacks are created\n",
       "        automatically and need not be passed to `model.fit()`.\n",
       "        `keras.callbacks.ProgbarLogger` is created\n",
       "        or not based on the `verbose` argument in `model.fit()`.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This\n",
       "        argument is not supported when `x` is a dataset, generator or\n",
       "        `keras.utils.PyDataset` instance.\n",
       "        If both `validation_data` and `validation_split` are provided,\n",
       "        `validation_data` will override `validation_split`.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data. Thus, note the fact\n",
       "        that the validation loss of data provided using\n",
       "        `validation_split` or `validation_data` is not affected by\n",
       "        regularization layers like noise and dropout.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        It could be:\n",
       "        - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
       "        - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
       "        arrays.\n",
       "        - A `tf.data.Dataset`.\n",
       "        - A Python generator or `keras.utils.PyDataset` returning\n",
       "        `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
       "    shuffle: Boolean, whether to shuffle the training data\n",
       "        before each epoch. This argument is\n",
       "        ignored when `x` is a generator or a `tf.data.Dataset`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class. When `class_weight` is specified\n",
       "        and targets have a rank of 2 or greater, either `y` must be\n",
       "        one-hot encoded, or an explicit final dimension of `1` must\n",
       "        be included for sparse class labels.\n",
       "    sample_weight: Optional NumPy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        NumPy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample.\n",
       "        This argument is not supported when `x` is a dataset, generator,\n",
       "        or `keras.utils.PyDataset` instance, instead provide the\n",
       "        sample_weights as the third element of `x`.\n",
       "        Note that sample weighting does not apply to metrics specified\n",
       "        via the `metrics` argument in `compile()`. To apply sample\n",
       "        weighting to your metrics, you can specify them via the\n",
       "        `weighted_metrics` in `compile()` instead.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        backend-native tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If `x` is a\n",
       "        `tf.data.Dataset`, and `steps_per_epoch`\n",
       "        is `None`, the epoch will run until the input dataset is\n",
       "        exhausted.  When passing an infinitely repeating dataset, you\n",
       "        must specify the `steps_per_epoch` argument. If\n",
       "        `steps_per_epoch=-1` the training will run indefinitely with an\n",
       "        infinitely repeating dataset.\n",
       "    validation_steps: Only relevant if `validation_data` is provided.\n",
       "        Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If `validation_steps` is `None`,\n",
       "        validation will run until the `validation_data` dataset is\n",
       "        exhausted. In the case of an infinitely repeated dataset, it\n",
       "        will run into an infinite loop. If `validation_steps` is\n",
       "        specified and only part of the dataset will be consumed, the\n",
       "        evaluation will start from the beginning of the dataset at each\n",
       "        epoch. This ensures that the same validation samples are used\n",
       "        every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in\n",
       "        the form of datasets or `keras.utils.PyDataset`\n",
       "        instances (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided.\n",
       "        Specifies how many training epochs to run\n",
       "        before a new validation run is performed,\n",
       "        e.g. `validation_freq=2` runs validation every 2 epochs.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass an iterator like object such as a\n",
       "    `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
       "    which will in fact yield not only features (`x`)\n",
       "    but optionally targets (`y`) and sample weights (`sample_weight`).\n",
       "    Keras requires that the output of such iterator-likes be\n",
       "    unambiguous. The iterator should return a tuple\n",
       "    of length 1, 2, or 3, where the optional second and third elements\n",
       "    will be used for `y` and `sample_weight` respectively.\n",
       "    Any other type provided will be wrapped in\n",
       "    a length-one tuple, effectively treating everything as `x`. When\n",
       "    yielding dicts, they should still adhere to the top-level tuple\n",
       "    structure,\n",
       "    e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "    features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the `namedtuple`. The reason is\n",
       "    that it behaves like both an ordered datatype (tuple) and a mapping\n",
       "    datatype (dict). So given a namedtuple of the form:\n",
       "    `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "    it is ambiguous whether to reverse the order of the elements when\n",
       "    interpreting the value. Even worse is a tuple of the form:\n",
       "    `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "    where it is unclear if the tuple was intended to be unpacked\n",
       "    into `x`, `y`, and `sample_weight` or passed through\n",
       "    as a single element to `x`.\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6bf2c-67fc-4771-adac-b7417ef9a408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ddc2ea-006d-4501-a865-8cb56fc42deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb492dab-1b49-42e4-a133-83e2842292b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>frame</th>\n",
       "      <th>border</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>videos/20240209_atelier_006.mp4</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>videos/20240209_atelier_007.mp4</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>videos/20240201_atelier_002.mp4</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>videos/20240201_atelier_004.mp4</td>\n",
       "      <td>806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>videos/20240201_atelier_003.mp4</td>\n",
       "      <td>622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>videos/20240201_atelier_003.mp4</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>videos/20240201_atelier_002.mp4</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>videos/20240201_atelier_003.mp4</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>videos/20240201_atelier_005.mp4</td>\n",
       "      <td>2390</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>videos/20240209_atelier_006.mp4</td>\n",
       "      <td>382</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path  frame  border\n",
       "0    videos/20240209_atelier_006.mp4    745       0\n",
       "1    videos/20240209_atelier_007.mp4    103       0\n",
       "2    videos/20240201_atelier_002.mp4     91       0\n",
       "3    videos/20240201_atelier_004.mp4    806       2\n",
       "4    videos/20240201_atelier_003.mp4    622       2\n",
       "..                               ...    ...     ...\n",
       "653  videos/20240201_atelier_003.mp4    247       2\n",
       "654  videos/20240201_atelier_002.mp4    370       2\n",
       "655  videos/20240201_atelier_003.mp4    242       1\n",
       "656  videos/20240201_atelier_005.mp4   2390       9\n",
       "657  videos/20240209_atelier_006.mp4    382       2\n",
       "\n",
       "[658 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pickle_load_or_create(video_border_labels_path, [])\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9b31e26-f5fb-4ad4-aabd-fdbf27d415ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 9, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pickle_load_or_create(video_border_labels_path, [])\n",
    "unique_labels = df_labels['border'].unique()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d0575-d2d2-4b49-974f-68fc3b878a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c77033-2026-4cdf-8ffd-d92bf3561a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d55fd-04dc-42fa-a069-bbcff3985d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67488ac-d8db-4f76-aaa9-974b9d48c82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36284c8-a8da-43a6-90e6-4be72f35c39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57d4ba-89d7-4c38-9c51-151a2dcdb525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdc98d-433f-4877-9f58-96966648ba1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1287828-b8f0-4db0-93b0-20dc90f54c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
