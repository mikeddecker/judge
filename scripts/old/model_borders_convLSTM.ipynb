{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46cd2f2-ccd7-4a7e-8725-cab1b9b4c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras CNN predict air, between, ground or not jumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866d8eb0-81e5-493a-aac8-c56f0b4aeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec73ef6e-5e7e-4e46-be92-312f781394ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 16:47:04.867917: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-25 16:47:05.336054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 16:47:06.362641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from utils_misc import pickle_load_or_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d583182b-037f-43d8-9352-7b2981366acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.callbacks.history.History object at 0x76327b832200>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.3533805012702942, 0.3549528419971466],\n",
       " 'loss': [10.40020751953125, 10.396940231323242],\n",
       " 'val_accuracy': [0.47440946102142334, 0.47440946102142334],\n",
       " 'val_loss': [8.471517562866211, 8.471517562866211]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle_load_or_create('../models/frames_skillborder_convLSTM_model_history', lambda: None, True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62270fb6-0959-4b25-b796-16742c062b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/miked/.local/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pandas in /home/miked/.local/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/miked/.local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/miked/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/miked/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sqlalchemy in /home/miked/.local/lib/python3.10/site-packages (2.0.29)\n",
      "Requirement already satisfied: PyMySQL in /home/miked/.local/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/miked/.local/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/miked/.local/lib/python3.10/site-packages (from sqlalchemy) (4.9.0)\n"
     ]
    }
   ],
   "source": [
    "from DataGeneratorBordersDB import DataGeneratorSkillBorders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b6daf1-ef2e-43c1-95d8-2a960b07955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'convolution': (3, 3),\n",
       " 'time_length': 8,\n",
       " 'dim': 128,\n",
       " 'rgb': True,\n",
       " 'unique_labels': 4}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = pickle_load_or_create('convLSTM_192_3x3_rgb', lambda:{\n",
    "    'convolution': (3,3),\n",
    "    'time_length':8,\n",
    "    'dim':128,\n",
    "    'rgb':True,\n",
    "    'unique_labels': 4,\n",
    "}, config=True)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca79375-37fd-4973-ae24-e4ac073a35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, TimeDistributed, Dense, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "if model is None:\n",
    "    model = Sequential()    \n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=config['convolution'],\n",
    "                         input_shape=(config['time_length'], config['dim'],  config['dim'], 3 if config['rgb'] else 1),\n",
    "                         padding='same', return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3),\n",
    "                         padding='same', return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Uncomment if you want to add more ConvLSTM2D layers\n",
    "    # model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3),\n",
    "    #                      padding='same', return_sequences=True))\n",
    "    # model.add(BatchNormalization())\n",
    "    \n",
    "    # Apply TimeDistributed Dense layer to each time step\n",
    "    model.add(TimeDistributed(Flatten()))  # Flatten each frame\n",
    "    model.add(TimeDistributed(Dense(128, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(config['unique_labels'], activation='softmax')))\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    model = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ced48a4-4077-4fc0-bf25-ebc558c8fc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_lstm2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">154,624</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1048576</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │   <span style=\"color: #00af00; text-decoration-color: #00af00\">134,217,856</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_lstm2d (\u001b[38;5;33mConvLSTM2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │       \u001b[38;5;34m154,624\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_1 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1048576\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │   \u001b[38;5;34m134,217,856\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │           \u001b[38;5;34m516\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">404,005,518</span> (1.51 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m404,005,518\u001b[0m (1.51 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,668,420</span> (513.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,668,420\u001b[0m (513.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">269,336,842</span> (1.00 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m269,336,842\u001b[0m (1.00 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ace776-ef47-4177-ba8a-74ebbd7ae68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247597a-b479-4865-8ec8-46fed87d2859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "082d01b7-eeb3-4858-9418-8ac0ece0c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "DataGeneratorSkillBorders init done\n",
      "on_epoch_end_called\n",
      "   videoID  batches_in_video  random_order  total_batches\n",
      "0        3               186             1            186\n",
      "1        6               112             2            298\n",
      "2        2               180             3            478\n",
      "3        4               260             4            738\n",
      "4        7               168             5            906\n",
      "5        5               318             6           1224\n",
      "6        1                92             7           1316\n",
      "connection established\n",
      "DataGeneratorSkillBorders init done\n",
      "on_epoch_end_called\n",
      "   videoID  batches_in_video  random_order  total_batches\n",
      "0        8               127             1            127\n",
      "1        9                87             2            214\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'dim': (config['dim'],config['dim']),\n",
    "          'time_length': config['time_length'],\n",
    "          'n_classes': config['unique_labels'],\n",
    "          'n_channels': 3 if config['rgb'] else 1,\n",
    "          'shuffle': True,\n",
    "}\n",
    "\n",
    "training_generator = DataGeneratorSkillBorders(train=True, **params)\n",
    "test_generator = DataGeneratorSkillBorders(train=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95c4a3d8-147f-4586-9e46-d4afcf9888ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>batches_in_video</th>\n",
       "      <th>random_order</th>\n",
       "      <th>total_batches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>318</td>\n",
       "      <td>6</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   videoID  batches_in_video  random_order  total_batches\n",
       "0        3               186             1            186\n",
       "1        6               112             2            298\n",
       "2        2               180             3            478\n",
       "3        4               260             4            738\n",
       "4        7               168             5            906\n",
       "5        5               318             6           1224\n",
       "6        1                92             7           1316"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.batch_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c27684-dffe-4e1e-b13b-e65c6e4dcfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a794b1-90ff-4c09-828c-58d3c8492e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " getitem, batch_nr 25 train is: True\n",
      "CPU times: user 904 ms, sys: 43.4 ms, total: 947 ms\n",
      "Wall time: 325 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = training_generator.__getitem__(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b63e884-ec87-47c9-ab73-b2d8513ee890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ab4052-80db-4918-8c15-b10bb3199a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          ...,\n",
       "          [0.28235294, 0.29411765, 0.29411765],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         [[0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          ...,\n",
       "          [0.29411765, 0.30588235, 0.30588235],\n",
       "          [0.29411765, 0.30588235, 0.30588235],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         [[0.33333333, 0.34509804, 0.34509804],\n",
       "          [0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.31764706, 0.32941176, 0.32941176],\n",
       "          ...,\n",
       "          [0.29411765, 0.30588235, 0.30588235],\n",
       "          [0.30980392, 0.30980392, 0.30980392],\n",
       "          [0.29803922, 0.30980392, 0.30980392]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.74901961, 0.71764706, 0.67058824],\n",
       "          [0.71372549, 0.69019608, 0.65098039],\n",
       "          [0.68627451, 0.65490196, 0.61568627],\n",
       "          ...,\n",
       "          [0.04313725, 0.08235294, 0.14901961],\n",
       "          [0.04313725, 0.08627451, 0.14509804],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]],\n",
       "\n",
       "         [[0.71764706, 0.69019608, 0.63137255],\n",
       "          [0.70980392, 0.67843137, 0.63137255],\n",
       "          [0.68235294, 0.65098039, 0.60392157],\n",
       "          ...,\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07843137, 0.1372549 ]],\n",
       "\n",
       "         [[0.68235294, 0.65490196, 0.60392157],\n",
       "          [0.66666667, 0.63529412, 0.58823529],\n",
       "          [0.65882353, 0.61568627, 0.57254902],\n",
       "          ...,\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.02745098, 0.07058824, 0.12941176],\n",
       "          [0.02745098, 0.07058824, 0.12941176]]],\n",
       "\n",
       "\n",
       "        [[[0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          ...,\n",
       "          [0.28235294, 0.29411765, 0.29411765],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         [[0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          ...,\n",
       "          [0.29803922, 0.30980392, 0.30980392],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         [[0.33333333, 0.34509804, 0.34509804],\n",
       "          [0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.31764706, 0.32941176, 0.32941176],\n",
       "          ...,\n",
       "          [0.29411765, 0.30588235, 0.30588235],\n",
       "          [0.30588235, 0.30588235, 0.30588235],\n",
       "          [0.30196078, 0.31372549, 0.31372549]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.74901961, 0.71764706, 0.67843137],\n",
       "          [0.71372549, 0.69019608, 0.65098039],\n",
       "          [0.68627451, 0.65490196, 0.61568627],\n",
       "          ...,\n",
       "          [0.04313725, 0.08235294, 0.14901961],\n",
       "          [0.04313725, 0.08627451, 0.14509804],\n",
       "          [0.03529412, 0.07843137, 0.1372549 ]],\n",
       "\n",
       "         [[0.71764706, 0.69019608, 0.63137255],\n",
       "          [0.70980392, 0.67843137, 0.63137255],\n",
       "          [0.68235294, 0.65098039, 0.60392157],\n",
       "          ...,\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]],\n",
       "\n",
       "         [[0.68627451, 0.65490196, 0.60784314],\n",
       "          [0.66666667, 0.63529412, 0.58823529],\n",
       "          [0.65882353, 0.61568627, 0.57254902],\n",
       "          ...,\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07843137, 0.1372549 ]]],\n",
       "\n",
       "\n",
       "        [[[0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          ...,\n",
       "          [0.27843137, 0.29019608, 0.29019608],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         [[0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          ...,\n",
       "          [0.29411765, 0.30588235, 0.30588235],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.29019608, 0.30196078, 0.30196078]],\n",
       "\n",
       "         [[0.33333333, 0.34509804, 0.34509804],\n",
       "          [0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.31764706, 0.32941176, 0.32941176],\n",
       "          ...,\n",
       "          [0.29803922, 0.30980392, 0.30980392],\n",
       "          [0.30588235, 0.30588235, 0.30588235],\n",
       "          [0.29803922, 0.30980392, 0.30980392]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.74901961, 0.71764706, 0.67843137],\n",
       "          [0.70980392, 0.68627451, 0.64705882],\n",
       "          [0.68627451, 0.65490196, 0.61568627],\n",
       "          ...,\n",
       "          [0.04313725, 0.08235294, 0.14901961],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07843137, 0.1372549 ]],\n",
       "\n",
       "         [[0.71764706, 0.69019608, 0.63137255],\n",
       "          [0.70588235, 0.6745098 , 0.62745098],\n",
       "          [0.68235294, 0.65098039, 0.60392157],\n",
       "          ...,\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.02745098, 0.07058824, 0.12941176]],\n",
       "\n",
       "         [[0.68627451, 0.65490196, 0.60784314],\n",
       "          [0.66666667, 0.63529412, 0.58823529],\n",
       "          [0.65882353, 0.61568627, 0.57254902],\n",
       "          ...,\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03529412, 0.0745098 , 0.14117647]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.31764706, 0.32941176, 0.32941176],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          ...,\n",
       "          [0.29019608, 0.29019608, 0.29019608],\n",
       "          [0.27843137, 0.29019608, 0.29019608],\n",
       "          [0.28235294, 0.29411765, 0.29411765]],\n",
       "\n",
       "         [[0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.30980392, 0.32156863, 0.32156863],\n",
       "          ...,\n",
       "          [0.28235294, 0.29411765, 0.29411765],\n",
       "          [0.28235294, 0.29411765, 0.29411765],\n",
       "          [0.28235294, 0.29411765, 0.29411765]],\n",
       "\n",
       "         [[0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          ...,\n",
       "          [0.30588235, 0.30588235, 0.30588235],\n",
       "          [0.29803922, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7372549 , 0.70588235, 0.66666667],\n",
       "          [0.71372549, 0.69019608, 0.65098039],\n",
       "          [0.68627451, 0.65490196, 0.61568627],\n",
       "          ...,\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]],\n",
       "\n",
       "         [[0.71372549, 0.68235294, 0.63529412],\n",
       "          [0.69803922, 0.65490196, 0.61176471],\n",
       "          [0.6745098 , 0.64313725, 0.59607843],\n",
       "          ...,\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03921569, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07058824, 0.12941176]],\n",
       "\n",
       "         [[0.67843137, 0.64705882, 0.6       ],\n",
       "          [0.66666667, 0.62352941, 0.58039216],\n",
       "          [0.65098039, 0.60784314, 0.56470588],\n",
       "          ...,\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]]],\n",
       "\n",
       "\n",
       "        [[[0.31764706, 0.32941176, 0.32941176],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          ...,\n",
       "          [0.29411765, 0.29411765, 0.29411765],\n",
       "          [0.2745098 , 0.28627451, 0.28627451],\n",
       "          [0.28235294, 0.29411765, 0.29411765]],\n",
       "\n",
       "         [[0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.30980392, 0.32156863, 0.32156863],\n",
       "          ...,\n",
       "          [0.28235294, 0.29411765, 0.29411765],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.28627451, 0.29803922, 0.29803922]],\n",
       "\n",
       "         [[0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          ...,\n",
       "          [0.30588235, 0.30588235, 0.30588235],\n",
       "          [0.29803922, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.74117647, 0.70980392, 0.67058824],\n",
       "          [0.71764706, 0.68627451, 0.64705882],\n",
       "          [0.68627451, 0.65490196, 0.61568627],\n",
       "          ...,\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]],\n",
       "\n",
       "         [[0.71372549, 0.68235294, 0.63529412],\n",
       "          [0.69803922, 0.65490196, 0.61176471],\n",
       "          [0.67843137, 0.64705882, 0.6       ],\n",
       "          ...,\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03921569, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07058824, 0.12941176]],\n",
       "\n",
       "         [[0.68235294, 0.64313725, 0.6       ],\n",
       "          [0.66666667, 0.62352941, 0.58039216],\n",
       "          [0.64705882, 0.60392157, 0.56078431],\n",
       "          ...,\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]]],\n",
       "\n",
       "\n",
       "        [[[0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          [0.32156863, 0.33333333, 0.33333333],\n",
       "          ...,\n",
       "          [0.29411765, 0.29411765, 0.29411765],\n",
       "          [0.2745098 , 0.28627451, 0.28627451],\n",
       "          [0.28235294, 0.29411765, 0.29411765]],\n",
       "\n",
       "         [[0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.31372549, 0.3254902 , 0.3254902 ],\n",
       "          [0.30588235, 0.31764706, 0.31764706],\n",
       "          ...,\n",
       "          [0.28235294, 0.29411765, 0.29411765],\n",
       "          [0.28627451, 0.29803922, 0.29803922],\n",
       "          [0.28627451, 0.29803922, 0.29803922]],\n",
       "\n",
       "         [[0.32941176, 0.34117647, 0.34117647],\n",
       "          [0.3254902 , 0.3372549 , 0.3372549 ],\n",
       "          [0.32941176, 0.34117647, 0.34117647],\n",
       "          ...,\n",
       "          [0.30588235, 0.30588235, 0.30588235],\n",
       "          [0.29803922, 0.29803922, 0.29803922],\n",
       "          [0.29411765, 0.30588235, 0.30588235]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.74117647, 0.70980392, 0.67058824],\n",
       "          [0.71764706, 0.68627451, 0.64705882],\n",
       "          [0.68627451, 0.65490196, 0.61568627],\n",
       "          ...,\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03921569, 0.08235294, 0.14117647],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]],\n",
       "\n",
       "         [[0.71372549, 0.68235294, 0.63529412],\n",
       "          [0.69411765, 0.65098039, 0.60784314],\n",
       "          [0.67843137, 0.64705882, 0.6       ],\n",
       "          ...,\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03921569, 0.0745098 , 0.13333333],\n",
       "          [0.03529412, 0.07058824, 0.12941176]],\n",
       "\n",
       "         [[0.68235294, 0.65098039, 0.60392157],\n",
       "          [0.6627451 , 0.63137255, 0.58431373],\n",
       "          [0.65098039, 0.60784314, 0.56470588],\n",
       "          ...,\n",
       "          [0.03529412, 0.07843137, 0.1372549 ],\n",
       "          [0.03137255, 0.0745098 , 0.13333333],\n",
       "          [0.03137255, 0.0745098 , 0.13333333]]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f683c31-77e9-471f-b857-4bb15857b735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09ceb346-6346-4258-9035-c209a0f9b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ba2c862-5576-4999-a5a3-f20623910ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8e48c69-83b9-460f-9cba-b809b33d3d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len called len is: 1316\n",
      "len called len is: 1316\n",
      " getitem, batch_nr 0 train is: True\n",
      " getitem, batch_nr 1 train is: True\n",
      "Epoch 1/2\n",
      "len called len is: 1316\n",
      "len called len is: 1316\n",
      " getitem, batch_nr 0 train is: True\n",
      " getitem, batch_nr 1 train is: True\n",
      "\u001b[1m   1/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:38:59\u001b[0m 10s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 2 train is: True\n",
      "\u001b[1m   2/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:07\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07  getitem, batch_nr 3 train is: True\n",
      "\u001b[1m   3/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:50\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 4 train is: True\n",
      "\u001b[1m   4/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:54\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 5 train is: True\n",
      "\u001b[1m   5/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:19\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 6 train is: True\n",
      "\u001b[1m   6/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:16\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 7 train is: True\n",
      "\u001b[1m   7/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:03\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 8 train is: True\n",
      "\u001b[1m   8/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:42\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 9 train is: True\n",
      "\u001b[1m   9/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53:06\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 10 train is: True\n",
      "\u001b[1m  10/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55:40\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 11 train is: True\n",
      "\u001b[1m  11/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58:08\u001b[0m 5s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 12 train is: True\n",
      "\u001b[1m  12/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00:32\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 13 train is: True\n",
      "\u001b[1m  13/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02:29\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 14 train is: True\n",
      "\u001b[1m  14/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01:47\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 15 train is: True\n",
      "\u001b[1m  15/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00:51\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 16 train is: True\n",
      "\u001b[1m  16/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00:11\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 17 train is: True\n",
      "\u001b[1m  17/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59:33\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.5763e-07 getitem, batch_nr 18 train is: True\n",
      "\u001b[1m  18/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58:40\u001b[0m 5s/step - accuracy: 0.9969 - loss: 0.0497     getitem, batch_nr 19 train is: True\n",
      "\u001b[1m  19/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58:10\u001b[0m 5s/step - accuracy: 0.9915 - loss: 0.1364 getitem, batch_nr 20 train is: True\n",
      "\u001b[1m  20/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57:39\u001b[0m 5s/step - accuracy: 0.9845 - loss: 0.2505 getitem, batch_nr 21 train is: True\n",
      "\u001b[1m  21/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57:01\u001b[0m 5s/step - accuracy: 0.9761 - loss: 0.3848 getitem, batch_nr 22 train is: True\n",
      "\u001b[1m  22/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56:35\u001b[0m 5s/step - accuracy: 0.9669 - loss: 0.5338 getitem, batch_nr 23 train is: True\n",
      "\u001b[1m  23/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56:09\u001b[0m 5s/step - accuracy: 0.9570 - loss: 0.6934 getitem, batch_nr 24 train is: True\n",
      "\u001b[1m  24/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55:48\u001b[0m 5s/step - accuracy: 0.9466 - loss: 0.8604 getitem, batch_nr 25 train is: True\n",
      "\u001b[1m  25/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55:20\u001b[0m 5s/step - accuracy: 0.9360 - loss: 1.0323 getitem, batch_nr 26 train is: True\n",
      "\u001b[1m  26/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54:59\u001b[0m 5s/step - accuracy: 0.9251 - loss: 1.2072 getitem, batch_nr 27 train is: True\n",
      "\u001b[1m  27/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54:42\u001b[0m 5s/step - accuracy: 0.9142 - loss: 1.3835 getitem, batch_nr 28 train is: True\n",
      "\u001b[1m  28/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54:28\u001b[0m 5s/step - accuracy: 0.9032 - loss: 1.5603 getitem, batch_nr 29 train is: True\n",
      "\u001b[1m  29/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54:08\u001b[0m 5s/step - accuracy: 0.8923 - loss: 1.7365 getitem, batch_nr 30 train is: True\n",
      "\u001b[1m  30/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53:54\u001b[0m 5s/step - accuracy: 0.8814 - loss: 1.9114 getitem, batch_nr 31 train is: True\n",
      "\u001b[1m  31/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53:39\u001b[0m 5s/step - accuracy: 0.8707 - loss: 2.0846 getitem, batch_nr 32 train is: True\n",
      "\u001b[1m  32/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53:25\u001b[0m 5s/step - accuracy: 0.8601 - loss: 2.2555 getitem, batch_nr 33 train is: True\n",
      "\u001b[1m  33/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53:11\u001b[0m 5s/step - accuracy: 0.8496 - loss: 2.4240 getitem, batch_nr 34 train is: True\n",
      "\u001b[1m  34/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53:00\u001b[0m 5s/step - accuracy: 0.8393 - loss: 2.5897 getitem, batch_nr 35 train is: True\n",
      "\u001b[1m  35/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52:49\u001b[0m 5s/step - accuracy: 0.8292 - loss: 2.7526 getitem, batch_nr 36 train is: True\n",
      "\u001b[1m  36/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52:31\u001b[0m 5s/step - accuracy: 0.8193 - loss: 2.9124 getitem, batch_nr 37 train is: True\n",
      "\u001b[1m  37/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52:19\u001b[0m 5s/step - accuracy: 0.8096 - loss: 3.0692 getitem, batch_nr 38 train is: True\n",
      "\u001b[1m  38/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52:07\u001b[0m 5s/step - accuracy: 0.8001 - loss: 3.2228 getitem, batch_nr 39 train is: True\n",
      "\u001b[1m  39/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:57\u001b[0m 5s/step - accuracy: 0.7907 - loss: 3.3733 getitem, batch_nr 40 train is: True\n",
      "\u001b[1m  40/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:44\u001b[0m 5s/step - accuracy: 0.7816 - loss: 3.5207 getitem, batch_nr 41 train is: True\n",
      "\u001b[1m  41/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:33\u001b[0m 5s/step - accuracy: 0.7726 - loss: 3.6649 getitem, batch_nr 42 train is: True\n",
      "\u001b[1m  42/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:23\u001b[0m 5s/step - accuracy: 0.7639 - loss: 3.8061 getitem, batch_nr 43 train is: True\n",
      "\u001b[1m  43/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:14\u001b[0m 5s/step - accuracy: 0.7553 - loss: 3.9442 getitem, batch_nr 44 train is: True\n",
      "\u001b[1m  44/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:02\u001b[0m 5s/step - accuracy: 0.7469 - loss: 4.0794 getitem, batch_nr 45 train is: True\n",
      "\u001b[1m  45/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:54\u001b[0m 5s/step - accuracy: 0.7387 - loss: 4.2116 getitem, batch_nr 46 train is: True\n",
      "\u001b[1m  46/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:48\u001b[0m 5s/step - accuracy: 0.7307 - loss: 4.3409 getitem, batch_nr 47 train is: True\n",
      "\u001b[1m  47/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:41\u001b[0m 5s/step - accuracy: 0.7228 - loss: 4.4675 getitem, batch_nr 48 train is: True\n",
      "\u001b[1m  48/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:39\u001b[0m 5s/step - accuracy: 0.7151 - loss: 4.5913 getitem, batch_nr 49 train is: True\n",
      "\u001b[1m  49/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:44\u001b[0m 5s/step - accuracy: 0.7076 - loss: 4.7124 getitem, batch_nr 50 train is: True\n",
      "\u001b[1m  50/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:37\u001b[0m 5s/step - accuracy: 0.7003 - loss: 4.8309 getitem, batch_nr 51 train is: True\n",
      "\u001b[1m  51/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:26\u001b[0m 5s/step - accuracy: 0.6931 - loss: 4.9469 getitem, batch_nr 52 train is: True\n",
      "\u001b[1m  52/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:15\u001b[0m 5s/step - accuracy: 0.6860 - loss: 5.0604 getitem, batch_nr 53 train is: True\n",
      "\u001b[1m  53/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:07\u001b[0m 5s/step - accuracy: 0.6792 - loss: 5.1714 getitem, batch_nr 54 train is: True\n",
      "\u001b[1m  54/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:01\u001b[0m 5s/step - accuracy: 0.6724 - loss: 5.2802 getitem, batch_nr 55 train is: True\n",
      "\u001b[1m  55/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:55\u001b[0m 5s/step - accuracy: 0.6658 - loss: 5.3867 getitem, batch_nr 56 train is: True\n",
      "\u001b[1m  56/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:49\u001b[0m 5s/step - accuracy: 0.6593 - loss: 5.4909 getitem, batch_nr 57 train is: True\n",
      "\u001b[1m  57/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:41\u001b[0m 5s/step - accuracy: 0.6530 - loss: 5.5930 getitem, batch_nr 58 train is: True\n",
      "\u001b[1m  58/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:35\u001b[0m 5s/step - accuracy: 0.6468 - loss: 5.6930 getitem, batch_nr 59 train is: True\n",
      "\u001b[1m  59/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:31\u001b[0m 5s/step - accuracy: 0.6407 - loss: 5.7910 getitem, batch_nr 60 train is: True\n",
      "\u001b[1m  60/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:27\u001b[0m 5s/step - accuracy: 0.6348 - loss: 5.8870 getitem, batch_nr 61 train is: True\n",
      "\u001b[1m  61/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:24\u001b[0m 5s/step - accuracy: 0.6289 - loss: 5.9811 getitem, batch_nr 62 train is: True\n",
      "\u001b[1m  62/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:18\u001b[0m 5s/step - accuracy: 0.6232 - loss: 6.0733 getitem, batch_nr 63 train is: True\n",
      "\u001b[1m  63/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:10\u001b[0m 5s/step - accuracy: 0.6178 - loss: 6.1607 getitem, batch_nr 64 train is: True\n",
      "\u001b[1m  64/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:06\u001b[0m 5s/step - accuracy: 0.6126 - loss: 6.2435 getitem, batch_nr 65 train is: True\n",
      "\u001b[1m  65/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:02\u001b[0m 5s/step - accuracy: 0.6076 - loss: 6.3248 getitem, batch_nr 66 train is: True\n",
      "\u001b[1m  66/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:53\u001b[0m 5s/step - accuracy: 0.6026 - loss: 6.4047 getitem, batch_nr 67 train is: True\n",
      "\u001b[1m  67/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:47\u001b[0m 5s/step - accuracy: 0.5978 - loss: 6.4833 getitem, batch_nr 68 train is: True\n",
      "\u001b[1m  68/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:48\u001b[0m 5s/step - accuracy: 0.5930 - loss: 6.5605 getitem, batch_nr 69 train is: True\n",
      "\u001b[1m  69/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:42\u001b[0m 5s/step - accuracy: 0.5883 - loss: 6.6364 getitem, batch_nr 70 train is: True\n",
      "\u001b[1m  70/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:42\u001b[0m 5s/step - accuracy: 0.5836 - loss: 6.7110 getitem, batch_nr 71 train is: True\n",
      "\u001b[1m  71/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:38\u001b[0m 5s/step - accuracy: 0.5791 - loss: 6.7843 getitem, batch_nr 72 train is: True\n",
      "\u001b[1m  72/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:36\u001b[0m 5s/step - accuracy: 0.5746 - loss: 6.8564 getitem, batch_nr 73 train is: True\n",
      "\u001b[1m  73/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:30\u001b[0m 5s/step - accuracy: 0.5702 - loss: 6.9274 getitem, batch_nr 74 train is: True\n",
      "\u001b[1m  74/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:21\u001b[0m 5s/step - accuracy: 0.5659 - loss: 6.9971 getitem, batch_nr 75 train is: True\n",
      "\u001b[1m  75/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:16\u001b[0m 5s/step - accuracy: 0.5616 - loss: 7.0657 getitem, batch_nr 76 train is: True\n",
      "\u001b[1m  76/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:09\u001b[0m 5s/step - accuracy: 0.5574 - loss: 7.1332 getitem, batch_nr 77 train is: True\n",
      "\u001b[1m  77/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:02\u001b[0m 5s/step - accuracy: 0.5533 - loss: 7.1996 getitem, batch_nr 78 train is: True\n",
      "\u001b[1m  78/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:59\u001b[0m 5s/step - accuracy: 0.5493 - loss: 7.2649 getitem, batch_nr 79 train is: True\n",
      "\u001b[1m  79/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:54\u001b[0m 5s/step - accuracy: 0.5453 - loss: 7.3292 getitem, batch_nr 80 train is: True\n",
      "\u001b[1m  80/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:46\u001b[0m 5s/step - accuracy: 0.5414 - loss: 7.3925 getitem, batch_nr 81 train is: True\n",
      "\u001b[1m  81/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:36\u001b[0m 5s/step - accuracy: 0.5375 - loss: 7.4547 getitem, batch_nr 82 train is: True\n",
      "\u001b[1m  82/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:27\u001b[0m 5s/step - accuracy: 0.5337 - loss: 7.5161 getitem, batch_nr 83 train is: True\n",
      "\u001b[1m  83/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:20\u001b[0m 5s/step - accuracy: 0.5299 - loss: 7.5764 getitem, batch_nr 84 train is: True\n",
      "\u001b[1m  84/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:13\u001b[0m 5s/step - accuracy: 0.5263 - loss: 7.6358 getitem, batch_nr 85 train is: True\n",
      "\u001b[1m  85/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:04\u001b[0m 5s/step - accuracy: 0.5226 - loss: 7.6944 getitem, batch_nr 86 train is: True\n",
      "\u001b[1m  86/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:56\u001b[0m 5s/step - accuracy: 0.5191 - loss: 7.7520 getitem, batch_nr 87 train is: True\n",
      "\u001b[1m  87/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:49\u001b[0m 5s/step - accuracy: 0.5155 - loss: 7.8088 getitem, batch_nr 88 train is: True\n",
      "\u001b[1m  88/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:42\u001b[0m 5s/step - accuracy: 0.5121 - loss: 7.8647 getitem, batch_nr 89 train is: True\n",
      "\u001b[1m  89/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:35\u001b[0m 5s/step - accuracy: 0.5086 - loss: 7.9198 getitem, batch_nr 90 train is: True\n",
      "\u001b[1m  90/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:29\u001b[0m 5s/step - accuracy: 0.5053 - loss: 7.9740 getitem, batch_nr 91 train is: True\n",
      "\u001b[1m  91/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:25\u001b[0m 5s/step - accuracy: 0.5020 - loss: 8.0275 getitem, batch_nr 92 train is: True\n",
      "\u001b[1m  92/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:18\u001b[0m 5s/step - accuracy: 0.4987 - loss: 8.0802 getitem, batch_nr 93 train is: True\n",
      "\u001b[1m  93/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:11\u001b[0m 5s/step - accuracy: 0.4955 - loss: 8.1322 getitem, batch_nr 94 train is: True\n",
      "\u001b[1m  94/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:04\u001b[0m 5s/step - accuracy: 0.4923 - loss: 8.1834 getitem, batch_nr 95 train is: True\n",
      "\u001b[1m  95/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:58\u001b[0m 5s/step - accuracy: 0.4892 - loss: 8.2339 getitem, batch_nr 96 train is: True\n",
      "\u001b[1m  96/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:51\u001b[0m 5s/step - accuracy: 0.4861 - loss: 8.2837 getitem, batch_nr 97 train is: True\n",
      "\u001b[1m  97/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:44\u001b[0m 5s/step - accuracy: 0.4830 - loss: 8.3327 getitem, batch_nr 98 train is: True\n",
      "\u001b[1m  98/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:37\u001b[0m 5s/step - accuracy: 0.4800 - loss: 8.3811 getitem, batch_nr 99 train is: True\n",
      "\u001b[1m  99/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:30\u001b[0m 5s/step - accuracy: 0.4771 - loss: 8.4289 getitem, batch_nr 100 train is: True\n",
      "\u001b[1m 100/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:26\u001b[0m 5s/step - accuracy: 0.4741 - loss: 8.4759 getitem, batch_nr 101 train is: True\n",
      "\u001b[1m 101/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:23\u001b[0m 5s/step - accuracy: 0.4713 - loss: 8.5224 getitem, batch_nr 102 train is: True\n",
      "\u001b[1m 102/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:17\u001b[0m 5s/step - accuracy: 0.4684 - loss: 8.5682 getitem, batch_nr 103 train is: True\n",
      "\u001b[1m 103/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:16\u001b[0m 5s/step - accuracy: 0.4656 - loss: 8.6134 getitem, batch_nr 104 train is: True\n",
      "\u001b[1m 104/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:09\u001b[0m 5s/step - accuracy: 0.4628 - loss: 8.6580 getitem, batch_nr 105 train is: True\n",
      "\u001b[1m 105/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:02\u001b[0m 5s/step - accuracy: 0.4601 - loss: 8.7020 getitem, batch_nr 106 train is: True\n",
      "\u001b[1m 106/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:57\u001b[0m 5s/step - accuracy: 0.4574 - loss: 8.7454 getitem, batch_nr 107 train is: True\n",
      "\u001b[1m 107/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:50\u001b[0m 5s/step - accuracy: 0.4548 - loss: 8.7882 getitem, batch_nr 108 train is: True\n",
      "\u001b[1m 108/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:44\u001b[0m 5s/step - accuracy: 0.4521 - loss: 8.8305 getitem, batch_nr 109 train is: True\n",
      "\u001b[1m 109/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:37\u001b[0m 5s/step - accuracy: 0.4495 - loss: 8.8723 getitem, batch_nr 110 train is: True\n",
      "\u001b[1m 110/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:32\u001b[0m 5s/step - accuracy: 0.4470 - loss: 8.9135 getitem, batch_nr 111 train is: True\n",
      "\u001b[1m 111/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:29\u001b[0m 5s/step - accuracy: 0.4445 - loss: 8.9542 getitem, batch_nr 112 train is: True\n",
      "\u001b[1m 112/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:25\u001b[0m 5s/step - accuracy: 0.4420 - loss: 8.9944 getitem, batch_nr 113 train is: True\n",
      "\u001b[1m 113/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:17\u001b[0m 5s/step - accuracy: 0.4395 - loss: 9.0341 getitem, batch_nr 114 train is: True\n",
      "\u001b[1m 114/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:11\u001b[0m 5s/step - accuracy: 0.4371 - loss: 9.0733 getitem, batch_nr 115 train is: True\n",
      "\u001b[1m 115/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:04\u001b[0m 5s/step - accuracy: 0.4347 - loss: 9.1120 getitem, batch_nr 116 train is: True\n",
      "\u001b[1m 116/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:58\u001b[0m 5s/step - accuracy: 0.4323 - loss: 9.1503 getitem, batch_nr 117 train is: True\n",
      "\u001b[1m 117/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:52\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1880 getitem, batch_nr 118 train is: True\n",
      "\u001b[1m 118/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:46\u001b[0m 5s/step - accuracy: 0.4276 - loss: 9.2253 getitem, batch_nr 119 train is: True\n",
      "\u001b[1m 119/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:39\u001b[0m 5s/step - accuracy: 0.4254 - loss: 9.2622 getitem, batch_nr 120 train is: True\n",
      "\u001b[1m 120/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:33\u001b[0m 5s/step - accuracy: 0.4231 - loss: 9.2986 getitem, batch_nr 121 train is: True\n",
      "\u001b[1m 121/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:27\u001b[0m 5s/step - accuracy: 0.4209 - loss: 9.3346 getitem, batch_nr 122 train is: True\n",
      "\u001b[1m 122/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:21\u001b[0m 5s/step - accuracy: 0.4187 - loss: 9.3702 getitem, batch_nr 123 train is: True\n",
      "\u001b[1m 123/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:15\u001b[0m 5s/step - accuracy: 0.4165 - loss: 9.4054 getitem, batch_nr 124 train is: True\n",
      "\u001b[1m 124/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:09\u001b[0m 5s/step - accuracy: 0.4143 - loss: 9.4401 getitem, batch_nr 125 train is: True\n",
      "\u001b[1m 125/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:02\u001b[0m 5s/step - accuracy: 0.4122 - loss: 9.4744 getitem, batch_nr 126 train is: True\n",
      "\u001b[1m 126/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:57\u001b[0m 5s/step - accuracy: 0.4101 - loss: 9.5084 getitem, batch_nr 127 train is: True\n",
      "\u001b[1m 127/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:51\u001b[0m 5s/step - accuracy: 0.4080 - loss: 9.5419 getitem, batch_nr 128 train is: True\n",
      "\u001b[1m 128/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:47\u001b[0m 5s/step - accuracy: 0.4059 - loss: 9.5751 getitem, batch_nr 129 train is: True\n",
      "\u001b[1m 129/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:42\u001b[0m 5s/step - accuracy: 0.4039 - loss: 9.6079 getitem, batch_nr 130 train is: True\n",
      "\u001b[1m 130/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:36\u001b[0m 5s/step - accuracy: 0.4019 - loss: 9.6403 getitem, batch_nr 131 train is: True\n",
      "\u001b[1m 131/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:31\u001b[0m 5s/step - accuracy: 0.3999 - loss: 9.6724 getitem, batch_nr 132 train is: True\n",
      "\u001b[1m 132/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:26\u001b[0m 5s/step - accuracy: 0.3979 - loss: 9.7041 getitem, batch_nr 133 train is: True\n",
      "\u001b[1m 133/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:21\u001b[0m 5s/step - accuracy: 0.3960 - loss: 9.7355 getitem, batch_nr 134 train is: True\n",
      "\u001b[1m 134/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:17\u001b[0m 5s/step - accuracy: 0.3941 - loss: 9.7665 getitem, batch_nr 135 train is: True\n",
      "\u001b[1m 135/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:10\u001b[0m 5s/step - accuracy: 0.3922 - loss: 9.7972 getitem, batch_nr 136 train is: True\n",
      "\u001b[1m 136/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:04\u001b[0m 5s/step - accuracy: 0.3903 - loss: 9.8276 getitem, batch_nr 137 train is: True\n",
      "\u001b[1m 137/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:59\u001b[0m 5s/step - accuracy: 0.3884 - loss: 9.8576 getitem, batch_nr 138 train is: True\n",
      "\u001b[1m 138/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:52\u001b[0m 5s/step - accuracy: 0.3866 - loss: 9.8873 getitem, batch_nr 139 train is: True\n",
      "\u001b[1m 139/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:46\u001b[0m 5s/step - accuracy: 0.3847 - loss: 9.9167 getitem, batch_nr 140 train is: True\n",
      "\u001b[1m 140/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:39\u001b[0m 5s/step - accuracy: 0.3829 - loss: 9.9458 getitem, batch_nr 141 train is: True\n",
      "\u001b[1m 141/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:34\u001b[0m 5s/step - accuracy: 0.3812 - loss: 9.9746 getitem, batch_nr 142 train is: True\n",
      "\u001b[1m 142/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:27\u001b[0m 5s/step - accuracy: 0.3794 - loss: 10.0030 getitem, batch_nr 143 train is: True\n",
      "\u001b[1m 143/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:21\u001b[0m 5s/step - accuracy: 0.3777 - loss: 10.0306 getitem, batch_nr 144 train is: True\n",
      "\u001b[1m 144/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:16\u001b[0m 5s/step - accuracy: 0.3760 - loss: 10.0572 getitem, batch_nr 145 train is: True\n",
      "\u001b[1m 145/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:09\u001b[0m 5s/step - accuracy: 0.3744 - loss: 10.0833 getitem, batch_nr 146 train is: True\n",
      "\u001b[1m 146/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:03\u001b[0m 5s/step - accuracy: 0.3728 - loss: 10.1093 getitem, batch_nr 147 train is: True\n",
      "\u001b[1m 147/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:56\u001b[0m 5s/step - accuracy: 0.3712 - loss: 10.1349 getitem, batch_nr 148 train is: True\n",
      "\u001b[1m 148/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:50\u001b[0m 5s/step - accuracy: 0.3696 - loss: 10.1604 getitem, batch_nr 149 train is: True\n",
      "\u001b[1m 149/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:46\u001b[0m 5s/step - accuracy: 0.3681 - loss: 10.1856 getitem, batch_nr 150 train is: True\n",
      "\u001b[1m 150/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:44\u001b[0m 5s/step - accuracy: 0.3665 - loss: 10.2105 getitem, batch_nr 151 train is: True\n",
      "\u001b[1m 151/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:40\u001b[0m 5s/step - accuracy: 0.3650 - loss: 10.2352 getitem, batch_nr 152 train is: True\n",
      "\u001b[1m 152/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:34\u001b[0m 5s/step - accuracy: 0.3635 - loss: 10.2597 getitem, batch_nr 153 train is: True\n",
      "\u001b[1m 153/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:28\u001b[0m 5s/step - accuracy: 0.3620 - loss: 10.2840 getitem, batch_nr 154 train is: True\n",
      "\u001b[1m 154/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:22\u001b[0m 5s/step - accuracy: 0.3605 - loss: 10.3080 getitem, batch_nr 155 train is: True\n",
      "\u001b[1m 155/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:17\u001b[0m 5s/step - accuracy: 0.3590 - loss: 10.3318 getitem, batch_nr 156 train is: True\n",
      "\u001b[1m 156/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:10\u001b[0m 5s/step - accuracy: 0.3576 - loss: 10.3550 getitem, batch_nr 157 train is: True\n",
      "\u001b[1m 157/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:04\u001b[0m 5s/step - accuracy: 0.3562 - loss: 10.3774 getitem, batch_nr 158 train is: True\n",
      "\u001b[1m 158/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:58\u001b[0m 5s/step - accuracy: 0.3548 - loss: 10.3988 getitem, batch_nr 159 train is: True\n",
      "\u001b[1m 159/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:52\u001b[0m 5s/step - accuracy: 0.3536 - loss: 10.4195 getitem, batch_nr 160 train is: True\n",
      "\u001b[1m 160/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:47\u001b[0m 5s/step - accuracy: 0.3523 - loss: 10.4394 getitem, batch_nr 161 train is: True\n",
      "\u001b[1m 161/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:41\u001b[0m 5s/step - accuracy: 0.3511 - loss: 10.4585 getitem, batch_nr 162 train is: True\n",
      "\u001b[1m 162/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:34\u001b[0m 5s/step - accuracy: 0.3500 - loss: 10.4768 getitem, batch_nr 163 train is: True\n",
      "\u001b[1m 163/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:28\u001b[0m 5s/step - accuracy: 0.3489 - loss: 10.4945 getitem, batch_nr 164 train is: True\n",
      "\u001b[1m 164/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:22\u001b[0m 5s/step - accuracy: 0.3479 - loss: 10.5114 getitem, batch_nr 165 train is: True\n",
      "\u001b[1m 165/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:16\u001b[0m 5s/step - accuracy: 0.3468 - loss: 10.5276 getitem, batch_nr 166 train is: True\n",
      "\u001b[1m 166/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:10\u001b[0m 5s/step - accuracy: 0.3459 - loss: 10.5431 getitem, batch_nr 167 train is: True\n",
      "\u001b[1m 167/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:04\u001b[0m 5s/step - accuracy: 0.3450 - loss: 10.5580 getitem, batch_nr 168 train is: True\n",
      "\u001b[1m 168/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:58\u001b[0m 5s/step - accuracy: 0.3441 - loss: 10.5723 getitem, batch_nr 169 train is: True\n",
      "\u001b[1m 169/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:52\u001b[0m 5s/step - accuracy: 0.3432 - loss: 10.5859 getitem, batch_nr 170 train is: True\n",
      "\u001b[1m 170/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:46\u001b[0m 5s/step - accuracy: 0.3424 - loss: 10.5989 getitem, batch_nr 171 train is: True\n",
      "\u001b[1m 171/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:39\u001b[0m 5s/step - accuracy: 0.3416 - loss: 10.6114 getitem, batch_nr 172 train is: True\n",
      "\u001b[1m 172/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:33\u001b[0m 5s/step - accuracy: 0.3409 - loss: 10.6232 getitem, batch_nr 173 train is: True\n",
      "\u001b[1m 173/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:27\u001b[0m 5s/step - accuracy: 0.3402 - loss: 10.6345 getitem, batch_nr 174 train is: True\n",
      "\u001b[1m 174/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:21\u001b[0m 5s/step - accuracy: 0.3395 - loss: 10.6453 getitem, batch_nr 175 train is: True\n",
      "\u001b[1m 175/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:15\u001b[0m 5s/step - accuracy: 0.3389 - loss: 10.6555 getitem, batch_nr 176 train is: True\n",
      "\u001b[1m 176/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:09\u001b[0m 5s/step - accuracy: 0.3383 - loss: 10.6652 getitem, batch_nr 177 train is: True\n",
      "\u001b[1m 177/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:03\u001b[0m 5s/step - accuracy: 0.3377 - loss: 10.6744 getitem, batch_nr 178 train is: True\n",
      "\u001b[1m 178/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:57\u001b[0m 5s/step - accuracy: 0.3372 - loss: 10.6831 getitem, batch_nr 179 train is: True\n",
      "\u001b[1m 179/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:51\u001b[0m 5s/step - accuracy: 0.3367 - loss: 10.6913 getitem, batch_nr 180 train is: True\n",
      "\u001b[1m 180/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:47\u001b[0m 5s/step - accuracy: 0.3362 - loss: 10.6991 getitem, batch_nr 181 train is: True\n",
      "\u001b[1m 181/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:42\u001b[0m 5s/step - accuracy: 0.3358 - loss: 10.7064 getitem, batch_nr 182 train is: True\n",
      "\u001b[1m 182/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:36\u001b[0m 5s/step - accuracy: 0.3353 - loss: 10.7133 getitem, batch_nr 183 train is: True\n",
      "\u001b[1m 183/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:30\u001b[0m 5s/step - accuracy: 0.3349 - loss: 10.7197 getitem, batch_nr 184 train is: True\n",
      "\u001b[1m 184/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:24\u001b[0m 5s/step - accuracy: 0.3346 - loss: 10.7257 getitem, batch_nr 185 train is: True\n",
      "\u001b[1m 185/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:19\u001b[0m 5s/step - accuracy: 0.3342 - loss: 10.7313 getitem, batch_nr 186 train is: True\n",
      "\u001b[1m 186/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:13\u001b[0m 5s/step - accuracy: 0.3339 - loss: 10.7365 getitem, batch_nr 187 train is: True\n",
      "\u001b[1m 187/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:07\u001b[0m 5s/step - accuracy: 0.3336 - loss: 10.7413 getitem, batch_nr 188 train is: True\n",
      "\u001b[1m 188/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:01\u001b[0m 5s/step - accuracy: 0.3333 - loss: 10.7457 getitem, batch_nr 189 train is: True\n",
      "\u001b[1m 189/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:56\u001b[0m 5s/step - accuracy: 0.3331 - loss: 10.7498 getitem, batch_nr 190 train is: True\n",
      "\u001b[1m 190/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:52\u001b[0m 5s/step - accuracy: 0.3328 - loss: 10.7535 getitem, batch_nr 191 train is: True\n",
      "\u001b[1m 191/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:50\u001b[0m 5s/step - accuracy: 0.3326 - loss: 10.7568 getitem, batch_nr 192 train is: True\n",
      "\u001b[1m 192/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:44\u001b[0m 5s/step - accuracy: 0.3324 - loss: 10.7598 getitem, batch_nr 193 train is: True\n",
      "\u001b[1m 193/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:39\u001b[0m 5s/step - accuracy: 0.3323 - loss: 10.7625 getitem, batch_nr 194 train is: True\n",
      "\u001b[1m 194/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:33\u001b[0m 5s/step - accuracy: 0.3321 - loss: 10.7649 getitem, batch_nr 195 train is: True\n",
      "\u001b[1m 195/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 5s/step - accuracy: 0.3320 - loss: 10.7669 getitem, batch_nr 196 train is: True\n",
      "\u001b[1m 196/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:21\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7686 getitem, batch_nr 197 train is: True\n",
      "\u001b[1m 197/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:16\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7700 getitem, batch_nr 198 train is: True\n",
      "\u001b[1m 198/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:10\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7711 getitem, batch_nr 199 train is: True\n",
      "\u001b[1m 199/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:04\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7719 getitem, batch_nr 200 train is: True\n",
      "\u001b[1m 200/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:58\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7725 getitem, batch_nr 201 train is: True\n",
      "\u001b[1m 201/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:53\u001b[0m 5s/step - accuracy: 0.3316 - loss: 10.7727 getitem, batch_nr 202 train is: True\n",
      "\u001b[1m 202/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:48\u001b[0m 5s/step - accuracy: 0.3316 - loss: 10.7727 getitem, batch_nr 203 train is: True\n",
      "\u001b[1m 203/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:45\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7724 getitem, batch_nr 204 train is: True\n",
      "\u001b[1m 204/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:39\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7719 getitem, batch_nr 205 train is: True\n",
      "\u001b[1m 205/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:36\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7712 getitem, batch_nr 206 train is: True\n",
      "\u001b[1m 206/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:31\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7704 getitem, batch_nr 207 train is: True\n",
      "\u001b[1m 207/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:25\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7697 getitem, batch_nr 208 train is: True\n",
      "\u001b[1m 208/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:20\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7692 getitem, batch_nr 209 train is: True\n",
      "\u001b[1m 209/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:16\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7689 getitem, batch_nr 210 train is: True\n",
      "\u001b[1m 210/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:13\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7686 getitem, batch_nr 211 train is: True\n",
      "\u001b[1m 211/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:07\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7685 getitem, batch_nr 212 train is: True\n",
      "\u001b[1m 212/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:01\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7685 getitem, batch_nr 213 train is: True\n",
      "\u001b[1m 213/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:56\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7686 getitem, batch_nr 214 train is: True\n",
      "\u001b[1m 214/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:50\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7688 getitem, batch_nr 215 train is: True\n",
      "\u001b[1m 215/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:44\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7692 getitem, batch_nr 216 train is: True\n",
      "\u001b[1m 216/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:39\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7696 getitem, batch_nr 217 train is: True\n",
      "\u001b[1m 217/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:33\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7702 getitem, batch_nr 218 train is: True\n",
      "\u001b[1m 218/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:28\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7708 getitem, batch_nr 219 train is: True\n",
      "\u001b[1m 219/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:22\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7716 getitem, batch_nr 220 train is: True\n",
      "\u001b[1m 220/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:16\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7725 getitem, batch_nr 221 train is: True\n",
      "\u001b[1m 221/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:10\u001b[0m 5s/step - accuracy: 0.3316 - loss: 10.7734 getitem, batch_nr 222 train is: True\n",
      "\u001b[1m 222/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:04\u001b[0m 5s/step - accuracy: 0.3315 - loss: 10.7745 getitem, batch_nr 223 train is: True\n",
      "\u001b[1m 223/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:59\u001b[0m 5s/step - accuracy: 0.3315 - loss: 10.7757 getitem, batch_nr 224 train is: True\n",
      "\u001b[1m 224/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:54\u001b[0m 5s/step - accuracy: 0.3314 - loss: 10.7769 getitem, batch_nr 225 train is: True\n",
      "\u001b[1m 225/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:48\u001b[0m 5s/step - accuracy: 0.3313 - loss: 10.7782 getitem, batch_nr 226 train is: True\n",
      "\u001b[1m 226/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:42\u001b[0m 5s/step - accuracy: 0.3312 - loss: 10.7796 getitem, batch_nr 227 train is: True\n",
      "\u001b[1m 227/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:36\u001b[0m 5s/step - accuracy: 0.3311 - loss: 10.7812 getitem, batch_nr 228 train is: True\n",
      "\u001b[1m 228/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:30\u001b[0m 5s/step - accuracy: 0.3310 - loss: 10.7827 getitem, batch_nr 229 train is: True\n",
      "\u001b[1m 229/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:24\u001b[0m 5s/step - accuracy: 0.3309 - loss: 10.7844 getitem, batch_nr 230 train is: True\n",
      "\u001b[1m 230/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:18\u001b[0m 5s/step - accuracy: 0.3308 - loss: 10.7862 getitem, batch_nr 231 train is: True\n",
      "\u001b[1m 231/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:12\u001b[0m 5s/step - accuracy: 0.3307 - loss: 10.7880 getitem, batch_nr 232 train is: True\n",
      "\u001b[1m 232/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:07\u001b[0m 5s/step - accuracy: 0.3306 - loss: 10.7899 getitem, batch_nr 233 train is: True\n",
      "\u001b[1m 233/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:01\u001b[0m 5s/step - accuracy: 0.3305 - loss: 10.7919 getitem, batch_nr 234 train is: True\n",
      "\u001b[1m 234/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:56\u001b[0m 5s/step - accuracy: 0.3303 - loss: 10.7939 getitem, batch_nr 235 train is: True\n",
      "\u001b[1m 235/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:50\u001b[0m 5s/step - accuracy: 0.3302 - loss: 10.7960 getitem, batch_nr 236 train is: True\n",
      "\u001b[1m 236/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:44\u001b[0m 5s/step - accuracy: 0.3301 - loss: 10.7982 getitem, batch_nr 237 train is: True\n",
      "\u001b[1m 237/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:38\u001b[0m 5s/step - accuracy: 0.3299 - loss: 10.8005 getitem, batch_nr 238 train is: True\n",
      "\u001b[1m 238/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:32\u001b[0m 5s/step - accuracy: 0.3298 - loss: 10.8028 getitem, batch_nr 239 train is: True\n",
      "\u001b[1m 239/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:27\u001b[0m 5s/step - accuracy: 0.3296 - loss: 10.8052 getitem, batch_nr 240 train is: True\n",
      "\u001b[1m 240/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:21\u001b[0m 5s/step - accuracy: 0.3295 - loss: 10.8076 getitem, batch_nr 241 train is: True\n",
      "\u001b[1m 241/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:15\u001b[0m 5s/step - accuracy: 0.3293 - loss: 10.8101 getitem, batch_nr 242 train is: True\n",
      "\u001b[1m 242/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:10\u001b[0m 5s/step - accuracy: 0.3292 - loss: 10.8127 getitem, batch_nr 243 train is: True\n",
      "\u001b[1m 243/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:04\u001b[0m 5s/step - accuracy: 0.3290 - loss: 10.8153 getitem, batch_nr 244 train is: True\n",
      "\u001b[1m 244/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:59\u001b[0m 5s/step - accuracy: 0.3288 - loss: 10.8180 getitem, batch_nr 245 train is: True\n",
      "\u001b[1m 245/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:53\u001b[0m 5s/step - accuracy: 0.3287 - loss: 10.8207 getitem, batch_nr 246 train is: True\n",
      "\u001b[1m 246/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:47\u001b[0m 5s/step - accuracy: 0.3285 - loss: 10.8235 getitem, batch_nr 247 train is: True\n",
      "\u001b[1m 247/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:42\u001b[0m 5s/step - accuracy: 0.3283 - loss: 10.8263 getitem, batch_nr 248 train is: True\n",
      "\u001b[1m 248/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:37\u001b[0m 5s/step - accuracy: 0.3281 - loss: 10.8292 getitem, batch_nr 249 train is: True\n",
      "\u001b[1m 249/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:31\u001b[0m 5s/step - accuracy: 0.3279 - loss: 10.8322 getitem, batch_nr 250 train is: True\n",
      "\u001b[1m 250/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:26\u001b[0m 5s/step - accuracy: 0.3278 - loss: 10.8352 getitem, batch_nr 251 train is: True\n",
      "\u001b[1m 251/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:21\u001b[0m 5s/step - accuracy: 0.3276 - loss: 10.8382 getitem, batch_nr 252 train is: True\n",
      "\u001b[1m 252/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:15\u001b[0m 5s/step - accuracy: 0.3274 - loss: 10.8413 getitem, batch_nr 253 train is: True\n",
      "\u001b[1m 253/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:10\u001b[0m 5s/step - accuracy: 0.3272 - loss: 10.8444 getitem, batch_nr 254 train is: True\n",
      "\u001b[1m 254/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:04\u001b[0m 5s/step - accuracy: 0.3270 - loss: 10.8476 getitem, batch_nr 255 train is: True\n",
      "\u001b[1m 255/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:58\u001b[0m 5s/step - accuracy: 0.3268 - loss: 10.8508 getitem, batch_nr 256 train is: True\n",
      "\u001b[1m 256/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:53\u001b[0m 5s/step - accuracy: 0.3266 - loss: 10.8541 getitem, batch_nr 257 train is: True\n",
      "\u001b[1m 257/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:47\u001b[0m 5s/step - accuracy: 0.3264 - loss: 10.8574 getitem, batch_nr 258 train is: True\n",
      "\u001b[1m 258/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:41\u001b[0m 5s/step - accuracy: 0.3262 - loss: 10.8608 getitem, batch_nr 259 train is: True\n",
      "\u001b[1m 259/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:36\u001b[0m 5s/step - accuracy: 0.3260 - loss: 10.8642 getitem, batch_nr 260 train is: True\n",
      "\u001b[1m 260/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:30\u001b[0m 5s/step - accuracy: 0.3258 - loss: 10.8676 getitem, batch_nr 261 train is: True\n",
      "\u001b[1m 261/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:25\u001b[0m 5s/step - accuracy: 0.3255 - loss: 10.8711 getitem, batch_nr 262 train is: True\n",
      "\u001b[1m 262/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:19\u001b[0m 5s/step - accuracy: 0.3253 - loss: 10.8746 getitem, batch_nr 263 train is: True\n",
      "\u001b[1m 263/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:16\u001b[0m 5s/step - accuracy: 0.3251 - loss: 10.8781 getitem, batch_nr 264 train is: True\n",
      "\u001b[1m 264/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:10\u001b[0m 5s/step - accuracy: 0.3249 - loss: 10.8817 getitem, batch_nr 265 train is: True\n",
      "\u001b[1m 265/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:04\u001b[0m 5s/step - accuracy: 0.3247 - loss: 10.8853 getitem, batch_nr 266 train is: True\n",
      "\u001b[1m 266/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:59\u001b[0m 5s/step - accuracy: 0.3244 - loss: 10.8889 getitem, batch_nr 267 train is: True\n",
      "\u001b[1m 267/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:54\u001b[0m 5s/step - accuracy: 0.3242 - loss: 10.8926 getitem, batch_nr 268 train is: True\n",
      "\u001b[1m 268/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:49\u001b[0m 5s/step - accuracy: 0.3240 - loss: 10.8963 getitem, batch_nr 269 train is: True\n",
      "\u001b[1m 269/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:44\u001b[0m 5s/step - accuracy: 0.3237 - loss: 10.9000 getitem, batch_nr 270 train is: True\n",
      "\u001b[1m 270/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:38\u001b[0m 5s/step - accuracy: 0.3235 - loss: 10.9038 getitem, batch_nr 271 train is: True\n",
      "\u001b[1m 271/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:33\u001b[0m 5s/step - accuracy: 0.3233 - loss: 10.9076 getitem, batch_nr 272 train is: True\n",
      "\u001b[1m 272/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:27\u001b[0m 5s/step - accuracy: 0.3230 - loss: 10.9114 getitem, batch_nr 273 train is: True\n",
      "\u001b[1m 273/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:21\u001b[0m 5s/step - accuracy: 0.3228 - loss: 10.9153 getitem, batch_nr 274 train is: True\n",
      "\u001b[1m 274/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:16\u001b[0m 5s/step - accuracy: 0.3226 - loss: 10.9192 getitem, batch_nr 275 train is: True\n",
      "\u001b[1m 275/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:11\u001b[0m 5s/step - accuracy: 0.3223 - loss: 10.9231 getitem, batch_nr 276 train is: True\n",
      "\u001b[1m 276/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:05\u001b[0m 5s/step - accuracy: 0.3221 - loss: 10.9270 getitem, batch_nr 277 train is: True\n",
      "\u001b[1m 277/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:00\u001b[0m 5s/step - accuracy: 0.3218 - loss: 10.9309 getitem, batch_nr 278 train is: True\n",
      "\u001b[1m 278/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:54\u001b[0m 5s/step - accuracy: 0.3216 - loss: 10.9349 getitem, batch_nr 279 train is: True\n",
      "\u001b[1m 279/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:49\u001b[0m 5s/step - accuracy: 0.3213 - loss: 10.9389 getitem, batch_nr 280 train is: True\n",
      "\u001b[1m 280/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:43\u001b[0m 5s/step - accuracy: 0.3211 - loss: 10.9430 getitem, batch_nr 281 train is: True\n",
      "\u001b[1m 281/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:38\u001b[0m 5s/step - accuracy: 0.3208 - loss: 10.9470 getitem, batch_nr 282 train is: True\n",
      "\u001b[1m 282/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:32\u001b[0m 5s/step - accuracy: 0.3206 - loss: 10.9511 getitem, batch_nr 283 train is: True\n",
      "\u001b[1m 283/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:27\u001b[0m 5s/step - accuracy: 0.3203 - loss: 10.9550 getitem, batch_nr 284 train is: True\n",
      "\u001b[1m 284/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:22\u001b[0m 5s/step - accuracy: 0.3201 - loss: 10.9587 getitem, batch_nr 285 train is: True\n",
      "\u001b[1m 285/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:16\u001b[0m 5s/step - accuracy: 0.3199 - loss: 10.9623 getitem, batch_nr 286 train is: True\n",
      "\u001b[1m 286/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:10\u001b[0m 5s/step - accuracy: 0.3197 - loss: 10.9657 getitem, batch_nr 287 train is: True\n",
      "\u001b[1m 287/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:05\u001b[0m 5s/step - accuracy: 0.3195 - loss: 10.9689 getitem, batch_nr 288 train is: True\n",
      "\u001b[1m 288/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:59\u001b[0m 5s/step - accuracy: 0.3193 - loss: 10.9720 getitem, batch_nr 289 train is: True\n",
      "\u001b[1m 289/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:54\u001b[0m 5s/step - accuracy: 0.3191 - loss: 10.9749 getitem, batch_nr 290 train is: True\n",
      "\u001b[1m 290/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:48\u001b[0m 5s/step - accuracy: 0.3189 - loss: 10.9776 getitem, batch_nr 291 train is: True\n",
      "\u001b[1m 291/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:43\u001b[0m 5s/step - accuracy: 0.3188 - loss: 10.9802 getitem, batch_nr 292 train is: True\n",
      "\u001b[1m 292/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:38\u001b[0m 5s/step - accuracy: 0.3186 - loss: 10.9826 getitem, batch_nr 293 train is: True\n",
      "\u001b[1m 293/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:33\u001b[0m 5s/step - accuracy: 0.3185 - loss: 10.9849 getitem, batch_nr 294 train is: True\n",
      "\u001b[1m 294/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:27\u001b[0m 5s/step - accuracy: 0.3183 - loss: 10.9870 getitem, batch_nr 295 train is: True\n",
      "\u001b[1m 295/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:22\u001b[0m 5s/step - accuracy: 0.3182 - loss: 10.9890 getitem, batch_nr 296 train is: True\n",
      "\u001b[1m 296/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:17\u001b[0m 5s/step - accuracy: 0.3181 - loss: 10.9908 getitem, batch_nr 297 train is: True\n",
      "\u001b[1m 297/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:11\u001b[0m 5s/step - accuracy: 0.3180 - loss: 10.9925 getitem, batch_nr 298 train is: True\n",
      "\u001b[1m 298/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:05\u001b[0m 5s/step - accuracy: 0.3179 - loss: 10.9941 getitem, batch_nr 299 train is: True\n",
      "\u001b[1m 299/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:00\u001b[0m 5s/step - accuracy: 0.3178 - loss: 10.9955 getitem, batch_nr 300 train is: True\n",
      "\u001b[1m 300/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:54\u001b[0m 5s/step - accuracy: 0.3177 - loss: 10.9968 getitem, batch_nr 301 train is: True\n",
      "\u001b[1m 301/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:49\u001b[0m 5s/step - accuracy: 0.3177 - loss: 10.9979 getitem, batch_nr 302 train is: True\n",
      "\u001b[1m 302/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:43\u001b[0m 5s/step - accuracy: 0.3176 - loss: 10.9989 getitem, batch_nr 303 train is: True\n",
      "\u001b[1m 303/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:38\u001b[0m 5s/step - accuracy: 0.3176 - loss: 10.9998 getitem, batch_nr 304 train is: True\n",
      "\u001b[1m 304/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:32\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0005 getitem, batch_nr 305 train is: True\n",
      "\u001b[1m 305/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:27\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0011 getitem, batch_nr 306 train is: True\n",
      "\u001b[1m 306/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:21\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0016 getitem, batch_nr 307 train is: True\n",
      "\u001b[1m 307/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:15\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0020 getitem, batch_nr 308 train is: True\n",
      "\u001b[1m 308/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:10\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0023 getitem, batch_nr 309 train is: True\n",
      "\u001b[1m 309/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:04\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0024 getitem, batch_nr 310 train is: True\n",
      "\u001b[1m 310/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:59\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0024 getitem, batch_nr 311 train is: True\n",
      "\u001b[1m 311/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:53\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 312 train is: True\n",
      "\u001b[1m 312/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:48\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 313 train is: True\n",
      "\u001b[1m 313/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:42\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 314 train is: True\n",
      "\u001b[1m 314/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:37\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 315 train is: True\n",
      "\u001b[1m 315/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:32\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 316 train is: True\n",
      "\u001b[1m 316/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:26\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 317 train is: True\n",
      "\u001b[1m 317/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:21\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 318 train is: True\n",
      "\u001b[1m 318/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:15\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 319 train is: True\n",
      "\u001b[1m 319/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:10\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 320 train is: True\n",
      "\u001b[1m 320/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:04\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 321 train is: True\n",
      "\u001b[1m 321/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:59\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 322 train is: True\n",
      "\u001b[1m 322/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:55\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 323 train is: True\n",
      "\u001b[1m 323/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:49\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 324 train is: True\n",
      "\u001b[1m 324/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:44\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 325 train is: True\n",
      "\u001b[1m 325/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:39\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 326 train is: True\n",
      "\u001b[1m 326/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:33\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 327 train is: True\n",
      "\u001b[1m 327/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:28\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 328 train is: True\n",
      "\u001b[1m 328/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:23\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 329 train is: True\n",
      "\u001b[1m 329/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:18\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 330 train is: True\n",
      "\u001b[1m 330/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:14\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 331 train is: True\n",
      "\u001b[1m 331/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:08\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 332 train is: True\n",
      "\u001b[1m 332/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:03\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 333 train is: True\n",
      "\u001b[1m 333/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:58\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0026 getitem, batch_nr 334 train is: True\n",
      "\u001b[1m 334/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:52\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 335 train is: True\n",
      "\u001b[1m 335/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:47\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0025 getitem, batch_nr 336 train is: True\n",
      "\u001b[1m 336/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:41\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0024 getitem, batch_nr 337 train is: True\n",
      "\u001b[1m 337/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:36\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0023 getitem, batch_nr 338 train is: True\n",
      "\u001b[1m 338/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:31\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0022 getitem, batch_nr 339 train is: True\n",
      "\u001b[1m 339/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:26\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0021 getitem, batch_nr 340 train is: True\n",
      "\u001b[1m 340/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:21\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0020 getitem, batch_nr 341 train is: True\n",
      "\u001b[1m 341/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:17\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0019 getitem, batch_nr 342 train is: True\n",
      "\u001b[1m 342/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:13\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0018 getitem, batch_nr 343 train is: True\n",
      "\u001b[1m 343/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:09\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0017 getitem, batch_nr 344 train is: True\n",
      "\u001b[1m 344/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:04\u001b[0m 5s/step - accuracy: 0.3174 - loss: 11.0015 getitem, batch_nr 345 train is: True\n",
      "\u001b[1m 345/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:59\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0013 getitem, batch_nr 346 train is: True\n",
      "\u001b[1m 346/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:54\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0011 getitem, batch_nr 347 train is: True\n",
      "\u001b[1m 347/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:49\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0008 getitem, batch_nr 348 train is: True\n",
      "\u001b[1m 348/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:43\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0005 getitem, batch_nr 349 train is: True\n",
      "\u001b[1m 349/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:38\u001b[0m 5s/step - accuracy: 0.3175 - loss: 11.0002 getitem, batch_nr 350 train is: True\n",
      "\u001b[1m 350/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:33\u001b[0m 5s/step - accuracy: 0.3175 - loss: 10.9998 getitem, batch_nr 351 train is: True\n",
      "\u001b[1m 351/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:27\u001b[0m 5s/step - accuracy: 0.3176 - loss: 10.9994 getitem, batch_nr 352 train is: True\n",
      "\u001b[1m 352/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:22\u001b[0m 5s/step - accuracy: 0.3176 - loss: 10.9990 getitem, batch_nr 353 train is: True\n",
      "\u001b[1m 353/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:17\u001b[0m 5s/step - accuracy: 0.3176 - loss: 10.9986 getitem, batch_nr 354 train is: True\n",
      "\u001b[1m 354/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:12\u001b[0m 5s/step - accuracy: 0.3177 - loss: 10.9981 getitem, batch_nr 355 train is: True\n",
      "\u001b[1m 355/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:07\u001b[0m 5s/step - accuracy: 0.3177 - loss: 10.9976 getitem, batch_nr 356 train is: True\n",
      "\u001b[1m 356/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:02\u001b[0m 5s/step - accuracy: 0.3177 - loss: 10.9971 getitem, batch_nr 357 train is: True\n",
      "\u001b[1m 357/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:57\u001b[0m 5s/step - accuracy: 0.3178 - loss: 10.9965 getitem, batch_nr 358 train is: True\n",
      "\u001b[1m 358/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:52\u001b[0m 5s/step - accuracy: 0.3178 - loss: 10.9960 getitem, batch_nr 359 train is: True\n",
      "\u001b[1m 359/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:47\u001b[0m 5s/step - accuracy: 0.3178 - loss: 10.9954 getitem, batch_nr 360 train is: True\n",
      "\u001b[1m 360/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:41\u001b[0m 5s/step - accuracy: 0.3179 - loss: 10.9948 getitem, batch_nr 361 train is: True\n",
      "\u001b[1m 361/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:36\u001b[0m 5s/step - accuracy: 0.3179 - loss: 10.9942 getitem, batch_nr 362 train is: True\n",
      "\u001b[1m 362/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:31\u001b[0m 5s/step - accuracy: 0.3179 - loss: 10.9936 getitem, batch_nr 363 train is: True\n",
      "\u001b[1m 363/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:26\u001b[0m 5s/step - accuracy: 0.3180 - loss: 10.9930 getitem, batch_nr 364 train is: True\n",
      "\u001b[1m 364/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:20\u001b[0m 5s/step - accuracy: 0.3180 - loss: 10.9923 getitem, batch_nr 365 train is: True\n",
      "\u001b[1m 365/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:15\u001b[0m 5s/step - accuracy: 0.3181 - loss: 10.9916 getitem, batch_nr 366 train is: True\n",
      "\u001b[1m 366/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:10\u001b[0m 5s/step - accuracy: 0.3181 - loss: 10.9908 getitem, batch_nr 367 train is: True\n",
      "\u001b[1m 367/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:05\u001b[0m 5s/step - accuracy: 0.3182 - loss: 10.9900 getitem, batch_nr 368 train is: True\n",
      "\u001b[1m 368/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:59\u001b[0m 5s/step - accuracy: 0.3182 - loss: 10.9892 getitem, batch_nr 369 train is: True\n",
      "\u001b[1m 369/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:54\u001b[0m 5s/step - accuracy: 0.3183 - loss: 10.9884 getitem, batch_nr 370 train is: True\n",
      "\u001b[1m 370/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:49\u001b[0m 5s/step - accuracy: 0.3183 - loss: 10.9875 getitem, batch_nr 371 train is: True\n",
      "\u001b[1m 371/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:44\u001b[0m 5s/step - accuracy: 0.3184 - loss: 10.9867 getitem, batch_nr 372 train is: True\n",
      "\u001b[1m 372/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:39\u001b[0m 5s/step - accuracy: 0.3184 - loss: 10.9857 getitem, batch_nr 373 train is: True\n",
      "\u001b[1m 373/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:33\u001b[0m 5s/step - accuracy: 0.3185 - loss: 10.9848 getitem, batch_nr 374 train is: True\n",
      "\u001b[1m 374/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:28\u001b[0m 5s/step - accuracy: 0.3185 - loss: 10.9838 getitem, batch_nr 375 train is: True\n",
      "\u001b[1m 375/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:23\u001b[0m 5s/step - accuracy: 0.3186 - loss: 10.9828 getitem, batch_nr 376 train is: True\n",
      "\u001b[1m 376/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:18\u001b[0m 5s/step - accuracy: 0.3187 - loss: 10.9818 getitem, batch_nr 377 train is: True\n",
      "\u001b[1m 377/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:13\u001b[0m 5s/step - accuracy: 0.3187 - loss: 10.9807 getitem, batch_nr 378 train is: True\n",
      "\u001b[1m 378/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:07\u001b[0m 5s/step - accuracy: 0.3188 - loss: 10.9796 getitem, batch_nr 379 train is: True\n",
      "\u001b[1m 379/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:02\u001b[0m 5s/step - accuracy: 0.3189 - loss: 10.9785 getitem, batch_nr 380 train is: True\n",
      "\u001b[1m 380/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:57\u001b[0m 5s/step - accuracy: 0.3189 - loss: 10.9773 getitem, batch_nr 381 train is: True\n",
      "\u001b[1m 381/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:51\u001b[0m 5s/step - accuracy: 0.3190 - loss: 10.9761 getitem, batch_nr 382 train is: True\n",
      "\u001b[1m 382/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:46\u001b[0m 5s/step - accuracy: 0.3191 - loss: 10.9749 getitem, batch_nr 383 train is: True\n",
      "\u001b[1m 383/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:41\u001b[0m 5s/step - accuracy: 0.3192 - loss: 10.9737 getitem, batch_nr 384 train is: True\n",
      "\u001b[1m 384/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:36\u001b[0m 5s/step - accuracy: 0.3192 - loss: 10.9726 getitem, batch_nr 385 train is: True\n",
      "\u001b[1m 385/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:31\u001b[0m 5s/step - accuracy: 0.3193 - loss: 10.9714 getitem, batch_nr 386 train is: True\n",
      "\u001b[1m 386/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:26\u001b[0m 5s/step - accuracy: 0.3194 - loss: 10.9703 getitem, batch_nr 387 train is: True\n",
      "\u001b[1m 387/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:21\u001b[0m 5s/step - accuracy: 0.3195 - loss: 10.9692 getitem, batch_nr 388 train is: True\n",
      "\u001b[1m 388/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:15\u001b[0m 5s/step - accuracy: 0.3195 - loss: 10.9681 getitem, batch_nr 389 train is: True\n",
      "\u001b[1m 389/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:10\u001b[0m 5s/step - accuracy: 0.3196 - loss: 10.9669 getitem, batch_nr 390 train is: True\n",
      "\u001b[1m 390/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:05\u001b[0m 5s/step - accuracy: 0.3197 - loss: 10.9657 getitem, batch_nr 391 train is: True\n",
      "\u001b[1m 391/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:00\u001b[0m 5s/step - accuracy: 0.3197 - loss: 10.9646 getitem, batch_nr 392 train is: True\n",
      "\u001b[1m 392/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:55\u001b[0m 5s/step - accuracy: 0.3198 - loss: 10.9634 getitem, batch_nr 393 train is: True\n",
      "\u001b[1m 393/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:50\u001b[0m 5s/step - accuracy: 0.3199 - loss: 10.9622 getitem, batch_nr 394 train is: True\n",
      "\u001b[1m 394/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:45\u001b[0m 5s/step - accuracy: 0.3200 - loss: 10.9609 getitem, batch_nr 395 train is: True\n",
      "\u001b[1m 395/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:39\u001b[0m 5s/step - accuracy: 0.3200 - loss: 10.9597 getitem, batch_nr 396 train is: True\n",
      "\u001b[1m 396/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:34\u001b[0m 5s/step - accuracy: 0.3201 - loss: 10.9584 getitem, batch_nr 397 train is: True\n",
      "\u001b[1m 397/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:29\u001b[0m 5s/step - accuracy: 0.3202 - loss: 10.9571 getitem, batch_nr 398 train is: True\n",
      "\u001b[1m 398/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:24\u001b[0m 5s/step - accuracy: 0.3203 - loss: 10.9558 getitem, batch_nr 399 train is: True\n",
      "\u001b[1m 399/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:19\u001b[0m 5s/step - accuracy: 0.3204 - loss: 10.9545 getitem, batch_nr 400 train is: True\n",
      "\u001b[1m 400/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:14\u001b[0m 5s/step - accuracy: 0.3204 - loss: 10.9531 getitem, batch_nr 401 train is: True\n",
      "\u001b[1m 401/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:08\u001b[0m 5s/step - accuracy: 0.3205 - loss: 10.9518 getitem, batch_nr 402 train is: True\n",
      "\u001b[1m 402/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:03\u001b[0m 5s/step - accuracy: 0.3206 - loss: 10.9504 getitem, batch_nr 403 train is: True\n",
      "\u001b[1m 403/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:58\u001b[0m 5s/step - accuracy: 0.3207 - loss: 10.9490 getitem, batch_nr 404 train is: True\n",
      "\u001b[1m 404/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:52\u001b[0m 5s/step - accuracy: 0.3208 - loss: 10.9476 getitem, batch_nr 405 train is: True\n",
      "\u001b[1m 405/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:47\u001b[0m 5s/step - accuracy: 0.3209 - loss: 10.9462 getitem, batch_nr 406 train is: True\n",
      "\u001b[1m 406/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:42\u001b[0m 5s/step - accuracy: 0.3210 - loss: 10.9447 getitem, batch_nr 407 train is: True\n",
      "\u001b[1m 407/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:37\u001b[0m 5s/step - accuracy: 0.3211 - loss: 10.9433 getitem, batch_nr 408 train is: True\n",
      "\u001b[1m 408/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:32\u001b[0m 5s/step - accuracy: 0.3211 - loss: 10.9418 getitem, batch_nr 409 train is: True\n",
      "\u001b[1m 409/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:27\u001b[0m 5s/step - accuracy: 0.3212 - loss: 10.9404 getitem, batch_nr 410 train is: True\n",
      "\u001b[1m 410/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:21\u001b[0m 5s/step - accuracy: 0.3213 - loss: 10.9389 getitem, batch_nr 411 train is: True\n",
      "\u001b[1m 411/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:16\u001b[0m 5s/step - accuracy: 0.3214 - loss: 10.9374 getitem, batch_nr 412 train is: True\n",
      "\u001b[1m 412/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:11\u001b[0m 5s/step - accuracy: 0.3215 - loss: 10.9358 getitem, batch_nr 413 train is: True\n",
      "\u001b[1m 413/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:06\u001b[0m 5s/step - accuracy: 0.3216 - loss: 10.9342 getitem, batch_nr 414 train is: True\n",
      "\u001b[1m 414/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:01\u001b[0m 5s/step - accuracy: 0.3217 - loss: 10.9327 getitem, batch_nr 415 train is: True\n",
      "\u001b[1m 415/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:56\u001b[0m 5s/step - accuracy: 0.3218 - loss: 10.9311 getitem, batch_nr 416 train is: True\n",
      "\u001b[1m 416/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:51\u001b[0m 5s/step - accuracy: 0.3219 - loss: 10.9295 getitem, batch_nr 417 train is: True\n",
      "\u001b[1m 417/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:45\u001b[0m 5s/step - accuracy: 0.3220 - loss: 10.9279 getitem, batch_nr 418 train is: True\n",
      "\u001b[1m 418/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:40\u001b[0m 5s/step - accuracy: 0.3221 - loss: 10.9262 getitem, batch_nr 419 train is: True\n",
      "\u001b[1m 419/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:35\u001b[0m 5s/step - accuracy: 0.3222 - loss: 10.9246 getitem, batch_nr 420 train is: True\n",
      "\u001b[1m 420/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:30\u001b[0m 5s/step - accuracy: 0.3223 - loss: 10.9229 getitem, batch_nr 421 train is: True\n",
      "\u001b[1m 421/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:25\u001b[0m 5s/step - accuracy: 0.3224 - loss: 10.9212 getitem, batch_nr 422 train is: True\n",
      "\u001b[1m 422/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:20\u001b[0m 5s/step - accuracy: 0.3225 - loss: 10.9195 getitem, batch_nr 423 train is: True\n",
      "\u001b[1m 423/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:15\u001b[0m 5s/step - accuracy: 0.3226 - loss: 10.9177 getitem, batch_nr 424 train is: True\n",
      "\u001b[1m 424/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:10\u001b[0m 5s/step - accuracy: 0.3228 - loss: 10.9160 getitem, batch_nr 425 train is: True\n",
      "\u001b[1m 425/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:04\u001b[0m 5s/step - accuracy: 0.3229 - loss: 10.9142 getitem, batch_nr 426 train is: True\n",
      "\u001b[1m 426/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:59\u001b[0m 5s/step - accuracy: 0.3230 - loss: 10.9124 getitem, batch_nr 427 train is: True\n",
      "\u001b[1m 427/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:54\u001b[0m 5s/step - accuracy: 0.3231 - loss: 10.9106 getitem, batch_nr 428 train is: True\n",
      "\u001b[1m 428/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:49\u001b[0m 5s/step - accuracy: 0.3232 - loss: 10.9088 getitem, batch_nr 429 train is: True\n",
      "\u001b[1m 429/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:43\u001b[0m 5s/step - accuracy: 0.3233 - loss: 10.9069 getitem, batch_nr 430 train is: True\n",
      "\u001b[1m 430/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:38\u001b[0m 5s/step - accuracy: 0.3234 - loss: 10.9051 getitem, batch_nr 431 train is: True\n",
      "\u001b[1m 431/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:33\u001b[0m 5s/step - accuracy: 0.3235 - loss: 10.9033 getitem, batch_nr 432 train is: True\n",
      "\u001b[1m 432/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:28\u001b[0m 5s/step - accuracy: 0.3237 - loss: 10.9014 getitem, batch_nr 433 train is: True\n",
      "\u001b[1m 433/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:23\u001b[0m 5s/step - accuracy: 0.3238 - loss: 10.8996 getitem, batch_nr 434 train is: True\n",
      "\u001b[1m 434/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:18\u001b[0m 5s/step - accuracy: 0.3239 - loss: 10.8977 getitem, batch_nr 435 train is: True\n",
      "\u001b[1m 435/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:13\u001b[0m 5s/step - accuracy: 0.3240 - loss: 10.8958 getitem, batch_nr 436 train is: True\n",
      "\u001b[1m 436/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:07\u001b[0m 5s/step - accuracy: 0.3241 - loss: 10.8939 getitem, batch_nr 437 train is: True\n",
      "\u001b[1m 437/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:02\u001b[0m 5s/step - accuracy: 0.3242 - loss: 10.8920 getitem, batch_nr 438 train is: True\n",
      "\u001b[1m 438/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:57\u001b[0m 5s/step - accuracy: 0.3244 - loss: 10.8901 getitem, batch_nr 439 train is: True\n",
      "\u001b[1m 439/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:52\u001b[0m 5s/step - accuracy: 0.3245 - loss: 10.8881 getitem, batch_nr 440 train is: True\n",
      "\u001b[1m 440/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:47\u001b[0m 5s/step - accuracy: 0.3246 - loss: 10.8862 getitem, batch_nr 441 train is: True\n",
      "\u001b[1m 441/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:42\u001b[0m 5s/step - accuracy: 0.3247 - loss: 10.8842 getitem, batch_nr 442 train is: True\n",
      "\u001b[1m 442/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:37\u001b[0m 5s/step - accuracy: 0.3248 - loss: 10.8821 getitem, batch_nr 443 train is: True\n",
      "\u001b[1m 443/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:32\u001b[0m 5s/step - accuracy: 0.3250 - loss: 10.8801 getitem, batch_nr 444 train is: True\n",
      "\u001b[1m 444/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:26\u001b[0m 5s/step - accuracy: 0.3251 - loss: 10.8780 getitem, batch_nr 445 train is: True\n",
      "\u001b[1m 445/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:21\u001b[0m 5s/step - accuracy: 0.3252 - loss: 10.8760 getitem, batch_nr 446 train is: True\n",
      "\u001b[1m 446/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:16\u001b[0m 5s/step - accuracy: 0.3254 - loss: 10.8739 getitem, batch_nr 447 train is: True\n",
      "\u001b[1m 447/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:11\u001b[0m 5s/step - accuracy: 0.3255 - loss: 10.8718 getitem, batch_nr 448 train is: True\n",
      "\u001b[1m 448/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:06\u001b[0m 5s/step - accuracy: 0.3256 - loss: 10.8697 getitem, batch_nr 449 train is: True\n",
      "\u001b[1m 449/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:00\u001b[0m 5s/step - accuracy: 0.3258 - loss: 10.8675 getitem, batch_nr 450 train is: True\n",
      "\u001b[1m 450/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:55\u001b[0m 5s/step - accuracy: 0.3259 - loss: 10.8654 getitem, batch_nr 451 train is: True\n",
      "\u001b[1m 451/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:50\u001b[0m 5s/step - accuracy: 0.3260 - loss: 10.8632 getitem, batch_nr 452 train is: True\n",
      "\u001b[1m 452/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:45\u001b[0m 5s/step - accuracy: 0.3262 - loss: 10.8611 getitem, batch_nr 453 train is: True\n",
      "\u001b[1m 453/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:40\u001b[0m 5s/step - accuracy: 0.3263 - loss: 10.8589 getitem, batch_nr 454 train is: True\n",
      "\u001b[1m 454/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:35\u001b[0m 5s/step - accuracy: 0.3264 - loss: 10.8567 getitem, batch_nr 455 train is: True\n",
      "\u001b[1m 455/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:30\u001b[0m 5s/step - accuracy: 0.3266 - loss: 10.8545 getitem, batch_nr 456 train is: True\n",
      "\u001b[1m 456/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:25\u001b[0m 5s/step - accuracy: 0.3267 - loss: 10.8523 getitem, batch_nr 457 train is: True\n",
      "\u001b[1m 457/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:19\u001b[0m 5s/step - accuracy: 0.3268 - loss: 10.8501 getitem, batch_nr 458 train is: True\n",
      "\u001b[1m 458/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:14\u001b[0m 5s/step - accuracy: 0.3270 - loss: 10.8478 getitem, batch_nr 459 train is: True\n",
      "\u001b[1m 459/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:09\u001b[0m 5s/step - accuracy: 0.3271 - loss: 10.8456 getitem, batch_nr 460 train is: True\n",
      "\u001b[1m 460/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:05\u001b[0m 5s/step - accuracy: 0.3273 - loss: 10.8434 getitem, batch_nr 461 train is: True\n",
      "\u001b[1m 461/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:00\u001b[0m 5s/step - accuracy: 0.3274 - loss: 10.8412 getitem, batch_nr 462 train is: True\n",
      "\u001b[1m 462/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:55\u001b[0m 5s/step - accuracy: 0.3275 - loss: 10.8390 getitem, batch_nr 463 train is: True\n",
      "\u001b[1m 463/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:50\u001b[0m 5s/step - accuracy: 0.3277 - loss: 10.8368 getitem, batch_nr 464 train is: True\n",
      "\u001b[1m 464/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:45\u001b[0m 5s/step - accuracy: 0.3278 - loss: 10.8347 getitem, batch_nr 465 train is: True\n",
      "\u001b[1m 465/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:40\u001b[0m 5s/step - accuracy: 0.3279 - loss: 10.8326 getitem, batch_nr 466 train is: True\n",
      "\u001b[1m 466/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:34\u001b[0m 5s/step - accuracy: 0.3281 - loss: 10.8305 getitem, batch_nr 467 train is: True\n",
      "\u001b[1m 467/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:29\u001b[0m 5s/step - accuracy: 0.3282 - loss: 10.8284 getitem, batch_nr 468 train is: True\n",
      "\u001b[1m 468/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:24\u001b[0m 5s/step - accuracy: 0.3283 - loss: 10.8263 getitem, batch_nr 469 train is: True\n",
      "\u001b[1m 469/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:19\u001b[0m 5s/step - accuracy: 0.3284 - loss: 10.8242 getitem, batch_nr 470 train is: True\n",
      "\u001b[1m 470/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:13\u001b[0m 5s/step - accuracy: 0.3286 - loss: 10.8222 getitem, batch_nr 471 train is: True\n",
      "\u001b[1m 471/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:09\u001b[0m 5s/step - accuracy: 0.3287 - loss: 10.8202 getitem, batch_nr 472 train is: True\n",
      "\u001b[1m 472/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:03\u001b[0m 5s/step - accuracy: 0.3288 - loss: 10.8182 getitem, batch_nr 473 train is: True\n",
      "\u001b[1m 473/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:58\u001b[0m 5s/step - accuracy: 0.3289 - loss: 10.8162 getitem, batch_nr 474 train is: True\n",
      "\u001b[1m 474/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:53\u001b[0m 5s/step - accuracy: 0.3291 - loss: 10.8142 getitem, batch_nr 475 train is: True\n",
      "\u001b[1m 475/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:48\u001b[0m 5s/step - accuracy: 0.3292 - loss: 10.8123 getitem, batch_nr 476 train is: True\n",
      "\u001b[1m 476/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:43\u001b[0m 5s/step - accuracy: 0.3293 - loss: 10.8104 getitem, batch_nr 477 train is: True\n",
      "fill_time_length_dimension_called\n",
      "\u001b[1m 477/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:37\u001b[0m 5s/step - accuracy: 0.3294 - loss: 10.8085 getitem, batch_nr 478 train is: True\n",
      "\u001b[1m 478/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:32\u001b[0m 5s/step - accuracy: 0.3295 - loss: 10.8066 getitem, batch_nr 479 train is: True\n",
      "\u001b[1m 479/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:27\u001b[0m 5s/step - accuracy: 0.3297 - loss: 10.8047 getitem, batch_nr 480 train is: True\n",
      "\u001b[1m 480/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:21\u001b[0m 5s/step - accuracy: 0.3298 - loss: 10.8028 getitem, batch_nr 481 train is: True\n",
      "\u001b[1m 481/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:16\u001b[0m 5s/step - accuracy: 0.3299 - loss: 10.8009 getitem, batch_nr 482 train is: True\n",
      "\u001b[1m 482/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:11\u001b[0m 5s/step - accuracy: 0.3300 - loss: 10.7991 getitem, batch_nr 483 train is: True\n",
      "\u001b[1m 483/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:06\u001b[0m 5s/step - accuracy: 0.3301 - loss: 10.7972 getitem, batch_nr 484 train is: True\n",
      "\u001b[1m 484/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:00\u001b[0m 5s/step - accuracy: 0.3302 - loss: 10.7954 getitem, batch_nr 485 train is: True\n",
      "\u001b[1m 485/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:55\u001b[0m 5s/step - accuracy: 0.3303 - loss: 10.7935 getitem, batch_nr 486 train is: True\n",
      "\u001b[1m 486/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:50\u001b[0m 5s/step - accuracy: 0.3305 - loss: 10.7916 getitem, batch_nr 487 train is: True\n",
      "\u001b[1m 487/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:45\u001b[0m 5s/step - accuracy: 0.3306 - loss: 10.7898 getitem, batch_nr 488 train is: True\n",
      "\u001b[1m 488/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:40\u001b[0m 5s/step - accuracy: 0.3307 - loss: 10.7879 getitem, batch_nr 489 train is: True\n",
      "\u001b[1m 489/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:35\u001b[0m 5s/step - accuracy: 0.3308 - loss: 10.7861 getitem, batch_nr 490 train is: True\n",
      "\u001b[1m 490/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:30\u001b[0m 5s/step - accuracy: 0.3309 - loss: 10.7843 getitem, batch_nr 491 train is: True\n",
      "\u001b[1m 491/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:24\u001b[0m 5s/step - accuracy: 0.3310 - loss: 10.7824 getitem, batch_nr 492 train is: True\n",
      "\u001b[1m 492/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:19\u001b[0m 5s/step - accuracy: 0.3311 - loss: 10.7806 getitem, batch_nr 493 train is: True\n",
      "\u001b[1m 493/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:14\u001b[0m 5s/step - accuracy: 0.3313 - loss: 10.7788 getitem, batch_nr 494 train is: True\n",
      "\u001b[1m 494/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:09\u001b[0m 5s/step - accuracy: 0.3314 - loss: 10.7770 getitem, batch_nr 495 train is: True\n",
      "\u001b[1m 495/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:04\u001b[0m 5s/step - accuracy: 0.3315 - loss: 10.7752 getitem, batch_nr 496 train is: True\n",
      "\u001b[1m 496/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:59\u001b[0m 5s/step - accuracy: 0.3316 - loss: 10.7735 getitem, batch_nr 497 train is: True\n",
      "\u001b[1m 497/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:53\u001b[0m 5s/step - accuracy: 0.3317 - loss: 10.7717 getitem, batch_nr 498 train is: True\n",
      "\u001b[1m 498/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:48\u001b[0m 5s/step - accuracy: 0.3318 - loss: 10.7699 getitem, batch_nr 499 train is: True\n",
      "\u001b[1m 499/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:43\u001b[0m 5s/step - accuracy: 0.3319 - loss: 10.7681 getitem, batch_nr 500 train is: True\n",
      "\u001b[1m 500/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:37\u001b[0m 5s/step - accuracy: 0.3320 - loss: 10.7663 getitem, batch_nr 501 train is: True\n",
      "\u001b[1m 501/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:32\u001b[0m 5s/step - accuracy: 0.3322 - loss: 10.7645 getitem, batch_nr 502 train is: True\n",
      "\u001b[1m 502/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:27\u001b[0m 5s/step - accuracy: 0.3323 - loss: 10.7627 getitem, batch_nr 503 train is: True\n",
      "\u001b[1m 503/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:22\u001b[0m 5s/step - accuracy: 0.3324 - loss: 10.7608 getitem, batch_nr 504 train is: True\n",
      "\u001b[1m 504/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:17\u001b[0m 5s/step - accuracy: 0.3325 - loss: 10.7590 getitem, batch_nr 505 train is: True\n",
      "\u001b[1m 505/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:12\u001b[0m 5s/step - accuracy: 0.3326 - loss: 10.7572 getitem, batch_nr 506 train is: True\n",
      "\u001b[1m 506/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:06\u001b[0m 5s/step - accuracy: 0.3327 - loss: 10.7554 getitem, batch_nr 507 train is: True\n",
      "\u001b[1m 507/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:01\u001b[0m 5s/step - accuracy: 0.3328 - loss: 10.7536 getitem, batch_nr 508 train is: True\n",
      "\u001b[1m 508/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:56\u001b[0m 5s/step - accuracy: 0.3329 - loss: 10.7517 getitem, batch_nr 509 train is: True\n",
      "\u001b[1m 509/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:51\u001b[0m 5s/step - accuracy: 0.3331 - loss: 10.7499 getitem, batch_nr 510 train is: True\n",
      "\u001b[1m 510/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:46\u001b[0m 5s/step - accuracy: 0.3332 - loss: 10.7481 getitem, batch_nr 511 train is: True\n",
      "\u001b[1m 511/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:40\u001b[0m 5s/step - accuracy: 0.3333 - loss: 10.7463 getitem, batch_nr 512 train is: True\n",
      "\u001b[1m 512/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:35\u001b[0m 5s/step - accuracy: 0.3334 - loss: 10.7445 getitem, batch_nr 513 train is: True\n",
      "\u001b[1m 513/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:30\u001b[0m 5s/step - accuracy: 0.3335 - loss: 10.7427 getitem, batch_nr 514 train is: True\n",
      "\u001b[1m 514/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:25\u001b[0m 5s/step - accuracy: 0.3336 - loss: 10.7409 getitem, batch_nr 515 train is: True\n",
      "\u001b[1m 515/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:19\u001b[0m 5s/step - accuracy: 0.3337 - loss: 10.7391 getitem, batch_nr 516 train is: True\n",
      "\u001b[1m 516/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:14\u001b[0m 5s/step - accuracy: 0.3338 - loss: 10.7373 getitem, batch_nr 517 train is: True\n",
      "\u001b[1m 517/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:09\u001b[0m 5s/step - accuracy: 0.3339 - loss: 10.7355 getitem, batch_nr 518 train is: True\n",
      "\u001b[1m 518/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:04\u001b[0m 5s/step - accuracy: 0.3341 - loss: 10.7337 getitem, batch_nr 519 train is: True\n",
      "\u001b[1m 519/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:58\u001b[0m 5s/step - accuracy: 0.3342 - loss: 10.7319 getitem, batch_nr 520 train is: True\n",
      "\u001b[1m 520/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:53\u001b[0m 5s/step - accuracy: 0.3343 - loss: 10.7300 getitem, batch_nr 521 train is: True\n",
      "\u001b[1m 521/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:48\u001b[0m 5s/step - accuracy: 0.3344 - loss: 10.7282 getitem, batch_nr 522 train is: True\n",
      "\u001b[1m 522/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:43\u001b[0m 5s/step - accuracy: 0.3345 - loss: 10.7264 getitem, batch_nr 523 train is: True\n",
      "\u001b[1m 523/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:38\u001b[0m 5s/step - accuracy: 0.3346 - loss: 10.7246 getitem, batch_nr 524 train is: True\n",
      "\u001b[1m 524/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:33\u001b[0m 5s/step - accuracy: 0.3347 - loss: 10.7227 getitem, batch_nr 525 train is: True\n",
      "\u001b[1m 525/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:27\u001b[0m 5s/step - accuracy: 0.3349 - loss: 10.7209 getitem, batch_nr 526 train is: True\n",
      "\u001b[1m 526/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:22\u001b[0m 5s/step - accuracy: 0.3350 - loss: 10.7191 getitem, batch_nr 527 train is: True\n",
      "\u001b[1m 527/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:17\u001b[0m 5s/step - accuracy: 0.3351 - loss: 10.7172 getitem, batch_nr 528 train is: True\n",
      "\u001b[1m 528/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:12\u001b[0m 5s/step - accuracy: 0.3352 - loss: 10.7154 getitem, batch_nr 529 train is: True\n",
      "\u001b[1m 529/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:07\u001b[0m 5s/step - accuracy: 0.3353 - loss: 10.7136 getitem, batch_nr 530 train is: True\n",
      "\u001b[1m 530/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:02\u001b[0m 5s/step - accuracy: 0.3354 - loss: 10.7118 getitem, batch_nr 531 train is: True\n",
      "\u001b[1m 531/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:57\u001b[0m 5s/step - accuracy: 0.3355 - loss: 10.7100 getitem, batch_nr 532 train is: True\n",
      "\u001b[1m 532/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:51\u001b[0m 5s/step - accuracy: 0.3356 - loss: 10.7082 getitem, batch_nr 533 train is: True\n",
      "\u001b[1m 533/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:46\u001b[0m 5s/step - accuracy: 0.3358 - loss: 10.7064 getitem, batch_nr 534 train is: True\n",
      "\u001b[1m 534/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:41\u001b[0m 5s/step - accuracy: 0.3359 - loss: 10.7046 getitem, batch_nr 535 train is: True\n",
      "\u001b[1m 535/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:36\u001b[0m 5s/step - accuracy: 0.3360 - loss: 10.7027 getitem, batch_nr 536 train is: True\n",
      "\u001b[1m 536/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:31\u001b[0m 5s/step - accuracy: 0.3361 - loss: 10.7009 getitem, batch_nr 537 train is: True\n",
      "\u001b[1m 537/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:26\u001b[0m 5s/step - accuracy: 0.3362 - loss: 10.6991 getitem, batch_nr 538 train is: True\n",
      "\u001b[1m 538/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:20\u001b[0m 5s/step - accuracy: 0.3363 - loss: 10.6972 getitem, batch_nr 539 train is: True\n",
      "\u001b[1m 539/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:15\u001b[0m 5s/step - accuracy: 0.3364 - loss: 10.6954 getitem, batch_nr 540 train is: True\n",
      "\u001b[1m 540/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:10\u001b[0m 5s/step - accuracy: 0.3365 - loss: 10.6936 getitem, batch_nr 541 train is: True\n",
      "\u001b[1m 541/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:05\u001b[0m 5s/step - accuracy: 0.3367 - loss: 10.6918 getitem, batch_nr 542 train is: True\n",
      "\u001b[1m 542/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:00\u001b[0m 5s/step - accuracy: 0.3368 - loss: 10.6900 getitem, batch_nr 543 train is: True\n",
      "\u001b[1m 543/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:54\u001b[0m 5s/step - accuracy: 0.3369 - loss: 10.6882 getitem, batch_nr 544 train is: True\n",
      "\u001b[1m 544/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:49\u001b[0m 5s/step - accuracy: 0.3370 - loss: 10.6864 getitem, batch_nr 545 train is: True\n",
      "\u001b[1m 545/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:44\u001b[0m 5s/step - accuracy: 0.3371 - loss: 10.6846 getitem, batch_nr 546 train is: True\n",
      "\u001b[1m 546/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:39\u001b[0m 5s/step - accuracy: 0.3372 - loss: 10.6828 getitem, batch_nr 547 train is: True\n",
      "\u001b[1m 547/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:34\u001b[0m 5s/step - accuracy: 0.3373 - loss: 10.6810 getitem, batch_nr 548 train is: True\n",
      "\u001b[1m 548/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:28\u001b[0m 5s/step - accuracy: 0.3374 - loss: 10.6792 getitem, batch_nr 549 train is: True\n",
      "\u001b[1m 549/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:23\u001b[0m 5s/step - accuracy: 0.3376 - loss: 10.6774 getitem, batch_nr 550 train is: True\n",
      "\u001b[1m 550/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:18\u001b[0m 5s/step - accuracy: 0.3377 - loss: 10.6756 getitem, batch_nr 551 train is: True\n",
      "\u001b[1m 551/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:13\u001b[0m 5s/step - accuracy: 0.3378 - loss: 10.6738 getitem, batch_nr 552 train is: True\n",
      "\u001b[1m 552/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:08\u001b[0m 5s/step - accuracy: 0.3379 - loss: 10.6720 getitem, batch_nr 553 train is: True\n",
      "\u001b[1m 553/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:03\u001b[0m 5s/step - accuracy: 0.3380 - loss: 10.6702 getitem, batch_nr 554 train is: True\n",
      "\u001b[1m 554/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:58\u001b[0m 5s/step - accuracy: 0.3381 - loss: 10.6684 getitem, batch_nr 555 train is: True\n",
      "\u001b[1m 555/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:53\u001b[0m 5s/step - accuracy: 0.3382 - loss: 10.6666 getitem, batch_nr 556 train is: True\n",
      "\u001b[1m 556/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:47\u001b[0m 5s/step - accuracy: 0.3383 - loss: 10.6648 getitem, batch_nr 557 train is: True\n",
      "\u001b[1m 557/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:42\u001b[0m 5s/step - accuracy: 0.3384 - loss: 10.6630 getitem, batch_nr 558 train is: True\n",
      "\u001b[1m 558/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:37\u001b[0m 5s/step - accuracy: 0.3386 - loss: 10.6612 getitem, batch_nr 559 train is: True\n",
      "\u001b[1m 559/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:32\u001b[0m 5s/step - accuracy: 0.3387 - loss: 10.6594 getitem, batch_nr 560 train is: True\n",
      "\u001b[1m 560/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:27\u001b[0m 5s/step - accuracy: 0.3388 - loss: 10.6576 getitem, batch_nr 561 train is: True\n",
      "\u001b[1m 561/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:22\u001b[0m 5s/step - accuracy: 0.3389 - loss: 10.6558 getitem, batch_nr 562 train is: True\n",
      "\u001b[1m 562/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:16\u001b[0m 5s/step - accuracy: 0.3390 - loss: 10.6540 getitem, batch_nr 563 train is: True\n",
      "\u001b[1m 563/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:11\u001b[0m 5s/step - accuracy: 0.3391 - loss: 10.6521 getitem, batch_nr 564 train is: True\n",
      "\u001b[1m 564/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:06\u001b[0m 5s/step - accuracy: 0.3392 - loss: 10.6503 getitem, batch_nr 565 train is: True\n",
      "\u001b[1m 565/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:01\u001b[0m 5s/step - accuracy: 0.3393 - loss: 10.6485 getitem, batch_nr 566 train is: True\n",
      "\u001b[1m 566/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:56\u001b[0m 5s/step - accuracy: 0.3395 - loss: 10.6467 getitem, batch_nr 567 train is: True\n",
      "\u001b[1m 567/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:51\u001b[0m 5s/step - accuracy: 0.3396 - loss: 10.6449 getitem, batch_nr 568 train is: True\n",
      "\u001b[1m 568/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:45\u001b[0m 5s/step - accuracy: 0.3397 - loss: 10.6430 getitem, batch_nr 569 train is: True\n",
      "\u001b[1m 569/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:40\u001b[0m 5s/step - accuracy: 0.3398 - loss: 10.6412 getitem, batch_nr 570 train is: True\n",
      "\u001b[1m 570/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:35\u001b[0m 5s/step - accuracy: 0.3399 - loss: 10.6394 getitem, batch_nr 571 train is: True\n",
      "\u001b[1m 571/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:30\u001b[0m 5s/step - accuracy: 0.3400 - loss: 10.6376 getitem, batch_nr 572 train is: True\n",
      "\u001b[1m 572/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:25\u001b[0m 5s/step - accuracy: 0.3401 - loss: 10.6357 getitem, batch_nr 573 train is: True\n",
      "\u001b[1m 573/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:20\u001b[0m 5s/step - accuracy: 0.3403 - loss: 10.6339 getitem, batch_nr 574 train is: True\n",
      "\u001b[1m 574/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:14\u001b[0m 5s/step - accuracy: 0.3404 - loss: 10.6320 getitem, batch_nr 575 train is: True\n",
      "\u001b[1m 575/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:09\u001b[0m 5s/step - accuracy: 0.3405 - loss: 10.6302 getitem, batch_nr 576 train is: True\n",
      "\u001b[1m 576/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:04\u001b[0m 5s/step - accuracy: 0.3406 - loss: 10.6284 getitem, batch_nr 577 train is: True\n",
      "\u001b[1m 577/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:59\u001b[0m 5s/step - accuracy: 0.3407 - loss: 10.6265 getitem, batch_nr 578 train is: True\n",
      "\u001b[1m 578/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:54\u001b[0m 5s/step - accuracy: 0.3408 - loss: 10.6247 getitem, batch_nr 579 train is: True\n",
      "\u001b[1m 579/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:49\u001b[0m 5s/step - accuracy: 0.3409 - loss: 10.6229 getitem, batch_nr 580 train is: True\n",
      "\u001b[1m 580/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:43\u001b[0m 5s/step - accuracy: 0.3410 - loss: 10.6210 getitem, batch_nr 581 train is: True\n",
      "\u001b[1m 581/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:38\u001b[0m 5s/step - accuracy: 0.3412 - loss: 10.6192 getitem, batch_nr 582 train is: True\n",
      "\u001b[1m 582/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:33\u001b[0m 5s/step - accuracy: 0.3413 - loss: 10.6174 getitem, batch_nr 583 train is: True\n",
      "\u001b[1m 583/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:28\u001b[0m 5s/step - accuracy: 0.3414 - loss: 10.6156 getitem, batch_nr 584 train is: True\n",
      "\u001b[1m 584/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:23\u001b[0m 5s/step - accuracy: 0.3415 - loss: 10.6138 getitem, batch_nr 585 train is: True\n",
      "\u001b[1m 585/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:18\u001b[0m 5s/step - accuracy: 0.3416 - loss: 10.6120 getitem, batch_nr 586 train is: True\n",
      "\u001b[1m 586/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:12\u001b[0m 5s/step - accuracy: 0.3417 - loss: 10.6102 getitem, batch_nr 587 train is: True\n",
      "\u001b[1m 587/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:07\u001b[0m 5s/step - accuracy: 0.3418 - loss: 10.6084 getitem, batch_nr 588 train is: True\n",
      "\u001b[1m 588/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:02\u001b[0m 5s/step - accuracy: 0.3419 - loss: 10.6066 getitem, batch_nr 589 train is: True\n",
      "\u001b[1m 589/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:01:57\u001b[0m 5s/step - accuracy: 0.3421 - loss: 10.6047 getitem, batch_nr 590 train is: True\n",
      "\u001b[1m 590/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:01:52\u001b[0m 5s/step - accuracy: 0.3422 - loss: 10.6029 getitem, batch_nr 591 train is: True\n",
      "\u001b[1m 591/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:01:46\u001b[0m 5s/step - accuracy: 0.3423 - loss: 10.6011 getitem, batch_nr 592 train is: True\n",
      "\u001b[1m 592/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:01:41\u001b[0m 5s/step - accuracy: 0.3424 - loss: 10.5993 getitem, batch_nr 593 train is: True\n",
      "\u001b[1m 593/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:36\u001b[0m 5s/step - accuracy: 0.3425 - loss: 10.5975 getitem, batch_nr 594 train is: True\n",
      "\u001b[1m 594/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:31\u001b[0m 5s/step - accuracy: 0.3426 - loss: 10.5956 getitem, batch_nr 595 train is: True\n",
      "\u001b[1m 595/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:26\u001b[0m 5s/step - accuracy: 0.3427 - loss: 10.5938 getitem, batch_nr 596 train is: True\n",
      "\u001b[1m 596/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:21\u001b[0m 5s/step - accuracy: 0.3428 - loss: 10.5920 getitem, batch_nr 597 train is: True\n",
      "\u001b[1m 597/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:15\u001b[0m 5s/step - accuracy: 0.3430 - loss: 10.5902 getitem, batch_nr 598 train is: True\n",
      "\u001b[1m 598/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:10\u001b[0m 5s/step - accuracy: 0.3431 - loss: 10.5884 getitem, batch_nr 599 train is: True\n",
      "\u001b[1m 599/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:05\u001b[0m 5s/step - accuracy: 0.3432 - loss: 10.5865 getitem, batch_nr 600 train is: True\n",
      "\u001b[1m 600/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:00\u001b[0m 5s/step - accuracy: 0.3433 - loss: 10.5847 getitem, batch_nr 601 train is: True\n",
      "\u001b[1m 601/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:55\u001b[0m 5s/step - accuracy: 0.3434 - loss: 10.5829 getitem, batch_nr 602 train is: True\n",
      "\u001b[1m 602/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:50\u001b[0m 5s/step - accuracy: 0.3435 - loss: 10.5811 getitem, batch_nr 603 train is: True\n",
      "\u001b[1m 603/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:45\u001b[0m 5s/step - accuracy: 0.3436 - loss: 10.5792 getitem, batch_nr 604 train is: True\n",
      "\u001b[1m 604/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:39\u001b[0m 5s/step - accuracy: 0.3438 - loss: 10.5774 getitem, batch_nr 605 train is: True\n",
      "\u001b[1m 605/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:34\u001b[0m 5s/step - accuracy: 0.3439 - loss: 10.5756 getitem, batch_nr 606 train is: True\n",
      "\u001b[1m 606/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:29\u001b[0m 5s/step - accuracy: 0.3440 - loss: 10.5737 getitem, batch_nr 607 train is: True\n",
      "\u001b[1m 607/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:24\u001b[0m 5s/step - accuracy: 0.3441 - loss: 10.5719 getitem, batch_nr 608 train is: True\n",
      "\u001b[1m 608/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:19\u001b[0m 5s/step - accuracy: 0.3442 - loss: 10.5701 getitem, batch_nr 609 train is: True\n",
      "\u001b[1m 609/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:14\u001b[0m 5s/step - accuracy: 0.3443 - loss: 10.5682 getitem, batch_nr 610 train is: True\n",
      "\u001b[1m 610/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:09\u001b[0m 5s/step - accuracy: 0.3444 - loss: 10.5664 getitem, batch_nr 611 train is: True\n",
      "\u001b[1m 611/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:03\u001b[0m 5s/step - accuracy: 0.3445 - loss: 10.5646 getitem, batch_nr 612 train is: True\n",
      "\u001b[1m 612/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:58\u001b[0m 5s/step - accuracy: 0.3447 - loss: 10.5628   getitem, batch_nr 613 train is: True\n",
      "\u001b[1m 613/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:53\u001b[0m 5s/step - accuracy: 0.3448 - loss: 10.5610 getitem, batch_nr 614 train is: True\n",
      "\u001b[1m 614/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:48\u001b[0m 5s/step - accuracy: 0.3449 - loss: 10.5592 getitem, batch_nr 615 train is: True\n",
      "\u001b[1m 615/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:43\u001b[0m 5s/step - accuracy: 0.3450 - loss: 10.5573 getitem, batch_nr 616 train is: True\n",
      "\u001b[1m 616/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:38\u001b[0m 5s/step - accuracy: 0.3451 - loss: 10.5555 getitem, batch_nr 617 train is: True\n",
      "\u001b[1m 617/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:32\u001b[0m 5s/step - accuracy: 0.3452 - loss: 10.5537 getitem, batch_nr 618 train is: True\n",
      "\u001b[1m 618/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:27\u001b[0m 5s/step - accuracy: 0.3453 - loss: 10.5519 getitem, batch_nr 619 train is: True\n",
      "\u001b[1m 619/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:22\u001b[0m 5s/step - accuracy: 0.3455 - loss: 10.5501 getitem, batch_nr 620 train is: True\n",
      "\u001b[1m 620/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:17\u001b[0m 5s/step - accuracy: 0.3456 - loss: 10.5483 getitem, batch_nr 621 train is: True\n",
      "\u001b[1m 621/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:12\u001b[0m 5s/step - accuracy: 0.3457 - loss: 10.5465 getitem, batch_nr 622 train is: True\n",
      "\u001b[1m 622/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:07\u001b[0m 5s/step - accuracy: 0.3458 - loss: 10.5446 getitem, batch_nr 623 train is: True\n",
      "\u001b[1m 623/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:01\u001b[0m 5s/step - accuracy: 0.3459 - loss: 10.5428 getitem, batch_nr 624 train is: True\n",
      "\u001b[1m 624/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:56\u001b[0m 5s/step - accuracy: 0.3460 - loss: 10.5410 getitem, batch_nr 625 train is: True\n",
      "\u001b[1m 625/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:51\u001b[0m 5s/step - accuracy: 0.3461 - loss: 10.5392 getitem, batch_nr 626 train is: True\n",
      "\u001b[1m 626/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:46\u001b[0m 5s/step - accuracy: 0.3462 - loss: 10.5374 getitem, batch_nr 627 train is: True\n",
      "\u001b[1m 627/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:41\u001b[0m 5s/step - accuracy: 0.3464 - loss: 10.5356 getitem, batch_nr 628 train is: True\n",
      "\u001b[1m 628/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:36\u001b[0m 5s/step - accuracy: 0.3465 - loss: 10.5338 getitem, batch_nr 629 train is: True\n",
      "\u001b[1m 629/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:30\u001b[0m 5s/step - accuracy: 0.3466 - loss: 10.5320 getitem, batch_nr 630 train is: True\n",
      "\u001b[1m 630/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:25\u001b[0m 5s/step - accuracy: 0.3467 - loss: 10.5301 getitem, batch_nr 631 train is: True\n",
      "\u001b[1m 631/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:20\u001b[0m 5s/step - accuracy: 0.3468 - loss: 10.5284 getitem, batch_nr 632 train is: True\n",
      "\u001b[1m 632/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:15\u001b[0m 5s/step - accuracy: 0.3469 - loss: 10.5266 getitem, batch_nr 633 train is: True\n",
      "\u001b[1m 633/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:10\u001b[0m 5s/step - accuracy: 0.3470 - loss: 10.5248 getitem, batch_nr 634 train is: True\n",
      "\u001b[1m 634/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:05\u001b[0m 5s/step - accuracy: 0.3471 - loss: 10.5230 getitem, batch_nr 635 train is: True\n",
      "\u001b[1m 635/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:00\u001b[0m 5s/step - accuracy: 0.3472 - loss: 10.5212 getitem, batch_nr 636 train is: True\n",
      "\u001b[1m 636/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:55\u001b[0m 5s/step - accuracy: 0.3474 - loss: 10.5194 getitem, batch_nr 637 train is: True\n",
      "\u001b[1m 637/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:50\u001b[0m 5s/step - accuracy: 0.3475 - loss: 10.5177 getitem, batch_nr 638 train is: True\n",
      "\u001b[1m 638/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:44\u001b[0m 5s/step - accuracy: 0.3476 - loss: 10.5159 getitem, batch_nr 639 train is: True\n",
      "\u001b[1m 639/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:39\u001b[0m 5s/step - accuracy: 0.3477 - loss: 10.5141 getitem, batch_nr 640 train is: True\n",
      "\u001b[1m 640/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:34\u001b[0m 5s/step - accuracy: 0.3478 - loss: 10.5123 getitem, batch_nr 641 train is: True\n",
      "\u001b[1m 641/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:29\u001b[0m 5s/step - accuracy: 0.3479 - loss: 10.5106 getitem, batch_nr 642 train is: True\n",
      "\u001b[1m 642/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:24\u001b[0m 5s/step - accuracy: 0.3480 - loss: 10.5088 getitem, batch_nr 643 train is: True\n",
      "\u001b[1m 643/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:19\u001b[0m 5s/step - accuracy: 0.3481 - loss: 10.5071 getitem, batch_nr 644 train is: True\n",
      "\u001b[1m 644/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:13\u001b[0m 5s/step - accuracy: 0.3482 - loss: 10.5053 getitem, batch_nr 645 train is: True\n",
      "\u001b[1m 645/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:08\u001b[0m 5s/step - accuracy: 0.3483 - loss: 10.5035 getitem, batch_nr 646 train is: True\n",
      "\u001b[1m 646/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:03\u001b[0m 5s/step - accuracy: 0.3484 - loss: 10.5018 getitem, batch_nr 647 train is: True\n",
      "\u001b[1m 647/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:58\u001b[0m 5s/step - accuracy: 0.3486 - loss: 10.5000 getitem, batch_nr 648 train is: True\n",
      "\u001b[1m 648/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:53\u001b[0m 5s/step - accuracy: 0.3487 - loss: 10.4983 getitem, batch_nr 649 train is: True\n",
      "\u001b[1m 649/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:48\u001b[0m 5s/step - accuracy: 0.3488 - loss: 10.4965 getitem, batch_nr 650 train is: True\n",
      "\u001b[1m 650/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:43\u001b[0m 5s/step - accuracy: 0.3489 - loss: 10.4948 getitem, batch_nr 651 train is: True\n",
      "\u001b[1m 651/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:38\u001b[0m 5s/step - accuracy: 0.3490 - loss: 10.4930 getitem, batch_nr 652 train is: True\n",
      "\u001b[1m 652/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:33\u001b[0m 5s/step - accuracy: 0.3491 - loss: 10.4912 getitem, batch_nr 653 train is: True\n",
      "\u001b[1m 653/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:27\u001b[0m 5s/step - accuracy: 0.3492 - loss: 10.4895 getitem, batch_nr 654 train is: True\n",
      "\u001b[1m 654/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:22\u001b[0m 5s/step - accuracy: 0.3493 - loss: 10.4877 getitem, batch_nr 655 train is: True\n",
      "\u001b[1m 655/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:17\u001b[0m 5s/step - accuracy: 0.3494 - loss: 10.4860 getitem, batch_nr 656 train is: True\n",
      "\u001b[1m 656/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:12\u001b[0m 5s/step - accuracy: 0.3495 - loss: 10.4843 getitem, batch_nr 657 train is: True\n",
      "\u001b[1m 657/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:07\u001b[0m 5s/step - accuracy: 0.3496 - loss: 10.4825 getitem, batch_nr 658 train is: True\n",
      "\u001b[1m 658/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:03\u001b[0m 5s/step - accuracy: 0.3498 - loss: 10.4808 getitem, batch_nr 659 train is: True\n",
      "\u001b[1m 659/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:58\u001b[0m 5s/step - accuracy: 0.3499 - loss: 10.4790 getitem, batch_nr 660 train is: True\n",
      "\u001b[1m 660/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:53\u001b[0m 5s/step - accuracy: 0.3500 - loss: 10.4773 getitem, batch_nr 661 train is: True\n",
      "\u001b[1m 661/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:48\u001b[0m 5s/step - accuracy: 0.3501 - loss: 10.4756 getitem, batch_nr 662 train is: True\n",
      "\u001b[1m 662/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:43\u001b[0m 5s/step - accuracy: 0.3502 - loss: 10.4738 getitem, batch_nr 663 train is: True\n",
      "\u001b[1m 663/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:38\u001b[0m 5s/step - accuracy: 0.3503 - loss: 10.4721 getitem, batch_nr 664 train is: True\n",
      "\u001b[1m 664/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:33\u001b[0m 5s/step - accuracy: 0.3504 - loss: 10.4703 getitem, batch_nr 665 train is: True\n",
      "\u001b[1m 665/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:28\u001b[0m 5s/step - accuracy: 0.3505 - loss: 10.4686 getitem, batch_nr 666 train is: True\n",
      "\u001b[1m 666/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:23\u001b[0m 5s/step - accuracy: 0.3506 - loss: 10.4669 getitem, batch_nr 667 train is: True\n",
      "\u001b[1m 667/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:18\u001b[0m 5s/step - accuracy: 0.3507 - loss: 10.4651 getitem, batch_nr 668 train is: True\n",
      "\u001b[1m 668/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:13\u001b[0m 5s/step - accuracy: 0.3508 - loss: 10.4634 getitem, batch_nr 669 train is: True\n",
      "\u001b[1m 669/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:08\u001b[0m 5s/step - accuracy: 0.3509 - loss: 10.4617 getitem, batch_nr 670 train is: True\n",
      "\u001b[1m 670/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:03\u001b[0m 5s/step - accuracy: 0.3510 - loss: 10.4600 getitem, batch_nr 671 train is: True\n",
      "\u001b[1m 671/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:58\u001b[0m 5s/step - accuracy: 0.3511 - loss: 10.4583 getitem, batch_nr 672 train is: True\n",
      "\u001b[1m 672/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:52\u001b[0m 5s/step - accuracy: 0.3512 - loss: 10.4566 getitem, batch_nr 673 train is: True\n",
      "\u001b[1m 673/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:47\u001b[0m 5s/step - accuracy: 0.3514 - loss: 10.4549 getitem, batch_nr 674 train is: True\n",
      "\u001b[1m 674/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:42\u001b[0m 5s/step - accuracy: 0.3515 - loss: 10.4533 getitem, batch_nr 675 train is: True\n",
      "\u001b[1m 675/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:37\u001b[0m 5s/step - accuracy: 0.3516 - loss: 10.4516 getitem, batch_nr 676 train is: True\n",
      "\u001b[1m 676/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:32\u001b[0m 5s/step - accuracy: 0.3517 - loss: 10.4499 getitem, batch_nr 677 train is: True\n",
      "\u001b[1m 677/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:27\u001b[0m 5s/step - accuracy: 0.3518 - loss: 10.4482 getitem, batch_nr 678 train is: True\n",
      "\u001b[1m 678/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:22\u001b[0m 5s/step - accuracy: 0.3519 - loss: 10.4465 getitem, batch_nr 679 train is: True\n",
      "\u001b[1m 679/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:16\u001b[0m 5s/step - accuracy: 0.3520 - loss: 10.4448 getitem, batch_nr 680 train is: True\n",
      "\u001b[1m 680/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:11\u001b[0m 5s/step - accuracy: 0.3521 - loss: 10.4431 getitem, batch_nr 681 train is: True\n",
      "\u001b[1m 681/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:06\u001b[0m 5s/step - accuracy: 0.3522 - loss: 10.4415 getitem, batch_nr 682 train is: True\n",
      "\u001b[1m 682/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:01\u001b[0m 5s/step - accuracy: 0.3523 - loss: 10.4398 getitem, batch_nr 683 train is: True\n",
      "\u001b[1m 683/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:56\u001b[0m 5s/step - accuracy: 0.3524 - loss: 10.4381 getitem, batch_nr 684 train is: True\n",
      "\u001b[1m 684/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:51\u001b[0m 5s/step - accuracy: 0.3525 - loss: 10.4365 getitem, batch_nr 685 train is: True\n",
      "\u001b[1m 685/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:46\u001b[0m 5s/step - accuracy: 0.3526 - loss: 10.4348 getitem, batch_nr 686 train is: True\n",
      "\u001b[1m 686/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:41\u001b[0m 5s/step - accuracy: 0.3527 - loss: 10.4331 getitem, batch_nr 687 train is: True\n",
      "\u001b[1m 687/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:36\u001b[0m 5s/step - accuracy: 0.3528 - loss: 10.4315 getitem, batch_nr 688 train is: True\n",
      "\u001b[1m 688/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:30\u001b[0m 5s/step - accuracy: 0.3529 - loss: 10.4298 getitem, batch_nr 689 train is: True\n",
      "\u001b[1m 689/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:25\u001b[0m 5s/step - accuracy: 0.3530 - loss: 10.4282 getitem, batch_nr 690 train is: True\n",
      "\u001b[1m 690/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:20\u001b[0m 5s/step - accuracy: 0.3531 - loss: 10.4265 getitem, batch_nr 691 train is: True\n",
      "\u001b[1m 691/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:15\u001b[0m 5s/step - accuracy: 0.3532 - loss: 10.4249 getitem, batch_nr 692 train is: True\n",
      "\u001b[1m 692/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:10\u001b[0m 5s/step - accuracy: 0.3533 - loss: 10.4232 getitem, batch_nr 693 train is: True\n",
      "\u001b[1m 693/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:05\u001b[0m 5s/step - accuracy: 0.3534 - loss: 10.4216 getitem, batch_nr 694 train is: True\n",
      "\u001b[1m 694/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:00\u001b[0m 5s/step - accuracy: 0.3535 - loss: 10.4199 getitem, batch_nr 695 train is: True\n",
      "\u001b[1m 695/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:55\u001b[0m 5s/step - accuracy: 0.3536 - loss: 10.4183 getitem, batch_nr 696 train is: True\n",
      "\u001b[1m 696/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:49\u001b[0m 5s/step - accuracy: 0.3537 - loss: 10.4166 getitem, batch_nr 697 train is: True\n",
      "\u001b[1m 697/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:45\u001b[0m 5s/step - accuracy: 0.3538 - loss: 10.4150 getitem, batch_nr 698 train is: True\n",
      "\u001b[1m 698/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:39\u001b[0m 5s/step - accuracy: 0.3539 - loss: 10.4133 getitem, batch_nr 699 train is: True\n",
      "\u001b[1m 699/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:35\u001b[0m 5s/step - accuracy: 0.3540 - loss: 10.4117 getitem, batch_nr 700 train is: True\n",
      "\u001b[1m 700/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:29\u001b[0m 5s/step - accuracy: 0.3541 - loss: 10.4100 getitem, batch_nr 701 train is: True\n",
      "\u001b[1m 701/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:24\u001b[0m 5s/step - accuracy: 0.3542 - loss: 10.4084 getitem, batch_nr 702 train is: True\n",
      "\u001b[1m 702/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:19\u001b[0m 5s/step - accuracy: 0.3543 - loss: 10.4068 getitem, batch_nr 703 train is: True\n",
      "\u001b[1m 703/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:14\u001b[0m 5s/step - accuracy: 0.3544 - loss: 10.4051 getitem, batch_nr 704 train is: True\n",
      "\u001b[1m 704/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:09\u001b[0m 5s/step - accuracy: 0.3545 - loss: 10.4035 getitem, batch_nr 705 train is: True\n",
      "\u001b[1m 705/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:04\u001b[0m 5s/step - accuracy: 0.3546 - loss: 10.4018 getitem, batch_nr 706 train is: True\n",
      "\u001b[1m 706/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:59\u001b[0m 5s/step - accuracy: 0.3547 - loss: 10.4002 getitem, batch_nr 707 train is: True\n",
      "\u001b[1m 707/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:54\u001b[0m 5s/step - accuracy: 0.3549 - loss: 10.3986 getitem, batch_nr 708 train is: True\n",
      "\u001b[1m 708/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:49\u001b[0m 5s/step - accuracy: 0.3550 - loss: 10.3970 getitem, batch_nr 709 train is: True\n",
      "\u001b[1m 709/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:44\u001b[0m 5s/step - accuracy: 0.3551 - loss: 10.3953 getitem, batch_nr 710 train is: True\n",
      "\u001b[1m 710/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:39\u001b[0m 5s/step - accuracy: 0.3552 - loss: 10.3937 getitem, batch_nr 711 train is: True\n",
      "\u001b[1m 711/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:34\u001b[0m 5s/step - accuracy: 0.3553 - loss: 10.3921 getitem, batch_nr 712 train is: True\n",
      "\u001b[1m 712/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:28\u001b[0m 5s/step - accuracy: 0.3554 - loss: 10.3905 getitem, batch_nr 713 train is: True\n",
      "\u001b[1m 713/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:23\u001b[0m 5s/step - accuracy: 0.3555 - loss: 10.3888 getitem, batch_nr 714 train is: True\n",
      "\u001b[1m 714/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:18\u001b[0m 5s/step - accuracy: 0.3556 - loss: 10.3872 getitem, batch_nr 715 train is: True\n",
      "\u001b[1m 715/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:13\u001b[0m 5s/step - accuracy: 0.3557 - loss: 10.3856 getitem, batch_nr 716 train is: True\n",
      "\u001b[1m 716/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:08\u001b[0m 5s/step - accuracy: 0.3558 - loss: 10.3840 getitem, batch_nr 717 train is: True\n",
      "\u001b[1m 717/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:03\u001b[0m 5s/step - accuracy: 0.3559 - loss: 10.3824 getitem, batch_nr 718 train is: True\n",
      "\u001b[1m 718/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:58\u001b[0m 5s/step - accuracy: 0.3560 - loss: 10.3807 getitem, batch_nr 719 train is: True\n",
      "\u001b[1m 719/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:53\u001b[0m 5s/step - accuracy: 0.3561 - loss: 10.3791 getitem, batch_nr 720 train is: True\n",
      "\u001b[1m 720/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:48\u001b[0m 5s/step - accuracy: 0.3562 - loss: 10.3775 getitem, batch_nr 721 train is: True\n",
      "\u001b[1m 721/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:43\u001b[0m 5s/step - accuracy: 0.3563 - loss: 10.3759 getitem, batch_nr 722 train is: True\n",
      "\u001b[1m 722/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:38\u001b[0m 5s/step - accuracy: 0.3564 - loss: 10.3743 getitem, batch_nr 723 train is: True\n",
      "\u001b[1m 723/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:33\u001b[0m 5s/step - accuracy: 0.3565 - loss: 10.3728 getitem, batch_nr 724 train is: True\n",
      "\u001b[1m 724/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:27\u001b[0m 5s/step - accuracy: 0.3566 - loss: 10.3712 getitem, batch_nr 725 train is: True\n",
      "\u001b[1m 725/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:22\u001b[0m 5s/step - accuracy: 0.3566 - loss: 10.3696 getitem, batch_nr 726 train is: True\n",
      "\u001b[1m 726/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:17\u001b[0m 5s/step - accuracy: 0.3567 - loss: 10.3680 getitem, batch_nr 727 train is: True\n",
      "\u001b[1m 727/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:12\u001b[0m 5s/step - accuracy: 0.3568 - loss: 10.3665 getitem, batch_nr 728 train is: True\n",
      "\u001b[1m 728/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:07\u001b[0m 5s/step - accuracy: 0.3569 - loss: 10.3649 getitem, batch_nr 729 train is: True\n",
      "\u001b[1m 729/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:02\u001b[0m 5s/step - accuracy: 0.3570 - loss: 10.3634 getitem, batch_nr 730 train is: True\n",
      "\u001b[1m 730/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:57\u001b[0m 5s/step - accuracy: 0.3571 - loss: 10.3618 getitem, batch_nr 731 train is: True\n",
      "\u001b[1m 731/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:52\u001b[0m 5s/step - accuracy: 0.3572 - loss: 10.3603 getitem, batch_nr 732 train is: True\n",
      "\u001b[1m 732/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:47\u001b[0m 5s/step - accuracy: 0.3573 - loss: 10.3587 getitem, batch_nr 733 train is: True\n",
      "\u001b[1m 733/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:42\u001b[0m 5s/step - accuracy: 0.3574 - loss: 10.3572 getitem, batch_nr 734 train is: True\n",
      "\u001b[1m 734/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:36\u001b[0m 5s/step - accuracy: 0.3575 - loss: 10.3557 getitem, batch_nr 735 train is: True\n",
      "\u001b[1m 735/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:31\u001b[0m 5s/step - accuracy: 0.3576 - loss: 10.3541 getitem, batch_nr 736 train is: True\n",
      "\u001b[1m 736/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:26\u001b[0m 5s/step - accuracy: 0.3577 - loss: 10.3526 getitem, batch_nr 737 train is: True\n",
      "\u001b[1m 737/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:21\u001b[0m 5s/step - accuracy: 0.3578 - loss: 10.3511 getitem, batch_nr 738 train is: True\n",
      "\u001b[1m 738/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:16\u001b[0m 5s/step - accuracy: 0.3579 - loss: 10.3496 getitem, batch_nr 739 train is: True\n",
      "\u001b[1m 739/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:11\u001b[0m 5s/step - accuracy: 0.3580 - loss: 10.3481 getitem, batch_nr 740 train is: True\n",
      "\u001b[1m 740/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:06\u001b[0m 5s/step - accuracy: 0.3581 - loss: 10.3466 getitem, batch_nr 741 train is: True\n",
      "\u001b[1m 741/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:00\u001b[0m 5s/step - accuracy: 0.3582 - loss: 10.3451 getitem, batch_nr 742 train is: True\n",
      "\u001b[1m 742/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:55\u001b[0m 5s/step - accuracy: 0.3583 - loss: 10.3437 getitem, batch_nr 743 train is: True\n",
      "\u001b[1m 743/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:50\u001b[0m 5s/step - accuracy: 0.3583 - loss: 10.3422 getitem, batch_nr 744 train is: True\n",
      "\u001b[1m 744/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:45\u001b[0m 5s/step - accuracy: 0.3584 - loss: 10.3407 getitem, batch_nr 745 train is: True\n",
      "\u001b[1m 745/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:40\u001b[0m 5s/step - accuracy: 0.3585 - loss: 10.3392 getitem, batch_nr 746 train is: True\n",
      "\u001b[1m 746/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:35\u001b[0m 5s/step - accuracy: 0.3586 - loss: 10.3378 getitem, batch_nr 747 train is: True\n",
      "\u001b[1m 747/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:30\u001b[0m 5s/step - accuracy: 0.3587 - loss: 10.3363 getitem, batch_nr 748 train is: True\n",
      "\u001b[1m 748/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:25\u001b[0m 5s/step - accuracy: 0.3588 - loss: 10.3348 getitem, batch_nr 749 train is: True\n",
      "\u001b[1m 749/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:20\u001b[0m 5s/step - accuracy: 0.3589 - loss: 10.3333 getitem, batch_nr 750 train is: True\n",
      "\u001b[1m 750/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:15\u001b[0m 5s/step - accuracy: 0.3590 - loss: 10.3319 getitem, batch_nr 751 train is: True\n",
      "\u001b[1m 751/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:10\u001b[0m 5s/step - accuracy: 0.3591 - loss: 10.3304 getitem, batch_nr 752 train is: True\n",
      "\u001b[1m 752/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:05\u001b[0m 5s/step - accuracy: 0.3592 - loss: 10.3289 getitem, batch_nr 753 train is: True\n",
      "\u001b[1m 753/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:59\u001b[0m 5s/step - accuracy: 0.3593 - loss: 10.3275 getitem, batch_nr 754 train is: True\n",
      "\u001b[1m 754/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:54\u001b[0m 5s/step - accuracy: 0.3594 - loss: 10.3260 getitem, batch_nr 755 train is: True\n",
      "\u001b[1m 755/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:49\u001b[0m 5s/step - accuracy: 0.3594 - loss: 10.3246 getitem, batch_nr 756 train is: True\n",
      "\u001b[1m 756/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:44\u001b[0m 5s/step - accuracy: 0.3595 - loss: 10.3231 getitem, batch_nr 757 train is: True\n",
      "\u001b[1m 757/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:39\u001b[0m 5s/step - accuracy: 0.3596 - loss: 10.3217 getitem, batch_nr 758 train is: True\n",
      "\u001b[1m 758/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:34\u001b[0m 5s/step - accuracy: 0.3597 - loss: 10.3202 getitem, batch_nr 759 train is: True\n",
      "\u001b[1m 759/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:29\u001b[0m 5s/step - accuracy: 0.3598 - loss: 10.3188 getitem, batch_nr 760 train is: True\n",
      "\u001b[1m 760/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:24\u001b[0m 5s/step - accuracy: 0.3599 - loss: 10.3173 getitem, batch_nr 761 train is: True\n",
      "\u001b[1m 761/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:19\u001b[0m 5s/step - accuracy: 0.3600 - loss: 10.3159 getitem, batch_nr 762 train is: True\n",
      "\u001b[1m 762/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:14\u001b[0m 5s/step - accuracy: 0.3601 - loss: 10.3145 getitem, batch_nr 763 train is: True\n",
      "\u001b[1m 763/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:08\u001b[0m 5s/step - accuracy: 0.3602 - loss: 10.3130 getitem, batch_nr 764 train is: True\n",
      "\u001b[1m 764/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:03\u001b[0m 5s/step - accuracy: 0.3602 - loss: 10.3116 getitem, batch_nr 765 train is: True\n",
      "\u001b[1m 765/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:58\u001b[0m 5s/step - accuracy: 0.3603 - loss: 10.3102 getitem, batch_nr 766 train is: True\n",
      "\u001b[1m 766/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:53\u001b[0m 5s/step - accuracy: 0.3604 - loss: 10.3088 getitem, batch_nr 767 train is: True\n",
      "\u001b[1m 767/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:48\u001b[0m 5s/step - accuracy: 0.3605 - loss: 10.3073 getitem, batch_nr 768 train is: True\n",
      "\u001b[1m 768/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:43\u001b[0m 5s/step - accuracy: 0.3606 - loss: 10.3059 getitem, batch_nr 769 train is: True\n",
      "\u001b[1m 769/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:38\u001b[0m 5s/step - accuracy: 0.3607 - loss: 10.3045 getitem, batch_nr 770 train is: True\n",
      "\u001b[1m 770/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:33\u001b[0m 5s/step - accuracy: 0.3608 - loss: 10.3031 getitem, batch_nr 771 train is: True\n",
      "\u001b[1m 771/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:28\u001b[0m 5s/step - accuracy: 0.3609 - loss: 10.3017 getitem, batch_nr 772 train is: True\n",
      "\u001b[1m 772/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:23\u001b[0m 5s/step - accuracy: 0.3609 - loss: 10.3003 getitem, batch_nr 773 train is: True\n",
      "\u001b[1m 773/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:17\u001b[0m 5s/step - accuracy: 0.3610 - loss: 10.2989 getitem, batch_nr 774 train is: True\n",
      "\u001b[1m 774/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:12\u001b[0m 5s/step - accuracy: 0.3611 - loss: 10.2975 getitem, batch_nr 775 train is: True\n",
      "\u001b[1m 775/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:07\u001b[0m 5s/step - accuracy: 0.3612 - loss: 10.2961 getitem, batch_nr 776 train is: True\n",
      "\u001b[1m 776/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:02\u001b[0m 5s/step - accuracy: 0.3613 - loss: 10.2948 getitem, batch_nr 777 train is: True\n",
      "\u001b[1m 777/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:57\u001b[0m 5s/step - accuracy: 0.3614 - loss: 10.2934 getitem, batch_nr 778 train is: True\n",
      "\u001b[1m 778/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:52\u001b[0m 5s/step - accuracy: 0.3615 - loss: 10.2920 getitem, batch_nr 779 train is: True\n",
      "\u001b[1m 779/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:47\u001b[0m 5s/step - accuracy: 0.3615 - loss: 10.2906 getitem, batch_nr 780 train is: True\n",
      "\u001b[1m 780/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:42\u001b[0m 5s/step - accuracy: 0.3616 - loss: 10.2893 getitem, batch_nr 781 train is: True\n",
      "\u001b[1m 781/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:37\u001b[0m 5s/step - accuracy: 0.3617 - loss: 10.2879 getitem, batch_nr 782 train is: True\n",
      "\u001b[1m 782/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:32\u001b[0m 5s/step - accuracy: 0.3618 - loss: 10.2865 getitem, batch_nr 783 train is: True\n",
      "\u001b[1m 783/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:26\u001b[0m 5s/step - accuracy: 0.3619 - loss: 10.2852 getitem, batch_nr 784 train is: True\n",
      "\u001b[1m 784/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:21\u001b[0m 5s/step - accuracy: 0.3620 - loss: 10.2838 getitem, batch_nr 785 train is: True\n",
      "\u001b[1m 785/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:16\u001b[0m 5s/step - accuracy: 0.3621 - loss: 10.2825 getitem, batch_nr 786 train is: True\n",
      "\u001b[1m 786/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:11\u001b[0m 5s/step - accuracy: 0.3621 - loss: 10.2811 getitem, batch_nr 787 train is: True\n",
      "\u001b[1m 787/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:06\u001b[0m 5s/step - accuracy: 0.3622 - loss: 10.2798 getitem, batch_nr 788 train is: True\n",
      "\u001b[1m 788/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:01\u001b[0m 5s/step - accuracy: 0.3623 - loss: 10.2785 getitem, batch_nr 789 train is: True\n",
      "\u001b[1m 789/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m44:56\u001b[0m 5s/step - accuracy: 0.3624 - loss: 10.2771 getitem, batch_nr 790 train is: True\n",
      "\u001b[1m 790/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:51\u001b[0m 5s/step - accuracy: 0.3625 - loss: 10.2758 getitem, batch_nr 791 train is: True\n",
      "\u001b[1m 791/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:46\u001b[0m 5s/step - accuracy: 0.3626 - loss: 10.2745 getitem, batch_nr 792 train is: True\n",
      "\u001b[1m 792/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:41\u001b[0m 5s/step - accuracy: 0.3626 - loss: 10.2731 getitem, batch_nr 793 train is: True\n",
      "\u001b[1m 793/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:35\u001b[0m 5s/step - accuracy: 0.3627 - loss: 10.2718 getitem, batch_nr 794 train is: True\n",
      "\u001b[1m 794/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:30\u001b[0m 5s/step - accuracy: 0.3628 - loss: 10.2705 getitem, batch_nr 795 train is: True\n",
      "\u001b[1m 795/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:25\u001b[0m 5s/step - accuracy: 0.3629 - loss: 10.2692 getitem, batch_nr 796 train is: True\n",
      "\u001b[1m 796/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:20\u001b[0m 5s/step - accuracy: 0.3630 - loss: 10.2679 getitem, batch_nr 797 train is: True\n",
      "\u001b[1m 797/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:15\u001b[0m 5s/step - accuracy: 0.3630 - loss: 10.2666 getitem, batch_nr 798 train is: True\n",
      "\u001b[1m 798/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:10\u001b[0m 5s/step - accuracy: 0.3631 - loss: 10.2653 getitem, batch_nr 799 train is: True\n",
      "\u001b[1m 799/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:05\u001b[0m 5s/step - accuracy: 0.3632 - loss: 10.2640 getitem, batch_nr 800 train is: True\n",
      "\u001b[1m 800/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:00\u001b[0m 5s/step - accuracy: 0.3633 - loss: 10.2627 getitem, batch_nr 801 train is: True\n",
      "\u001b[1m 801/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:54\u001b[0m 5s/step - accuracy: 0.3634 - loss: 10.2614 getitem, batch_nr 802 train is: True\n",
      "\u001b[1m 802/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:49\u001b[0m 5s/step - accuracy: 0.3634 - loss: 10.2601 getitem, batch_nr 803 train is: True\n",
      "\u001b[1m 803/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:44\u001b[0m 5s/step - accuracy: 0.3635 - loss: 10.2588 getitem, batch_nr 804 train is: True\n",
      "\u001b[1m 804/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:39\u001b[0m 5s/step - accuracy: 0.3636 - loss: 10.2575 getitem, batch_nr 805 train is: True\n",
      "\u001b[1m 805/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:34\u001b[0m 5s/step - accuracy: 0.3637 - loss: 10.2563 getitem, batch_nr 806 train is: True\n",
      "\u001b[1m 806/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:29\u001b[0m 5s/step - accuracy: 0.3638 - loss: 10.2550 getitem, batch_nr 807 train is: True\n",
      "\u001b[1m 807/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:24\u001b[0m 5s/step - accuracy: 0.3638 - loss: 10.2537 getitem, batch_nr 808 train is: True\n",
      "\u001b[1m 808/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:19\u001b[0m 5s/step - accuracy: 0.3639 - loss: 10.2525 getitem, batch_nr 809 train is: True\n",
      "\u001b[1m 809/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:14\u001b[0m 5s/step - accuracy: 0.3640 - loss: 10.2512 getitem, batch_nr 810 train is: True\n",
      "\u001b[1m 810/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:09\u001b[0m 5s/step - accuracy: 0.3641 - loss: 10.2499 getitem, batch_nr 811 train is: True\n",
      "\u001b[1m 811/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:04\u001b[0m 5s/step - accuracy: 0.3641 - loss: 10.2487 getitem, batch_nr 812 train is: True\n",
      "\u001b[1m 812/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:59\u001b[0m 5s/step - accuracy: 0.3642 - loss: 10.2475 getitem, batch_nr 813 train is: True\n",
      "\u001b[1m 813/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:53\u001b[0m 5s/step - accuracy: 0.3643 - loss: 10.2462 getitem, batch_nr 814 train is: True\n",
      "\u001b[1m 814/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:48\u001b[0m 5s/step - accuracy: 0.3644 - loss: 10.2450 getitem, batch_nr 815 train is: True\n",
      "\u001b[1m 815/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:43\u001b[0m 5s/step - accuracy: 0.3645 - loss: 10.2437 getitem, batch_nr 816 train is: True\n",
      "\u001b[1m 816/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:38\u001b[0m 5s/step - accuracy: 0.3645 - loss: 10.2425 getitem, batch_nr 817 train is: True\n",
      "\u001b[1m 817/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:33\u001b[0m 5s/step - accuracy: 0.3646 - loss: 10.2413 getitem, batch_nr 818 train is: True\n",
      "\u001b[1m 818/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:28\u001b[0m 5s/step - accuracy: 0.3647 - loss: 10.2401 getitem, batch_nr 819 train is: True\n",
      "\u001b[1m 819/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:23\u001b[0m 5s/step - accuracy: 0.3648 - loss: 10.2388 getitem, batch_nr 820 train is: True\n",
      "\u001b[1m 820/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:18\u001b[0m 5s/step - accuracy: 0.3648 - loss: 10.2376 getitem, batch_nr 821 train is: True\n",
      "\u001b[1m 821/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:13\u001b[0m 5s/step - accuracy: 0.3649 - loss: 10.2364 getitem, batch_nr 822 train is: True\n",
      "\u001b[1m 822/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:07\u001b[0m 5s/step - accuracy: 0.3650 - loss: 10.2352 getitem, batch_nr 823 train is: True\n",
      "\u001b[1m 823/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:02\u001b[0m 5s/step - accuracy: 0.3651 - loss: 10.2340 getitem, batch_nr 824 train is: True\n",
      "\u001b[1m 824/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:57\u001b[0m 5s/step - accuracy: 0.3651 - loss: 10.2328 getitem, batch_nr 825 train is: True\n",
      "\u001b[1m 825/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:52\u001b[0m 5s/step - accuracy: 0.3652 - loss: 10.2316 getitem, batch_nr 826 train is: True\n",
      "\u001b[1m 826/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:47\u001b[0m 5s/step - accuracy: 0.3653 - loss: 10.2304 getitem, batch_nr 827 train is: True\n",
      "\u001b[1m 827/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:42\u001b[0m 5s/step - accuracy: 0.3654 - loss: 10.2292 getitem, batch_nr 828 train is: True\n",
      "\u001b[1m 828/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:37\u001b[0m 5s/step - accuracy: 0.3654 - loss: 10.2280 getitem, batch_nr 829 train is: True\n",
      "\u001b[1m 829/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:32\u001b[0m 5s/step - accuracy: 0.3655 - loss: 10.2269 getitem, batch_nr 830 train is: True\n",
      "\u001b[1m 830/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:27\u001b[0m 5s/step - accuracy: 0.3656 - loss: 10.2257 getitem, batch_nr 831 train is: True\n",
      "\u001b[1m 831/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:21\u001b[0m 5s/step - accuracy: 0.3657 - loss: 10.2245 getitem, batch_nr 832 train is: True\n",
      "\u001b[1m 832/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:16\u001b[0m 5s/step - accuracy: 0.3657 - loss: 10.2233 getitem, batch_nr 833 train is: True\n",
      "\u001b[1m 833/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:11\u001b[0m 5s/step - accuracy: 0.3658 - loss: 10.2222 getitem, batch_nr 834 train is: True\n",
      "\u001b[1m 834/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:06\u001b[0m 5s/step - accuracy: 0.3659 - loss: 10.2210 getitem, batch_nr 835 train is: True\n",
      "\u001b[1m 835/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:01\u001b[0m 5s/step - accuracy: 0.3659 - loss: 10.2199 getitem, batch_nr 836 train is: True\n",
      "\u001b[1m 836/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:56\u001b[0m 5s/step - accuracy: 0.3660 - loss: 10.2187 getitem, batch_nr 837 train is: True\n",
      "\u001b[1m 837/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:51\u001b[0m 5s/step - accuracy: 0.3661 - loss: 10.2175 getitem, batch_nr 838 train is: True\n",
      "\u001b[1m 838/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:46\u001b[0m 5s/step - accuracy: 0.3662 - loss: 10.2164 getitem, batch_nr 839 train is: True\n",
      "\u001b[1m 839/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:41\u001b[0m 5s/step - accuracy: 0.3662 - loss: 10.2152 getitem, batch_nr 840 train is: True\n",
      "\u001b[1m 840/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:35\u001b[0m 5s/step - accuracy: 0.3663 - loss: 10.2141 getitem, batch_nr 841 train is: True\n",
      "\u001b[1m 841/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:30\u001b[0m 5s/step - accuracy: 0.3664 - loss: 10.2130 getitem, batch_nr 842 train is: True\n",
      "\u001b[1m 842/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:25\u001b[0m 5s/step - accuracy: 0.3664 - loss: 10.2118 getitem, batch_nr 843 train is: True\n",
      "\u001b[1m 843/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:20\u001b[0m 5s/step - accuracy: 0.3665 - loss: 10.2107 getitem, batch_nr 844 train is: True\n",
      "\u001b[1m 844/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:15\u001b[0m 5s/step - accuracy: 0.3666 - loss: 10.2096 getitem, batch_nr 845 train is: True\n",
      "\u001b[1m 845/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:10\u001b[0m 5s/step - accuracy: 0.3666 - loss: 10.2084 getitem, batch_nr 846 train is: True\n",
      "\u001b[1m 846/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:05\u001b[0m 5s/step - accuracy: 0.3667 - loss: 10.2073 getitem, batch_nr 847 train is: True\n",
      "\u001b[1m 847/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:00\u001b[0m 5s/step - accuracy: 0.3668 - loss: 10.2062 getitem, batch_nr 848 train is: True\n",
      "\u001b[1m 848/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:55\u001b[0m 5s/step - accuracy: 0.3669 - loss: 10.2051 getitem, batch_nr 849 train is: True\n",
      "\u001b[1m 849/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:50\u001b[0m 5s/step - accuracy: 0.3669 - loss: 10.2040 getitem, batch_nr 850 train is: True\n",
      "\u001b[1m 850/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:44\u001b[0m 5s/step - accuracy: 0.3670 - loss: 10.2029 getitem, batch_nr 851 train is: True\n",
      "\u001b[1m 851/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:39\u001b[0m 5s/step - accuracy: 0.3671 - loss: 10.2017 getitem, batch_nr 852 train is: True\n",
      "\u001b[1m 852/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:34\u001b[0m 5s/step - accuracy: 0.3671 - loss: 10.2006 getitem, batch_nr 853 train is: True\n",
      "\u001b[1m 853/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:29\u001b[0m 5s/step - accuracy: 0.3672 - loss: 10.1995 getitem, batch_nr 854 train is: True\n",
      "\u001b[1m 854/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:24\u001b[0m 5s/step - accuracy: 0.3673 - loss: 10.1984 getitem, batch_nr 855 train is: True\n",
      "\u001b[1m 855/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:19\u001b[0m 5s/step - accuracy: 0.3673 - loss: 10.1973 getitem, batch_nr 856 train is: True\n",
      "\u001b[1m 856/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:14\u001b[0m 5s/step - accuracy: 0.3674 - loss: 10.1962 getitem, batch_nr 857 train is: True\n",
      "\u001b[1m 857/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:09\u001b[0m 5s/step - accuracy: 0.3675 - loss: 10.1951 getitem, batch_nr 858 train is: True\n",
      "\u001b[1m 858/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:04\u001b[0m 5s/step - accuracy: 0.3675 - loss: 10.1940 getitem, batch_nr 859 train is: True\n",
      "\u001b[1m 859/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:59\u001b[0m 5s/step - accuracy: 0.3676 - loss: 10.1930 getitem, batch_nr 860 train is: True\n",
      "\u001b[1m 860/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:53\u001b[0m 5s/step - accuracy: 0.3677 - loss: 10.1919 getitem, batch_nr 861 train is: True\n",
      "\u001b[1m 861/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:48\u001b[0m 5s/step - accuracy: 0.3677 - loss: 10.1908 getitem, batch_nr 862 train is: True\n",
      "\u001b[1m 862/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:43\u001b[0m 5s/step - accuracy: 0.3678 - loss: 10.1897 getitem, batch_nr 863 train is: True\n",
      "\u001b[1m 863/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:38\u001b[0m 5s/step - accuracy: 0.3679 - loss: 10.1886 getitem, batch_nr 864 train is: True\n",
      "\u001b[1m 864/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:33\u001b[0m 5s/step - accuracy: 0.3679 - loss: 10.1876 getitem, batch_nr 865 train is: True\n",
      "\u001b[1m 865/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:28\u001b[0m 5s/step - accuracy: 0.3680 - loss: 10.1865 getitem, batch_nr 866 train is: True\n",
      "\u001b[1m 866/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:23\u001b[0m 5s/step - accuracy: 0.3681 - loss: 10.1854 getitem, batch_nr 867 train is: True\n",
      "\u001b[1m 867/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:18\u001b[0m 5s/step - accuracy: 0.3681 - loss: 10.1844 getitem, batch_nr 868 train is: True\n",
      "\u001b[1m 868/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:12\u001b[0m 5s/step - accuracy: 0.3682 - loss: 10.1833 getitem, batch_nr 869 train is: True\n",
      "\u001b[1m 869/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:07\u001b[0m 5s/step - accuracy: 0.3683 - loss: 10.1822 getitem, batch_nr 870 train is: True\n",
      "\u001b[1m 870/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:02\u001b[0m 5s/step - accuracy: 0.3683 - loss: 10.1812 getitem, batch_nr 871 train is: True\n",
      "\u001b[1m 871/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:57\u001b[0m 5s/step - accuracy: 0.3684 - loss: 10.1801 getitem, batch_nr 872 train is: True\n",
      "\u001b[1m 872/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:52\u001b[0m 5s/step - accuracy: 0.3685 - loss: 10.1791 getitem, batch_nr 873 train is: True\n",
      "\u001b[1m 873/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:47\u001b[0m 5s/step - accuracy: 0.3685 - loss: 10.1780 getitem, batch_nr 874 train is: True\n",
      "\u001b[1m 874/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:42\u001b[0m 5s/step - accuracy: 0.3686 - loss: 10.1770 getitem, batch_nr 875 train is: True\n",
      "\u001b[1m 875/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:37\u001b[0m 5s/step - accuracy: 0.3687 - loss: 10.1759 getitem, batch_nr 876 train is: True\n",
      "\u001b[1m 876/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:32\u001b[0m 5s/step - accuracy: 0.3687 - loss: 10.1749 getitem, batch_nr 877 train is: True\n",
      "\u001b[1m 877/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:27\u001b[0m 5s/step - accuracy: 0.3688 - loss: 10.1739 getitem, batch_nr 878 train is: True\n",
      "\u001b[1m 878/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:21\u001b[0m 5s/step - accuracy: 0.3689 - loss: 10.1728 getitem, batch_nr 879 train is: True\n",
      "\u001b[1m 879/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:16\u001b[0m 5s/step - accuracy: 0.3689 - loss: 10.1718 getitem, batch_nr 880 train is: True\n",
      "\u001b[1m 880/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:11\u001b[0m 5s/step - accuracy: 0.3690 - loss: 10.1708 getitem, batch_nr 881 train is: True\n",
      "\u001b[1m 881/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:06\u001b[0m 5s/step - accuracy: 0.3690 - loss: 10.1698 getitem, batch_nr 882 train is: True\n",
      "\u001b[1m 882/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:01\u001b[0m 5s/step - accuracy: 0.3691 - loss: 10.1688 getitem, batch_nr 883 train is: True\n",
      "\u001b[1m 883/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:56\u001b[0m 5s/step - accuracy: 0.3692 - loss: 10.1677 getitem, batch_nr 884 train is: True\n",
      "\u001b[1m 884/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:51\u001b[0m 5s/step - accuracy: 0.3692 - loss: 10.1667 getitem, batch_nr 885 train is: True\n",
      "\u001b[1m 885/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:46\u001b[0m 5s/step - accuracy: 0.3693 - loss: 10.1657 getitem, batch_nr 886 train is: True\n",
      "\u001b[1m 886/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:40\u001b[0m 5s/step - accuracy: 0.3694 - loss: 10.1647 getitem, batch_nr 887 train is: True\n",
      "\u001b[1m 887/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:35\u001b[0m 5s/step - accuracy: 0.3694 - loss: 10.1637 getitem, batch_nr 888 train is: True\n",
      "\u001b[1m 888/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:30\u001b[0m 5s/step - accuracy: 0.3695 - loss: 10.1627 getitem, batch_nr 889 train is: True\n",
      "\u001b[1m 889/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:25\u001b[0m 5s/step - accuracy: 0.3695 - loss: 10.1617 getitem, batch_nr 890 train is: True\n",
      "\u001b[1m 890/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:20\u001b[0m 5s/step - accuracy: 0.3696 - loss: 10.1607 getitem, batch_nr 891 train is: True\n",
      "\u001b[1m 891/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:15\u001b[0m 5s/step - accuracy: 0.3697 - loss: 10.1597 getitem, batch_nr 892 train is: True\n",
      "\u001b[1m 892/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:10\u001b[0m 5s/step - accuracy: 0.3697 - loss: 10.1587 getitem, batch_nr 893 train is: True\n",
      "\u001b[1m 893/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:05\u001b[0m 5s/step - accuracy: 0.3698 - loss: 10.1577 getitem, batch_nr 894 train is: True\n",
      "\u001b[1m 894/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:00\u001b[0m 5s/step - accuracy: 0.3699 - loss: 10.1567 getitem, batch_nr 895 train is: True\n",
      "\u001b[1m 895/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:55\u001b[0m 5s/step - accuracy: 0.3699 - loss: 10.1557 getitem, batch_nr 896 train is: True\n",
      "\u001b[1m 896/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:49\u001b[0m 5s/step - accuracy: 0.3700 - loss: 10.1547 getitem, batch_nr 897 train is: True\n",
      "\u001b[1m 897/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:44\u001b[0m 5s/step - accuracy: 0.3700 - loss: 10.1537 getitem, batch_nr 898 train is: True\n",
      "\u001b[1m 898/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:39\u001b[0m 5s/step - accuracy: 0.3701 - loss: 10.1528 getitem, batch_nr 899 train is: True\n",
      "\u001b[1m 899/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:34\u001b[0m 5s/step - accuracy: 0.3702 - loss: 10.1518 getitem, batch_nr 900 train is: True\n",
      "\u001b[1m 900/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:29\u001b[0m 5s/step - accuracy: 0.3702 - loss: 10.1508 getitem, batch_nr 901 train is: True\n",
      "\u001b[1m 901/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:24\u001b[0m 5s/step - accuracy: 0.3703 - loss: 10.1499 getitem, batch_nr 902 train is: True\n",
      "\u001b[1m 902/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:19\u001b[0m 5s/step - accuracy: 0.3703 - loss: 10.1489 getitem, batch_nr 903 train is: True\n",
      "\u001b[1m 903/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:14\u001b[0m 5s/step - accuracy: 0.3704 - loss: 10.1479 getitem, batch_nr 904 train is: True\n",
      "\u001b[1m 904/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:09\u001b[0m 5s/step - accuracy: 0.3705 - loss: 10.1470 getitem, batch_nr 905 train is: True\n",
      "fill_time_length_dimension_called\n",
      "\u001b[1m 905/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:03\u001b[0m 5s/step - accuracy: 0.3705 - loss: 10.1460 getitem, batch_nr 906 train is: True\n",
      "\u001b[1m 906/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:58\u001b[0m 5s/step - accuracy: 0.3706 - loss: 10.1451 getitem, batch_nr 907 train is: True\n",
      "\u001b[1m 907/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:53\u001b[0m 5s/step - accuracy: 0.3706 - loss: 10.1441 getitem, batch_nr 908 train is: True\n",
      "\u001b[1m 908/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:48\u001b[0m 5s/step - accuracy: 0.3707 - loss: 10.1432 getitem, batch_nr 909 train is: True\n",
      "\u001b[1m 909/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:43\u001b[0m 5s/step - accuracy: 0.3708 - loss: 10.1422 getitem, batch_nr 910 train is: True\n",
      "\u001b[1m 910/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:38\u001b[0m 5s/step - accuracy: 0.3708 - loss: 10.1413 getitem, batch_nr 911 train is: True\n",
      "\u001b[1m 911/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:33\u001b[0m 5s/step - accuracy: 0.3709 - loss: 10.1403 getitem, batch_nr 912 train is: True\n",
      "\u001b[1m 912/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:28\u001b[0m 5s/step - accuracy: 0.3709 - loss: 10.1394 getitem, batch_nr 913 train is: True\n",
      "\u001b[1m 913/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:22\u001b[0m 5s/step - accuracy: 0.3710 - loss: 10.1385 getitem, batch_nr 914 train is: True\n",
      "\u001b[1m 914/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:17\u001b[0m 5s/step - accuracy: 0.3710 - loss: 10.1375 getitem, batch_nr 915 train is: True\n",
      "\u001b[1m 915/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:12\u001b[0m 5s/step - accuracy: 0.3711 - loss: 10.1366 getitem, batch_nr 916 train is: True\n",
      "\u001b[1m 916/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:07\u001b[0m 5s/step - accuracy: 0.3712 - loss: 10.1357 getitem, batch_nr 917 train is: True\n",
      "\u001b[1m 917/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:02\u001b[0m 5s/step - accuracy: 0.3712 - loss: 10.1347 getitem, batch_nr 918 train is: True\n",
      "\u001b[1m 918/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33:57\u001b[0m 5s/step - accuracy: 0.3713 - loss: 10.1338 getitem, batch_nr 919 train is: True\n",
      "\u001b[1m 919/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33:52\u001b[0m 5s/step - accuracy: 0.3713 - loss: 10.1329 getitem, batch_nr 920 train is: True\n",
      "\u001b[1m 920/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33:47\u001b[0m 5s/step - accuracy: 0.3714 - loss: 10.1320 getitem, batch_nr 921 train is: True\n",
      "\u001b[1m 921/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33:42\u001b[0m 5s/step - accuracy: 0.3714 - loss: 10.1310 getitem, batch_nr 922 train is: True\n",
      "\u001b[1m 922/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:36\u001b[0m 5s/step - accuracy: 0.3715 - loss: 10.1301 getitem, batch_nr 923 train is: True\n",
      "\u001b[1m 923/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:31\u001b[0m 5s/step - accuracy: 0.3716 - loss: 10.1292 getitem, batch_nr 924 train is: True\n",
      "\u001b[1m 924/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:26\u001b[0m 5s/step - accuracy: 0.3716 - loss: 10.1283 getitem, batch_nr 925 train is: True\n",
      "\u001b[1m 925/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:21\u001b[0m 5s/step - accuracy: 0.3717 - loss: 10.1274 getitem, batch_nr 926 train is: True\n",
      "\u001b[1m 926/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:16\u001b[0m 5s/step - accuracy: 0.3717 - loss: 10.1265 getitem, batch_nr 927 train is: True\n",
      "\u001b[1m 927/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:11\u001b[0m 5s/step - accuracy: 0.3718 - loss: 10.1256 getitem, batch_nr 928 train is: True\n",
      "\u001b[1m 928/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:06\u001b[0m 5s/step - accuracy: 0.3718 - loss: 10.1247 getitem, batch_nr 929 train is: True\n",
      "\u001b[1m 929/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:01\u001b[0m 5s/step - accuracy: 0.3719 - loss: 10.1238 getitem, batch_nr 930 train is: True\n",
      "\u001b[1m 930/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:55\u001b[0m 5s/step - accuracy: 0.3720 - loss: 10.1229 getitem, batch_nr 931 train is: True\n",
      "\u001b[1m 931/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:50\u001b[0m 5s/step - accuracy: 0.3720 - loss: 10.1220 getitem, batch_nr 932 train is: True\n",
      "\u001b[1m 932/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:45\u001b[0m 5s/step - accuracy: 0.3721 - loss: 10.1211 getitem, batch_nr 933 train is: True\n",
      "\u001b[1m 933/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:40\u001b[0m 5s/step - accuracy: 0.3721 - loss: 10.1202 getitem, batch_nr 934 train is: True\n",
      "\u001b[1m 934/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:35\u001b[0m 5s/step - accuracy: 0.3722 - loss: 10.1193 getitem, batch_nr 935 train is: True\n",
      "\u001b[1m 935/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:30\u001b[0m 5s/step - accuracy: 0.3722 - loss: 10.1184 getitem, batch_nr 936 train is: True\n",
      "\u001b[1m 936/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:25\u001b[0m 5s/step - accuracy: 0.3723 - loss: 10.1175 getitem, batch_nr 937 train is: True\n",
      "\u001b[1m 937/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:20\u001b[0m 5s/step - accuracy: 0.3723 - loss: 10.1166 getitem, batch_nr 938 train is: True\n",
      "\u001b[1m 938/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:15\u001b[0m 5s/step - accuracy: 0.3724 - loss: 10.1157 getitem, batch_nr 939 train is: True\n",
      "\u001b[1m 939/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:09\u001b[0m 5s/step - accuracy: 0.3725 - loss: 10.1148 getitem, batch_nr 940 train is: True\n",
      "\u001b[1m 940/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:04\u001b[0m 5s/step - accuracy: 0.3725 - loss: 10.1139 getitem, batch_nr 941 train is: True\n",
      "\u001b[1m 941/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:59\u001b[0m 5s/step - accuracy: 0.3726 - loss: 10.1130 getitem, batch_nr 942 train is: True\n",
      "\u001b[1m 942/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:54\u001b[0m 5s/step - accuracy: 0.3726 - loss: 10.1121 getitem, batch_nr 943 train is: True\n",
      "\u001b[1m 943/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:49\u001b[0m 5s/step - accuracy: 0.3727 - loss: 10.1112 getitem, batch_nr 944 train is: True\n",
      "\u001b[1m 944/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:44\u001b[0m 5s/step - accuracy: 0.3727 - loss: 10.1103 getitem, batch_nr 945 train is: True\n",
      "\u001b[1m 945/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:39\u001b[0m 5s/step - accuracy: 0.3728 - loss: 10.1094 getitem, batch_nr 946 train is: True\n",
      "\u001b[1m 946/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:33\u001b[0m 5s/step - accuracy: 0.3728 - loss: 10.1085 getitem, batch_nr 947 train is: True\n",
      "\u001b[1m 947/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:28\u001b[0m 5s/step - accuracy: 0.3729 - loss: 10.1076 getitem, batch_nr 948 train is: True\n",
      "\u001b[1m 948/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:23\u001b[0m 5s/step - accuracy: 0.3730 - loss: 10.1067 getitem, batch_nr 949 train is: True\n",
      "\u001b[1m 949/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:18\u001b[0m 5s/step - accuracy: 0.3730 - loss: 10.1058 getitem, batch_nr 950 train is: True\n",
      "\u001b[1m 950/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:13\u001b[0m 5s/step - accuracy: 0.3731 - loss: 10.1049 getitem, batch_nr 951 train is: True\n",
      "\u001b[1m 951/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:08\u001b[0m 5s/step - accuracy: 0.3731 - loss: 10.1040 getitem, batch_nr 952 train is: True\n",
      "\u001b[1m 952/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:03\u001b[0m 5s/step - accuracy: 0.3732 - loss: 10.1031 getitem, batch_nr 953 train is: True\n",
      "\u001b[1m 953/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:58\u001b[0m 5s/step - accuracy: 0.3732 - loss: 10.1022 getitem, batch_nr 954 train is: True\n",
      "\u001b[1m 954/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:53\u001b[0m 5s/step - accuracy: 0.3733 - loss: 10.1013 getitem, batch_nr 955 train is: True\n",
      "\u001b[1m 955/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:47\u001b[0m 5s/step - accuracy: 0.3734 - loss: 10.1004 getitem, batch_nr 956 train is: True\n",
      "\u001b[1m 956/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:42\u001b[0m 5s/step - accuracy: 0.3734 - loss: 10.0995 getitem, batch_nr 957 train is: True\n",
      "\u001b[1m 957/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:37\u001b[0m 5s/step - accuracy: 0.3735 - loss: 10.0986 getitem, batch_nr 958 train is: True\n",
      "\u001b[1m 958/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:32\u001b[0m 5s/step - accuracy: 0.3735 - loss: 10.0977 getitem, batch_nr 959 train is: True\n",
      "\u001b[1m 959/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:27\u001b[0m 5s/step - accuracy: 0.3736 - loss: 10.0968 getitem, batch_nr 960 train is: True\n",
      "\u001b[1m 960/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:22\u001b[0m 5s/step - accuracy: 0.3736 - loss: 10.0959 getitem, batch_nr 961 train is: True\n",
      "\u001b[1m 961/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:17\u001b[0m 5s/step - accuracy: 0.3737 - loss: 10.0950 getitem, batch_nr 962 train is: True\n",
      "\u001b[1m 962/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:12\u001b[0m 5s/step - accuracy: 0.3737 - loss: 10.0941 getitem, batch_nr 963 train is: True\n",
      "\u001b[1m 963/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:07\u001b[0m 5s/step - accuracy: 0.3738 - loss: 10.0932 getitem, batch_nr 964 train is: True\n",
      "\u001b[1m 964/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:01\u001b[0m 5s/step - accuracy: 0.3739 - loss: 10.0923 getitem, batch_nr 965 train is: True\n",
      "\u001b[1m 965/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:56\u001b[0m 5s/step - accuracy: 0.3739 - loss: 10.0914 getitem, batch_nr 966 train is: True\n",
      "\u001b[1m 966/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:51\u001b[0m 5s/step - accuracy: 0.3740 - loss: 10.0905 getitem, batch_nr 967 train is: True\n",
      "\u001b[1m 967/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:46\u001b[0m 5s/step - accuracy: 0.3740 - loss: 10.0896 getitem, batch_nr 968 train is: True\n",
      "\u001b[1m 968/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:41\u001b[0m 5s/step - accuracy: 0.3741 - loss: 10.0887 getitem, batch_nr 969 train is: True\n",
      "\u001b[1m 969/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:36\u001b[0m 5s/step - accuracy: 0.3741 - loss: 10.0879 getitem, batch_nr 970 train is: True\n",
      "\u001b[1m 970/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:31\u001b[0m 5s/step - accuracy: 0.3742 - loss: 10.0870 getitem, batch_nr 971 train is: True\n",
      "\u001b[1m 971/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:26\u001b[0m 5s/step - accuracy: 0.3742 - loss: 10.0861 getitem, batch_nr 972 train is: True\n",
      "\u001b[1m 972/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:21\u001b[0m 5s/step - accuracy: 0.3743 - loss: 10.0852 getitem, batch_nr 973 train is: True\n",
      "\u001b[1m 973/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:15\u001b[0m 5s/step - accuracy: 0.3743 - loss: 10.0843 getitem, batch_nr 974 train is: True\n",
      "\u001b[1m 974/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:10\u001b[0m 5s/step - accuracy: 0.3744 - loss: 10.0834 getitem, batch_nr 975 train is: True\n",
      "\u001b[1m 975/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:05\u001b[0m 5s/step - accuracy: 0.3745 - loss: 10.0825 getitem, batch_nr 976 train is: True\n",
      "\u001b[1m 976/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:00\u001b[0m 5s/step - accuracy: 0.3745 - loss: 10.0816 getitem, batch_nr 977 train is: True\n",
      "\u001b[1m 977/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:55\u001b[0m 5s/step - accuracy: 0.3746 - loss: 10.0807 getitem, batch_nr 978 train is: True\n",
      "\u001b[1m 978/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:50\u001b[0m 5s/step - accuracy: 0.3746 - loss: 10.0799 getitem, batch_nr 979 train is: True\n",
      "\u001b[1m 979/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:45\u001b[0m 5s/step - accuracy: 0.3747 - loss: 10.0790 getitem, batch_nr 980 train is: True\n",
      "\u001b[1m 980/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:40\u001b[0m 5s/step - accuracy: 0.3747 - loss: 10.0781 getitem, batch_nr 981 train is: True\n",
      "\u001b[1m 981/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:34\u001b[0m 5s/step - accuracy: 0.3748 - loss: 10.0772 getitem, batch_nr 982 train is: True\n",
      "\u001b[1m 982/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:29\u001b[0m 5s/step - accuracy: 0.3748 - loss: 10.0763 getitem, batch_nr 983 train is: True\n",
      "\u001b[1m 983/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:24\u001b[0m 5s/step - accuracy: 0.3749 - loss: 10.0754 getitem, batch_nr 984 train is: True\n",
      "\u001b[1m 984/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:19\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0746 getitem, batch_nr 985 train is: True\n",
      "\u001b[1m 985/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:14\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0737 getitem, batch_nr 986 train is: True\n",
      "\u001b[1m 986/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:09\u001b[0m 5s/step - accuracy: 0.3751 - loss: 10.0728 getitem, batch_nr 987 train is: True\n",
      "\u001b[1m 987/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28:04\u001b[0m 5s/step - accuracy: 0.3751 - loss: 10.0719 getitem, batch_nr 988 train is: True\n",
      "\u001b[1m 988/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:59\u001b[0m 5s/step - accuracy: 0.3752 - loss: 10.0710 getitem, batch_nr 989 train is: True\n",
      "\u001b[1m 989/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:53\u001b[0m 5s/step - accuracy: 0.3752 - loss: 10.0702 getitem, batch_nr 990 train is: True\n",
      "\u001b[1m 990/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:48\u001b[0m 5s/step - accuracy: 0.3753 - loss: 10.0693 getitem, batch_nr 991 train is: True\n",
      "\u001b[1m 991/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:43\u001b[0m 5s/step - accuracy: 0.3753 - loss: 10.0684 getitem, batch_nr 992 train is: True\n",
      "\u001b[1m 992/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:38\u001b[0m 5s/step - accuracy: 0.3754 - loss: 10.0675 getitem, batch_nr 993 train is: True\n",
      "\u001b[1m 993/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:33\u001b[0m 5s/step - accuracy: 0.3754 - loss: 10.0666 getitem, batch_nr 994 train is: True\n",
      "\u001b[1m 994/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:28\u001b[0m 5s/step - accuracy: 0.3755 - loss: 10.0658 getitem, batch_nr 995 train is: True\n",
      "\u001b[1m 995/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:23\u001b[0m 5s/step - accuracy: 0.3756 - loss: 10.0649 getitem, batch_nr 996 train is: True\n",
      "\u001b[1m 996/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:18\u001b[0m 5s/step - accuracy: 0.3756 - loss: 10.0640 getitem, batch_nr 997 train is: True\n",
      "\u001b[1m 997/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:13\u001b[0m 5s/step - accuracy: 0.3757 - loss: 10.0631 getitem, batch_nr 998 train is: True\n",
      "\u001b[1m 998/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:07\u001b[0m 5s/step - accuracy: 0.3757 - loss: 10.0622 getitem, batch_nr 999 train is: True\n",
      "\u001b[1m 999/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:02\u001b[0m 5s/step - accuracy: 0.3758 - loss: 10.0614 getitem, batch_nr 1000 train is: True\n",
      "\u001b[1m1000/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:57\u001b[0m 5s/step - accuracy: 0.3758 - loss: 10.0605 getitem, batch_nr 1001 train is: True\n",
      "\u001b[1m1001/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:52\u001b[0m 5s/step - accuracy: 0.3759 - loss: 10.0596 getitem, batch_nr 1002 train is: True\n",
      "\u001b[1m1002/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:47\u001b[0m 5s/step - accuracy: 0.3759 - loss: 10.0587 getitem, batch_nr 1003 train is: True\n",
      "\u001b[1m1003/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:42\u001b[0m 5s/step - accuracy: 0.3760 - loss: 10.0578 getitem, batch_nr 1004 train is: True\n",
      "\u001b[1m1004/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:37\u001b[0m 5s/step - accuracy: 0.3760 - loss: 10.0569 getitem, batch_nr 1005 train is: True\n",
      "\u001b[1m1005/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:32\u001b[0m 5s/step - accuracy: 0.3761 - loss: 10.0561 getitem, batch_nr 1006 train is: True\n",
      "\u001b[1m1006/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:26\u001b[0m 5s/step - accuracy: 0.3762 - loss: 10.0552 getitem, batch_nr 1007 train is: True\n",
      "\u001b[1m1007/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:21\u001b[0m 5s/step - accuracy: 0.3762 - loss: 10.0543 getitem, batch_nr 1008 train is: True\n",
      "\u001b[1m1008/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:16\u001b[0m 5s/step - accuracy: 0.3763 - loss: 10.0534 getitem, batch_nr 1009 train is: True\n",
      "\u001b[1m1009/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:11\u001b[0m 5s/step - accuracy: 0.3763 - loss: 10.0526 getitem, batch_nr 1010 train is: True\n",
      "\u001b[1m1010/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:06\u001b[0m 5s/step - accuracy: 0.3764 - loss: 10.0517 getitem, batch_nr 1011 train is: True\n",
      "\u001b[1m1011/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:01\u001b[0m 5s/step - accuracy: 0.3764 - loss: 10.0508 getitem, batch_nr 1012 train is: True\n",
      "\u001b[1m1012/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:56\u001b[0m 5s/step - accuracy: 0.3765 - loss: 10.0499 getitem, batch_nr 1013 train is: True\n",
      "\u001b[1m1013/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:51\u001b[0m 5s/step - accuracy: 0.3765 - loss: 10.0491 getitem, batch_nr 1014 train is: True\n",
      "\u001b[1m1014/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:46\u001b[0m 5s/step - accuracy: 0.3766 - loss: 10.0482 getitem, batch_nr 1015 train is: True\n",
      "\u001b[1m1015/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:40\u001b[0m 5s/step - accuracy: 0.3766 - loss: 10.0473 getitem, batch_nr 1016 train is: True\n",
      "\u001b[1m1016/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:35\u001b[0m 5s/step - accuracy: 0.3767 - loss: 10.0465 getitem, batch_nr 1017 train is: True\n",
      "\u001b[1m1017/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:30\u001b[0m 5s/step - accuracy: 0.3768 - loss: 10.0456 getitem, batch_nr 1018 train is: True\n",
      "\u001b[1m1018/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:25\u001b[0m 5s/step - accuracy: 0.3768 - loss: 10.0447 getitem, batch_nr 1019 train is: True\n",
      "\u001b[1m1019/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:20\u001b[0m 5s/step - accuracy: 0.3769 - loss: 10.0439 getitem, batch_nr 1020 train is: True\n",
      "\u001b[1m1020/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:15\u001b[0m 5s/step - accuracy: 0.3769 - loss: 10.0430 getitem, batch_nr 1021 train is: True\n",
      "\u001b[1m1021/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:10\u001b[0m 5s/step - accuracy: 0.3770 - loss: 10.0421 getitem, batch_nr 1022 train is: True\n",
      "\u001b[1m1022/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:05\u001b[0m 5s/step - accuracy: 0.3770 - loss: 10.0413 getitem, batch_nr 1023 train is: True\n",
      "\u001b[1m1023/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:59\u001b[0m 5s/step - accuracy: 0.3771 - loss: 10.0404 getitem, batch_nr 1024 train is: True\n",
      "\u001b[1m1024/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:54\u001b[0m 5s/step - accuracy: 0.3771 - loss: 10.0395 getitem, batch_nr 1025 train is: True\n",
      "\u001b[1m1025/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:49\u001b[0m 5s/step - accuracy: 0.3772 - loss: 10.0387 getitem, batch_nr 1026 train is: True\n",
      "\u001b[1m1026/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:44\u001b[0m 5s/step - accuracy: 0.3772 - loss: 10.0378 getitem, batch_nr 1027 train is: True\n",
      "\u001b[1m1027/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:39\u001b[0m 5s/step - accuracy: 0.3773 - loss: 10.0369 getitem, batch_nr 1028 train is: True\n",
      "\u001b[1m1028/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:34\u001b[0m 5s/step - accuracy: 0.3773 - loss: 10.0361 getitem, batch_nr 1029 train is: True\n",
      "\u001b[1m1029/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:29\u001b[0m 5s/step - accuracy: 0.3774 - loss: 10.0352 getitem, batch_nr 1030 train is: True\n",
      "\u001b[1m1030/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:24\u001b[0m 5s/step - accuracy: 0.3774 - loss: 10.0344 getitem, batch_nr 1031 train is: True\n",
      "\u001b[1m1031/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:19\u001b[0m 5s/step - accuracy: 0.3775 - loss: 10.0335 getitem, batch_nr 1032 train is: True\n",
      "\u001b[1m1032/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:13\u001b[0m 5s/step - accuracy: 0.3776 - loss: 10.0327 getitem, batch_nr 1033 train is: True\n",
      "\u001b[1m1033/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:08\u001b[0m 5s/step - accuracy: 0.3776 - loss: 10.0318 getitem, batch_nr 1034 train is: True\n",
      "\u001b[1m1034/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:03\u001b[0m 5s/step - accuracy: 0.3777 - loss: 10.0309 getitem, batch_nr 1035 train is: True\n",
      "\u001b[1m1035/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:58\u001b[0m 5s/step - accuracy: 0.3777 - loss: 10.0301 getitem, batch_nr 1036 train is: True\n",
      "\u001b[1m1036/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:53\u001b[0m 5s/step - accuracy: 0.3778 - loss: 10.0292 getitem, batch_nr 1037 train is: True\n",
      "\u001b[1m1037/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:48\u001b[0m 5s/step - accuracy: 0.3778 - loss: 10.0284 getitem, batch_nr 1038 train is: True\n",
      "\u001b[1m1038/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:43\u001b[0m 5s/step - accuracy: 0.3779 - loss: 10.0275 getitem, batch_nr 1039 train is: True\n",
      "\u001b[1m1039/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:38\u001b[0m 5s/step - accuracy: 0.3779 - loss: 10.0267 getitem, batch_nr 1040 train is: True\n",
      "\u001b[1m1040/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:32\u001b[0m 5s/step - accuracy: 0.3780 - loss: 10.0258 getitem, batch_nr 1041 train is: True\n",
      "\u001b[1m1041/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:27\u001b[0m 5s/step - accuracy: 0.3780 - loss: 10.0249 getitem, batch_nr 1042 train is: True\n",
      "\u001b[1m1042/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:22\u001b[0m 5s/step - accuracy: 0.3781 - loss: 10.0241 getitem, batch_nr 1043 train is: True\n",
      "\u001b[1m1043/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:17\u001b[0m 5s/step - accuracy: 0.3781 - loss: 10.0232 getitem, batch_nr 1044 train is: True\n",
      "\u001b[1m1044/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:12\u001b[0m 5s/step - accuracy: 0.3782 - loss: 10.0224 getitem, batch_nr 1045 train is: True\n",
      "\u001b[1m1045/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:07\u001b[0m 5s/step - accuracy: 0.3782 - loss: 10.0215 getitem, batch_nr 1046 train is: True\n",
      "\u001b[1m1046/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:02\u001b[0m 5s/step - accuracy: 0.3783 - loss: 10.0207 getitem, batch_nr 1047 train is: True\n",
      "\u001b[1m1047/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:57\u001b[0m 5s/step - accuracy: 0.3784 - loss: 10.0198 getitem, batch_nr 1048 train is: True\n",
      "\u001b[1m1048/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:52\u001b[0m 5s/step - accuracy: 0.3784 - loss: 10.0189 getitem, batch_nr 1049 train is: True\n",
      "\u001b[1m1049/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:46\u001b[0m 5s/step - accuracy: 0.3785 - loss: 10.0181 getitem, batch_nr 1050 train is: True\n",
      "\u001b[1m1050/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:41\u001b[0m 5s/step - accuracy: 0.3785 - loss: 10.0172 getitem, batch_nr 1051 train is: True\n",
      "\u001b[1m1051/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:36\u001b[0m 5s/step - accuracy: 0.3786 - loss: 10.0164 getitem, batch_nr 1052 train is: True\n",
      "\u001b[1m1052/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:31\u001b[0m 5s/step - accuracy: 0.3786 - loss: 10.0155 getitem, batch_nr 1053 train is: True\n",
      "\u001b[1m1053/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:26\u001b[0m 5s/step - accuracy: 0.3787 - loss: 10.0147 getitem, batch_nr 1054 train is: True\n",
      "\u001b[1m1054/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:21\u001b[0m 5s/step - accuracy: 0.3787 - loss: 10.0138 getitem, batch_nr 1055 train is: True\n",
      "\u001b[1m1055/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:16\u001b[0m 5s/step - accuracy: 0.3788 - loss: 10.0130 getitem, batch_nr 1056 train is: True\n",
      "\u001b[1m1056/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:11\u001b[0m 5s/step - accuracy: 0.3788 - loss: 10.0121 getitem, batch_nr 1057 train is: True\n",
      "\u001b[1m1057/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:06\u001b[0m 5s/step - accuracy: 0.3789 - loss: 10.0113 getitem, batch_nr 1058 train is: True\n",
      "\u001b[1m1058/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:00\u001b[0m 5s/step - accuracy: 0.3789 - loss: 10.0104 getitem, batch_nr 1059 train is: True\n",
      "\u001b[1m1059/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:55\u001b[0m 5s/step - accuracy: 0.3790 - loss: 10.0096 getitem, batch_nr 1060 train is: True\n",
      "\u001b[1m1060/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:50\u001b[0m 5s/step - accuracy: 0.3790 - loss: 10.0087 getitem, batch_nr 1061 train is: True\n",
      "\u001b[1m1061/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:45\u001b[0m 5s/step - accuracy: 0.3791 - loss: 10.0079 getitem, batch_nr 1062 train is: True\n",
      "\u001b[1m1062/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:40\u001b[0m 5s/step - accuracy: 0.3791 - loss: 10.0071 getitem, batch_nr 1063 train is: True\n",
      "\u001b[1m1063/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:35\u001b[0m 5s/step - accuracy: 0.3792 - loss: 10.0062 getitem, batch_nr 1064 train is: True\n",
      "\u001b[1m1064/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:30\u001b[0m 5s/step - accuracy: 0.3792 - loss: 10.0054 getitem, batch_nr 1065 train is: True\n",
      "\u001b[1m1065/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:25\u001b[0m 5s/step - accuracy: 0.3793 - loss: 10.0045 getitem, batch_nr 1066 train is: True\n",
      "\u001b[1m1066/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:19\u001b[0m 5s/step - accuracy: 0.3793 - loss: 10.0037 getitem, batch_nr 1067 train is: True\n",
      "\u001b[1m1067/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:14\u001b[0m 5s/step - accuracy: 0.3794 - loss: 10.0029 getitem, batch_nr 1068 train is: True\n",
      "\u001b[1m1068/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:09\u001b[0m 5s/step - accuracy: 0.3795 - loss: 10.0020 getitem, batch_nr 1069 train is: True\n",
      "\u001b[1m1069/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:04\u001b[0m 5s/step - accuracy: 0.3795 - loss: 10.0012 getitem, batch_nr 1070 train is: True\n",
      "\u001b[1m1070/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:59\u001b[0m 5s/step - accuracy: 0.3796 - loss: 10.0004 getitem, batch_nr 1071 train is: True\n",
      "\u001b[1m1071/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:54\u001b[0m 5s/step - accuracy: 0.3796 - loss: 9.9995  getitem, batch_nr 1072 train is: True\n",
      "\u001b[1m1072/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:49\u001b[0m 5s/step - accuracy: 0.3797 - loss: 9.9987 getitem, batch_nr 1073 train is: True\n",
      "\u001b[1m1073/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:44\u001b[0m 5s/step - accuracy: 0.3797 - loss: 9.9979 getitem, batch_nr 1074 train is: True\n",
      "\u001b[1m1074/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:39\u001b[0m 5s/step - accuracy: 0.3798 - loss: 9.9971 getitem, batch_nr 1075 train is: True\n",
      "\u001b[1m1075/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:33\u001b[0m 5s/step - accuracy: 0.3798 - loss: 9.9962 getitem, batch_nr 1076 train is: True\n",
      "\u001b[1m1076/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:28\u001b[0m 5s/step - accuracy: 0.3799 - loss: 9.9954 getitem, batch_nr 1077 train is: True\n",
      "\u001b[1m1077/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:23\u001b[0m 5s/step - accuracy: 0.3799 - loss: 9.9946 getitem, batch_nr 1078 train is: True\n",
      "\u001b[1m1078/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:18\u001b[0m 5s/step - accuracy: 0.3800 - loss: 9.9938 getitem, batch_nr 1079 train is: True\n",
      "\u001b[1m1079/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:13\u001b[0m 5s/step - accuracy: 0.3800 - loss: 9.9929 getitem, batch_nr 1080 train is: True\n",
      "\u001b[1m1080/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:08\u001b[0m 5s/step - accuracy: 0.3801 - loss: 9.9921 getitem, batch_nr 1081 train is: True\n",
      "\u001b[1m1081/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:03\u001b[0m 5s/step - accuracy: 0.3801 - loss: 9.9913 getitem, batch_nr 1082 train is: True\n",
      "\u001b[1m1082/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:58\u001b[0m 5s/step - accuracy: 0.3802 - loss: 9.9905 getitem, batch_nr 1083 train is: True\n",
      "\u001b[1m1083/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:52\u001b[0m 5s/step - accuracy: 0.3802 - loss: 9.9897 getitem, batch_nr 1084 train is: True\n",
      "\u001b[1m1084/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:47\u001b[0m 5s/step - accuracy: 0.3803 - loss: 9.9889 getitem, batch_nr 1085 train is: True\n",
      "\u001b[1m1085/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:42\u001b[0m 5s/step - accuracy: 0.3803 - loss: 9.9880 getitem, batch_nr 1086 train is: True\n",
      "\u001b[1m1086/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:37\u001b[0m 5s/step - accuracy: 0.3804 - loss: 9.9872 getitem, batch_nr 1087 train is: True\n",
      "\u001b[1m1087/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:32\u001b[0m 5s/step - accuracy: 0.3804 - loss: 9.9864 getitem, batch_nr 1088 train is: True\n",
      "\u001b[1m1088/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:27\u001b[0m 5s/step - accuracy: 0.3805 - loss: 9.9856 getitem, batch_nr 1089 train is: True\n",
      "\u001b[1m1089/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:22\u001b[0m 5s/step - accuracy: 0.3805 - loss: 9.9848 getitem, batch_nr 1090 train is: True\n",
      "\u001b[1m1090/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:17\u001b[0m 5s/step - accuracy: 0.3806 - loss: 9.9840 getitem, batch_nr 1091 train is: True\n",
      "\u001b[1m1091/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:12\u001b[0m 5s/step - accuracy: 0.3806 - loss: 9.9832 getitem, batch_nr 1092 train is: True\n",
      "\u001b[1m1092/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:06\u001b[0m 5s/step - accuracy: 0.3807 - loss: 9.9824 getitem, batch_nr 1093 train is: True\n",
      "\u001b[1m1093/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:01\u001b[0m 5s/step - accuracy: 0.3807 - loss: 9.9815 getitem, batch_nr 1094 train is: True\n",
      "\u001b[1m1094/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:56\u001b[0m 5s/step - accuracy: 0.3808 - loss: 9.9807 getitem, batch_nr 1095 train is: True\n",
      "\u001b[1m1095/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:51\u001b[0m 5s/step - accuracy: 0.3808 - loss: 9.9799 getitem, batch_nr 1096 train is: True\n",
      "\u001b[1m1096/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:46\u001b[0m 5s/step - accuracy: 0.3809 - loss: 9.9791 getitem, batch_nr 1097 train is: True\n",
      "\u001b[1m1097/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:41\u001b[0m 5s/step - accuracy: 0.3809 - loss: 9.9783 getitem, batch_nr 1098 train is: True\n",
      "\u001b[1m1098/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:36\u001b[0m 5s/step - accuracy: 0.3810 - loss: 9.9775 getitem, batch_nr 1099 train is: True\n",
      "\u001b[1m1099/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:31\u001b[0m 5s/step - accuracy: 0.3810 - loss: 9.9767 getitem, batch_nr 1100 train is: True\n",
      "\u001b[1m1100/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:26\u001b[0m 5s/step - accuracy: 0.3811 - loss: 9.9759 getitem, batch_nr 1101 train is: True\n",
      "\u001b[1m1101/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:20\u001b[0m 5s/step - accuracy: 0.3811 - loss: 9.9751 getitem, batch_nr 1102 train is: True\n",
      "\u001b[1m1102/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:15\u001b[0m 5s/step - accuracy: 0.3812 - loss: 9.9743 getitem, batch_nr 1103 train is: True\n",
      "\u001b[1m1103/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:10\u001b[0m 5s/step - accuracy: 0.3812 - loss: 9.9734 getitem, batch_nr 1104 train is: True\n",
      "\u001b[1m1104/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:05\u001b[0m 5s/step - accuracy: 0.3813 - loss: 9.9726 getitem, batch_nr 1105 train is: True\n",
      "\u001b[1m1105/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:00\u001b[0m 5s/step - accuracy: 0.3813 - loss: 9.9718 getitem, batch_nr 1106 train is: True\n",
      "\u001b[1m1106/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:55\u001b[0m 5s/step - accuracy: 0.3814 - loss: 9.9710 getitem, batch_nr 1107 train is: True\n",
      "\u001b[1m1107/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:50\u001b[0m 5s/step - accuracy: 0.3814 - loss: 9.9702 getitem, batch_nr 1108 train is: True\n",
      "\u001b[1m1108/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:45\u001b[0m 5s/step - accuracy: 0.3815 - loss: 9.9694 getitem, batch_nr 1109 train is: True\n",
      "\u001b[1m1109/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:39\u001b[0m 5s/step - accuracy: 0.3815 - loss: 9.9686 getitem, batch_nr 1110 train is: True\n",
      "\u001b[1m1110/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:34\u001b[0m 5s/step - accuracy: 0.3816 - loss: 9.9678 getitem, batch_nr 1111 train is: True\n",
      "\u001b[1m1111/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:29\u001b[0m 5s/step - accuracy: 0.3816 - loss: 9.9670 getitem, batch_nr 1112 train is: True\n",
      "\u001b[1m1112/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:24\u001b[0m 5s/step - accuracy: 0.3817 - loss: 9.9662 getitem, batch_nr 1113 train is: True\n",
      "\u001b[1m1113/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:19\u001b[0m 5s/step - accuracy: 0.3817 - loss: 9.9654 getitem, batch_nr 1114 train is: True\n",
      "\u001b[1m1114/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:14\u001b[0m 5s/step - accuracy: 0.3818 - loss: 9.9646 getitem, batch_nr 1115 train is: True\n",
      "\u001b[1m1115/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:09\u001b[0m 5s/step - accuracy: 0.3818 - loss: 9.9638 getitem, batch_nr 1116 train is: True\n",
      "\u001b[1m1116/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:04\u001b[0m 5s/step - accuracy: 0.3819 - loss: 9.9630 getitem, batch_nr 1117 train is: True\n",
      "\u001b[1m1117/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m16:58\u001b[0m 5s/step - accuracy: 0.3819 - loss: 9.9622 getitem, batch_nr 1118 train is: True\n",
      "\u001b[1m1118/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m16:53\u001b[0m 5s/step - accuracy: 0.3820 - loss: 9.9614 getitem, batch_nr 1119 train is: True\n",
      "\u001b[1m1119/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:48\u001b[0m 5s/step - accuracy: 0.3820 - loss: 9.9606 getitem, batch_nr 1120 train is: True\n",
      "\u001b[1m1120/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:43\u001b[0m 5s/step - accuracy: 0.3821 - loss: 9.9598 getitem, batch_nr 1121 train is: True\n",
      "\u001b[1m1121/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:38\u001b[0m 5s/step - accuracy: 0.3821 - loss: 9.9590 getitem, batch_nr 1122 train is: True\n",
      "\u001b[1m1122/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:33\u001b[0m 5s/step - accuracy: 0.3822 - loss: 9.9582 getitem, batch_nr 1123 train is: True\n",
      "\u001b[1m1123/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:28\u001b[0m 5s/step - accuracy: 0.3822 - loss: 9.9574 getitem, batch_nr 1124 train is: True\n",
      "\u001b[1m1124/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:23\u001b[0m 5s/step - accuracy: 0.3823 - loss: 9.9566 getitem, batch_nr 1125 train is: True\n",
      "\u001b[1m1125/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:18\u001b[0m 5s/step - accuracy: 0.3823 - loss: 9.9558 getitem, batch_nr 1126 train is: True\n",
      "\u001b[1m1126/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:12\u001b[0m 5s/step - accuracy: 0.3824 - loss: 9.9551 getitem, batch_nr 1127 train is: True\n",
      "\u001b[1m1127/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:07\u001b[0m 5s/step - accuracy: 0.3824 - loss: 9.9543 getitem, batch_nr 1128 train is: True\n",
      "\u001b[1m1128/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:02\u001b[0m 5s/step - accuracy: 0.3825 - loss: 9.9535 getitem, batch_nr 1129 train is: True\n",
      "\u001b[1m1129/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:57\u001b[0m 5s/step - accuracy: 0.3825 - loss: 9.9527 getitem, batch_nr 1130 train is: True\n",
      "\u001b[1m1130/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:52\u001b[0m 5s/step - accuracy: 0.3826 - loss: 9.9519 getitem, batch_nr 1131 train is: True\n",
      "\u001b[1m1131/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:47\u001b[0m 5s/step - accuracy: 0.3826 - loss: 9.9511 getitem, batch_nr 1132 train is: True\n",
      "\u001b[1m1132/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:42\u001b[0m 5s/step - accuracy: 0.3827 - loss: 9.9503 getitem, batch_nr 1133 train is: True\n",
      "\u001b[1m1133/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:37\u001b[0m 5s/step - accuracy: 0.3827 - loss: 9.9496 getitem, batch_nr 1134 train is: True\n",
      "\u001b[1m1134/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:31\u001b[0m 5s/step - accuracy: 0.3828 - loss: 9.9488 getitem, batch_nr 1135 train is: True\n",
      "\u001b[1m1135/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:26\u001b[0m 5s/step - accuracy: 0.3828 - loss: 9.9480 getitem, batch_nr 1136 train is: True\n",
      "\u001b[1m1136/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:21\u001b[0m 5s/step - accuracy: 0.3829 - loss: 9.9472 getitem, batch_nr 1137 train is: True\n",
      "\u001b[1m1137/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:16\u001b[0m 5s/step - accuracy: 0.3829 - loss: 9.9464 getitem, batch_nr 1138 train is: True\n",
      "\u001b[1m1138/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:11\u001b[0m 5s/step - accuracy: 0.3830 - loss: 9.9457 getitem, batch_nr 1139 train is: True\n",
      "\u001b[1m1139/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:06\u001b[0m 5s/step - accuracy: 0.3830 - loss: 9.9449 getitem, batch_nr 1140 train is: True\n",
      "\u001b[1m1140/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:01\u001b[0m 5s/step - accuracy: 0.3830 - loss: 9.9441 getitem, batch_nr 1141 train is: True\n",
      "\u001b[1m1141/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:56\u001b[0m 5s/step - accuracy: 0.3831 - loss: 9.9433 getitem, batch_nr 1142 train is: True\n",
      "\u001b[1m1142/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:51\u001b[0m 5s/step - accuracy: 0.3831 - loss: 9.9426 getitem, batch_nr 1143 train is: True\n",
      "\u001b[1m1143/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:45\u001b[0m 5s/step - accuracy: 0.3832 - loss: 9.9418 getitem, batch_nr 1144 train is: True\n",
      "\u001b[1m1144/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:40\u001b[0m 5s/step - accuracy: 0.3832 - loss: 9.9410 getitem, batch_nr 1145 train is: True\n",
      "\u001b[1m1145/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:35\u001b[0m 5s/step - accuracy: 0.3833 - loss: 9.9403 getitem, batch_nr 1146 train is: True\n",
      "\u001b[1m1146/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:30\u001b[0m 5s/step - accuracy: 0.3833 - loss: 9.9395 getitem, batch_nr 1147 train is: True\n",
      "\u001b[1m1147/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:25\u001b[0m 5s/step - accuracy: 0.3834 - loss: 9.9387 getitem, batch_nr 1148 train is: True\n",
      "\u001b[1m1148/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:20\u001b[0m 5s/step - accuracy: 0.3834 - loss: 9.9379 getitem, batch_nr 1149 train is: True\n",
      "\u001b[1m1149/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:15\u001b[0m 5s/step - accuracy: 0.3835 - loss: 9.9372 getitem, batch_nr 1150 train is: True\n",
      "\u001b[1m1150/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:10\u001b[0m 5s/step - accuracy: 0.3835 - loss: 9.9364 getitem, batch_nr 1151 train is: True\n",
      "\u001b[1m1151/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:04\u001b[0m 5s/step - accuracy: 0.3836 - loss: 9.9356 getitem, batch_nr 1152 train is: True\n",
      "\u001b[1m1152/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:59\u001b[0m 5s/step - accuracy: 0.3836 - loss: 9.9349 getitem, batch_nr 1153 train is: True\n",
      "\u001b[1m1153/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:54\u001b[0m 5s/step - accuracy: 0.3837 - loss: 9.9341 getitem, batch_nr 1154 train is: True\n",
      "\u001b[1m1154/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:49\u001b[0m 5s/step - accuracy: 0.3837 - loss: 9.9333 getitem, batch_nr 1155 train is: True\n",
      "\u001b[1m1155/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:44\u001b[0m 5s/step - accuracy: 0.3838 - loss: 9.9325 getitem, batch_nr 1156 train is: True\n",
      "\u001b[1m1156/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:39\u001b[0m 5s/step - accuracy: 0.3838 - loss: 9.9318 getitem, batch_nr 1157 train is: True\n",
      "\u001b[1m1157/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:34\u001b[0m 5s/step - accuracy: 0.3839 - loss: 9.9310 getitem, batch_nr 1158 train is: True\n",
      "\u001b[1m1158/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:29\u001b[0m 5s/step - accuracy: 0.3839 - loss: 9.9302 getitem, batch_nr 1159 train is: True\n",
      "\u001b[1m1159/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:24\u001b[0m 5s/step - accuracy: 0.3840 - loss: 9.9295 getitem, batch_nr 1160 train is: True\n",
      "\u001b[1m1160/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:18\u001b[0m 5s/step - accuracy: 0.3840 - loss: 9.9287 getitem, batch_nr 1161 train is: True\n",
      "\u001b[1m1161/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:13\u001b[0m 5s/step - accuracy: 0.3841 - loss: 9.9279 getitem, batch_nr 1162 train is: True\n",
      "\u001b[1m1162/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:08\u001b[0m 5s/step - accuracy: 0.3841 - loss: 9.9271 getitem, batch_nr 1163 train is: True\n",
      "\u001b[1m1163/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:03\u001b[0m 5s/step - accuracy: 0.3841 - loss: 9.9264 getitem, batch_nr 1164 train is: True\n",
      "\u001b[1m1164/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:58\u001b[0m 5s/step - accuracy: 0.3842 - loss: 9.9256 getitem, batch_nr 1165 train is: True\n",
      "\u001b[1m1165/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:53\u001b[0m 5s/step - accuracy: 0.3842 - loss: 9.9249 getitem, batch_nr 1166 train is: True\n",
      "\u001b[1m1166/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:48\u001b[0m 5s/step - accuracy: 0.3843 - loss: 9.9241 getitem, batch_nr 1167 train is: True\n",
      "\u001b[1m1167/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:43\u001b[0m 5s/step - accuracy: 0.3843 - loss: 9.9233 getitem, batch_nr 1168 train is: True\n",
      "\u001b[1m1168/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:37\u001b[0m 5s/step - accuracy: 0.3844 - loss: 9.9226 getitem, batch_nr 1169 train is: True\n",
      "\u001b[1m1169/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:32\u001b[0m 5s/step - accuracy: 0.3844 - loss: 9.9218 getitem, batch_nr 1170 train is: True\n",
      "\u001b[1m1170/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:27\u001b[0m 5s/step - accuracy: 0.3845 - loss: 9.9211 getitem, batch_nr 1171 train is: True\n",
      "\u001b[1m1171/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:22\u001b[0m 5s/step - accuracy: 0.3845 - loss: 9.9203 getitem, batch_nr 1172 train is: True\n",
      "\u001b[1m1172/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:17\u001b[0m 5s/step - accuracy: 0.3846 - loss: 9.9196 getitem, batch_nr 1173 train is: True\n",
      "\u001b[1m1173/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:12\u001b[0m 5s/step - accuracy: 0.3846 - loss: 9.9188 getitem, batch_nr 1174 train is: True\n",
      "\u001b[1m1174/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:07\u001b[0m 5s/step - accuracy: 0.3847 - loss: 9.9180 getitem, batch_nr 1175 train is: True\n",
      "\u001b[1m1175/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:02\u001b[0m 5s/step - accuracy: 0.3847 - loss: 9.9173 getitem, batch_nr 1176 train is: True\n",
      "\u001b[1m1176/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:57\u001b[0m 5s/step - accuracy: 0.3848 - loss: 9.9165 getitem, batch_nr 1177 train is: True\n",
      "\u001b[1m1177/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:51\u001b[0m 5s/step - accuracy: 0.3848 - loss: 9.9158 getitem, batch_nr 1178 train is: True\n",
      "\u001b[1m1178/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:46\u001b[0m 5s/step - accuracy: 0.3849 - loss: 9.9150 getitem, batch_nr 1179 train is: True\n",
      "\u001b[1m1179/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:41\u001b[0m 5s/step - accuracy: 0.3849 - loss: 9.9143 getitem, batch_nr 1180 train is: True\n",
      "\u001b[1m1180/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:36\u001b[0m 5s/step - accuracy: 0.3849 - loss: 9.9135 getitem, batch_nr 1181 train is: True\n",
      "\u001b[1m1181/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:31\u001b[0m 5s/step - accuracy: 0.3850 - loss: 9.9128 getitem, batch_nr 1182 train is: True\n",
      "\u001b[1m1182/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:26\u001b[0m 5s/step - accuracy: 0.3850 - loss: 9.9120 getitem, batch_nr 1183 train is: True\n",
      "\u001b[1m1183/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:21\u001b[0m 5s/step - accuracy: 0.3851 - loss: 9.9113 getitem, batch_nr 1184 train is: True\n",
      "\u001b[1m1184/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:16\u001b[0m 5s/step - accuracy: 0.3851 - loss: 9.9105 getitem, batch_nr 1185 train is: True\n",
      "\u001b[1m1185/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:10\u001b[0m 5s/step - accuracy: 0.3852 - loss: 9.9098 getitem, batch_nr 1186 train is: True\n",
      "\u001b[1m1186/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:05\u001b[0m 5s/step - accuracy: 0.3852 - loss: 9.9090 getitem, batch_nr 1187 train is: True\n",
      "\u001b[1m1187/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:00\u001b[0m 5s/step - accuracy: 0.3853 - loss: 9.9083 getitem, batch_nr 1188 train is: True\n",
      "\u001b[1m1188/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:55\u001b[0m 5s/step - accuracy: 0.3853 - loss: 9.9076 getitem, batch_nr 1189 train is: True\n",
      "\u001b[1m1189/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:50\u001b[0m 5s/step - accuracy: 0.3854 - loss: 9.9068 getitem, batch_nr 1190 train is: True\n",
      "\u001b[1m1190/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:45\u001b[0m 5s/step - accuracy: 0.3854 - loss: 9.9061 getitem, batch_nr 1191 train is: True\n",
      "\u001b[1m1191/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:40\u001b[0m 5s/step - accuracy: 0.3855 - loss: 9.9053 getitem, batch_nr 1192 train is: True\n",
      "\u001b[1m1192/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:35\u001b[0m 5s/step - accuracy: 0.3855 - loss: 9.9046 getitem, batch_nr 1193 train is: True\n",
      "\u001b[1m1193/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:29\u001b[0m 5s/step - accuracy: 0.3855 - loss: 9.9039 getitem, batch_nr 1194 train is: True\n",
      "\u001b[1m1194/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:24\u001b[0m 5s/step - accuracy: 0.3856 - loss: 9.9031 getitem, batch_nr 1195 train is: True\n",
      "\u001b[1m1195/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:19\u001b[0m 5s/step - accuracy: 0.3856 - loss: 9.9024 getitem, batch_nr 1196 train is: True\n",
      "\u001b[1m1196/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:14\u001b[0m 5s/step - accuracy: 0.3857 - loss: 9.9017 getitem, batch_nr 1197 train is: True\n",
      "\u001b[1m1197/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:09\u001b[0m 5s/step - accuracy: 0.3857 - loss: 9.9009 getitem, batch_nr 1198 train is: True\n",
      "\u001b[1m1198/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:04\u001b[0m 5s/step - accuracy: 0.3858 - loss: 9.9002 getitem, batch_nr 1199 train is: True\n",
      "\u001b[1m1199/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:59\u001b[0m 5s/step - accuracy: 0.3858 - loss: 9.8995  getitem, batch_nr 1200 train is: True\n",
      "\u001b[1m1200/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:54\u001b[0m 5s/step - accuracy: 0.3859 - loss: 9.8988 getitem, batch_nr 1201 train is: True\n",
      "\u001b[1m1201/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:49\u001b[0m 5s/step - accuracy: 0.3859 - loss: 9.8980 getitem, batch_nr 1202 train is: True\n",
      "\u001b[1m1202/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:43\u001b[0m 5s/step - accuracy: 0.3860 - loss: 9.8973 getitem, batch_nr 1203 train is: True\n",
      "\u001b[1m1203/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:38\u001b[0m 5s/step - accuracy: 0.3860 - loss: 9.8966 getitem, batch_nr 1204 train is: True\n",
      "\u001b[1m1204/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:33\u001b[0m 5s/step - accuracy: 0.3860 - loss: 9.8959 getitem, batch_nr 1205 train is: True\n",
      "\u001b[1m1205/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:28\u001b[0m 5s/step - accuracy: 0.3861 - loss: 9.8951 getitem, batch_nr 1206 train is: True\n",
      "\u001b[1m1206/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:23\u001b[0m 5s/step - accuracy: 0.3861 - loss: 9.8944 getitem, batch_nr 1207 train is: True\n",
      "\u001b[1m1207/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:18\u001b[0m 5s/step - accuracy: 0.3862 - loss: 9.8937 getitem, batch_nr 1208 train is: True\n",
      "\u001b[1m1208/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:13\u001b[0m 5s/step - accuracy: 0.3862 - loss: 9.8930 getitem, batch_nr 1209 train is: True\n",
      "\u001b[1m1209/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:08\u001b[0m 5s/step - accuracy: 0.3863 - loss: 9.8922 getitem, batch_nr 1210 train is: True\n",
      "\u001b[1m1210/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:02\u001b[0m 5s/step - accuracy: 0.3863 - loss: 9.8915 getitem, batch_nr 1211 train is: True\n",
      "\u001b[1m1211/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:57\u001b[0m 5s/step - accuracy: 0.3864 - loss: 9.8908 getitem, batch_nr 1212 train is: True\n",
      "\u001b[1m1212/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:52\u001b[0m 5s/step - accuracy: 0.3864 - loss: 9.8901 getitem, batch_nr 1213 train is: True\n",
      "\u001b[1m1213/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:47\u001b[0m 5s/step - accuracy: 0.3864 - loss: 9.8894 getitem, batch_nr 1214 train is: True\n",
      "\u001b[1m1214/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:42\u001b[0m 5s/step - accuracy: 0.3865 - loss: 9.8887 getitem, batch_nr 1215 train is: True\n",
      "\u001b[1m1215/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:37\u001b[0m 5s/step - accuracy: 0.3865 - loss: 9.8880 getitem, batch_nr 1216 train is: True\n",
      "\u001b[1m1216/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:32\u001b[0m 5s/step - accuracy: 0.3866 - loss: 9.8873 getitem, batch_nr 1217 train is: True\n",
      "\u001b[1m1217/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:27\u001b[0m 5s/step - accuracy: 0.3866 - loss: 9.8866 getitem, batch_nr 1218 train is: True\n",
      "\u001b[1m1218/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:21\u001b[0m 5s/step - accuracy: 0.3867 - loss: 9.8859 getitem, batch_nr 1219 train is: True\n",
      "\u001b[1m1219/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:16\u001b[0m 5s/step - accuracy: 0.3867 - loss: 9.8852 getitem, batch_nr 1220 train is: True\n",
      "\u001b[1m1220/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:11\u001b[0m 5s/step - accuracy: 0.3867 - loss: 9.8845 getitem, batch_nr 1221 train is: True\n",
      "\u001b[1m1221/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:06\u001b[0m 5s/step - accuracy: 0.3868 - loss: 9.8838 getitem, batch_nr 1222 train is: True\n",
      "\u001b[1m1222/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:01\u001b[0m 5s/step - accuracy: 0.3868 - loss: 9.8831 getitem, batch_nr 1223 train is: True\n",
      "fill_time_length_dimension_called\n",
      "\u001b[1m1223/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:56\u001b[0m 5s/step - accuracy: 0.3869 - loss: 9.8824 getitem, batch_nr 1224 train is: True\n",
      "\u001b[1m1224/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:51\u001b[0m 5s/step - accuracy: 0.3869 - loss: 9.8817 getitem, batch_nr 1225 train is: True\n",
      "\u001b[1m1225/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:46\u001b[0m 5s/step - accuracy: 0.3870 - loss: 9.8810 getitem, batch_nr 1226 train is: True\n",
      "\u001b[1m1226/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:40\u001b[0m 5s/step - accuracy: 0.3870 - loss: 9.8803 getitem, batch_nr 1227 train is: True\n",
      "\u001b[1m1227/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:35\u001b[0m 5s/step - accuracy: 0.3870 - loss: 9.8796 getitem, batch_nr 1228 train is: True\n",
      "\u001b[1m1228/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:30\u001b[0m 5s/step - accuracy: 0.3871 - loss: 9.8789 getitem, batch_nr 1229 train is: True\n",
      "\u001b[1m1229/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:25\u001b[0m 5s/step - accuracy: 0.3871 - loss: 9.8782 getitem, batch_nr 1230 train is: True\n",
      "\u001b[1m1230/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:20\u001b[0m 5s/step - accuracy: 0.3872 - loss: 9.8776 getitem, batch_nr 1231 train is: True\n",
      "\u001b[1m1231/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:15\u001b[0m 5s/step - accuracy: 0.3872 - loss: 9.8769 getitem, batch_nr 1232 train is: True\n",
      "\u001b[1m1232/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:10\u001b[0m 5s/step - accuracy: 0.3873 - loss: 9.8762 getitem, batch_nr 1233 train is: True\n",
      "\u001b[1m1233/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:05\u001b[0m 5s/step - accuracy: 0.3873 - loss: 9.8755 getitem, batch_nr 1234 train is: True\n",
      "\u001b[1m1234/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:00\u001b[0m 5s/step - accuracy: 0.3873 - loss: 9.8748 getitem, batch_nr 1235 train is: True\n",
      "\u001b[1m1235/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:54\u001b[0m 5s/step - accuracy: 0.3874 - loss: 9.8741 getitem, batch_nr 1236 train is: True\n",
      "\u001b[1m1236/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:49\u001b[0m 5s/step - accuracy: 0.3874 - loss: 9.8734 getitem, batch_nr 1237 train is: True\n",
      "\u001b[1m1237/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:44\u001b[0m 5s/step - accuracy: 0.3875 - loss: 9.8728 getitem, batch_nr 1238 train is: True\n",
      "\u001b[1m1238/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:39\u001b[0m 5s/step - accuracy: 0.3875 - loss: 9.8721 getitem, batch_nr 1239 train is: True\n",
      "\u001b[1m1239/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:34\u001b[0m 5s/step - accuracy: 0.3876 - loss: 9.8714 getitem, batch_nr 1240 train is: True\n",
      "\u001b[1m1240/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:29\u001b[0m 5s/step - accuracy: 0.3876 - loss: 9.8707 getitem, batch_nr 1241 train is: True\n",
      "\u001b[1m1241/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:24\u001b[0m 5s/step - accuracy: 0.3876 - loss: 9.8700 getitem, batch_nr 1242 train is: True\n",
      "\u001b[1m1242/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:19\u001b[0m 5s/step - accuracy: 0.3877 - loss: 9.8693 getitem, batch_nr 1243 train is: True\n",
      "\u001b[1m1243/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:13\u001b[0m 5s/step - accuracy: 0.3877 - loss: 9.8687 getitem, batch_nr 1244 train is: True\n",
      "\u001b[1m1244/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:08\u001b[0m 5s/step - accuracy: 0.3878 - loss: 9.8680 getitem, batch_nr 1245 train is: True\n",
      "\u001b[1m1245/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:03\u001b[0m 5s/step - accuracy: 0.3878 - loss: 9.8673 getitem, batch_nr 1246 train is: True\n",
      "\u001b[1m1246/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:58\u001b[0m 5s/step - accuracy: 0.3879 - loss: 9.8666 getitem, batch_nr 1247 train is: True\n",
      "\u001b[1m1247/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:53\u001b[0m 5s/step - accuracy: 0.3879 - loss: 9.8660 getitem, batch_nr 1248 train is: True\n",
      "\u001b[1m1248/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:48\u001b[0m 5s/step - accuracy: 0.3879 - loss: 9.8653 getitem, batch_nr 1249 train is: True\n",
      "\u001b[1m1249/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:43\u001b[0m 5s/step - accuracy: 0.3880 - loss: 9.8646 getitem, batch_nr 1250 train is: True\n",
      "\u001b[1m1250/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:38\u001b[0m 5s/step - accuracy: 0.3880 - loss: 9.8639 getitem, batch_nr 1251 train is: True\n",
      "\u001b[1m1251/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:32\u001b[0m 5s/step - accuracy: 0.3881 - loss: 9.8633 getitem, batch_nr 1252 train is: True\n",
      "\u001b[1m1252/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:27\u001b[0m 5s/step - accuracy: 0.3881 - loss: 9.8626 getitem, batch_nr 1253 train is: True\n",
      "\u001b[1m1253/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:22\u001b[0m 5s/step - accuracy: 0.3881 - loss: 9.8619 getitem, batch_nr 1254 train is: True\n",
      "\u001b[1m1254/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:17\u001b[0m 5s/step - accuracy: 0.3882 - loss: 9.8613 getitem, batch_nr 1255 train is: True\n",
      "\u001b[1m1255/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:12\u001b[0m 5s/step - accuracy: 0.3882 - loss: 9.8606 getitem, batch_nr 1256 train is: True\n",
      "\u001b[1m1256/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:07\u001b[0m 5s/step - accuracy: 0.3883 - loss: 9.8599 getitem, batch_nr 1257 train is: True\n",
      "\u001b[1m1257/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:02\u001b[0m 5s/step - accuracy: 0.3883 - loss: 9.8593 getitem, batch_nr 1258 train is: True\n",
      "\u001b[1m1258/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:57\u001b[0m 5s/step - accuracy: 0.3884 - loss: 9.8586 getitem, batch_nr 1259 train is: True\n",
      "\u001b[1m1259/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:51\u001b[0m 5s/step - accuracy: 0.3884 - loss: 9.8579 getitem, batch_nr 1260 train is: True\n",
      "\u001b[1m1260/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:46\u001b[0m 5s/step - accuracy: 0.3884 - loss: 9.8573 getitem, batch_nr 1261 train is: True\n",
      "\u001b[1m1261/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:41\u001b[0m 5s/step - accuracy: 0.3885 - loss: 9.8566 getitem, batch_nr 1262 train is: True\n",
      "\u001b[1m1262/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:36\u001b[0m 5s/step - accuracy: 0.3885 - loss: 9.8559 getitem, batch_nr 1263 train is: True\n",
      "\u001b[1m1263/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:31\u001b[0m 5s/step - accuracy: 0.3886 - loss: 9.8553 getitem, batch_nr 1264 train is: True\n",
      "\u001b[1m1264/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:26\u001b[0m 5s/step - accuracy: 0.3886 - loss: 9.8546 getitem, batch_nr 1265 train is: True\n",
      "\u001b[1m1265/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:21\u001b[0m 5s/step - accuracy: 0.3886 - loss: 9.8540 getitem, batch_nr 1266 train is: True\n",
      "\u001b[1m1266/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:16\u001b[0m 5s/step - accuracy: 0.3887 - loss: 9.8533 getitem, batch_nr 1267 train is: True\n",
      "\u001b[1m1267/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:11\u001b[0m 5s/step - accuracy: 0.3887 - loss: 9.8526 getitem, batch_nr 1268 train is: True\n",
      "\u001b[1m1268/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:05\u001b[0m 5s/step - accuracy: 0.3888 - loss: 9.8520 getitem, batch_nr 1269 train is: True\n",
      "\u001b[1m1269/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:00\u001b[0m 5s/step - accuracy: 0.3888 - loss: 9.8513 getitem, batch_nr 1270 train is: True\n",
      "\u001b[1m1270/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:55\u001b[0m 5s/step - accuracy: 0.3888 - loss: 9.8507 getitem, batch_nr 1271 train is: True\n",
      "\u001b[1m1271/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:50\u001b[0m 5s/step - accuracy: 0.3889 - loss: 9.8500 getitem, batch_nr 1272 train is: True\n",
      "\u001b[1m1272/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:45\u001b[0m 5s/step - accuracy: 0.3889 - loss: 9.8494 getitem, batch_nr 1273 train is: True\n",
      "\u001b[1m1273/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:40\u001b[0m 5s/step - accuracy: 0.3890 - loss: 9.8487 getitem, batch_nr 1274 train is: True\n",
      "\u001b[1m1274/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:35\u001b[0m 5s/step - accuracy: 0.3890 - loss: 9.8481 getitem, batch_nr 1275 train is: True\n",
      "\u001b[1m1275/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:30\u001b[0m 5s/step - accuracy: 0.3890 - loss: 9.8474 getitem, batch_nr 1276 train is: True\n",
      "\u001b[1m1276/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:24\u001b[0m 5s/step - accuracy: 0.3891 - loss: 9.8468 getitem, batch_nr 1277 train is: True\n",
      "\u001b[1m1277/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:19\u001b[0m 5s/step - accuracy: 0.3891 - loss: 9.8461 getitem, batch_nr 1278 train is: True\n",
      "\u001b[1m1278/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:14\u001b[0m 5s/step - accuracy: 0.3892 - loss: 9.8455 getitem, batch_nr 1279 train is: True\n",
      "\u001b[1m1279/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:09\u001b[0m 5s/step - accuracy: 0.3892 - loss: 9.8448 getitem, batch_nr 1280 train is: True\n",
      "\u001b[1m1280/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:04\u001b[0m 5s/step - accuracy: 0.3892 - loss: 9.8442 getitem, batch_nr 1281 train is: True\n",
      "\u001b[1m1281/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:59\u001b[0m 5s/step - accuracy: 0.3893 - loss: 9.8435 getitem, batch_nr 1282 train is: True\n",
      "\u001b[1m1282/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:54\u001b[0m 5s/step - accuracy: 0.3893 - loss: 9.8429 getitem, batch_nr 1283 train is: True\n",
      "\u001b[1m1283/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:49\u001b[0m 5s/step - accuracy: 0.3894 - loss: 9.8423 getitem, batch_nr 1284 train is: True\n",
      "\u001b[1m1284/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:43\u001b[0m 5s/step - accuracy: 0.3894 - loss: 9.8416 getitem, batch_nr 1285 train is: True\n",
      "\u001b[1m1285/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:38\u001b[0m 5s/step - accuracy: 0.3894 - loss: 9.8410 getitem, batch_nr 1286 train is: True\n",
      "\u001b[1m1286/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:33\u001b[0m 5s/step - accuracy: 0.3895 - loss: 9.8404 getitem, batch_nr 1287 train is: True\n",
      "\u001b[1m1287/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:28\u001b[0m 5s/step - accuracy: 0.3895 - loss: 9.8398 getitem, batch_nr 1288 train is: True\n",
      "\u001b[1m1288/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:23\u001b[0m 5s/step - accuracy: 0.3896 - loss: 9.8391 getitem, batch_nr 1289 train is: True\n",
      "\u001b[1m1289/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:18\u001b[0m 5s/step - accuracy: 0.3896 - loss: 9.8385 getitem, batch_nr 1290 train is: True\n",
      "\u001b[1m1290/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:13\u001b[0m 5s/step - accuracy: 0.3896 - loss: 9.8379 getitem, batch_nr 1291 train is: True\n",
      "\u001b[1m1291/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:08\u001b[0m 5s/step - accuracy: 0.3897 - loss: 9.8373 getitem, batch_nr 1292 train is: True\n",
      "\u001b[1m1292/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:02\u001b[0m 5s/step - accuracy: 0.3897 - loss: 9.8366 getitem, batch_nr 1293 train is: True\n",
      "\u001b[1m1293/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:57\u001b[0m 5s/step - accuracy: 0.3898 - loss: 9.8360 getitem, batch_nr 1294 train is: True\n",
      "\u001b[1m1294/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:52\u001b[0m 5s/step - accuracy: 0.3898 - loss: 9.8354 getitem, batch_nr 1295 train is: True\n",
      "\u001b[1m1295/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:47\u001b[0m 5s/step - accuracy: 0.3898 - loss: 9.8348 getitem, batch_nr 1296 train is: True\n",
      "\u001b[1m1296/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:42\u001b[0m 5s/step - accuracy: 0.3899 - loss: 9.8342 getitem, batch_nr 1297 train is: True\n",
      "\u001b[1m1297/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:37\u001b[0m 5s/step - accuracy: 0.3899 - loss: 9.8335 getitem, batch_nr 1298 train is: True\n",
      "\u001b[1m1298/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:32\u001b[0m 5s/step - accuracy: 0.3899 - loss: 9.8329 getitem, batch_nr 1299 train is: True\n",
      "\u001b[1m1299/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:27\u001b[0m 5s/step - accuracy: 0.3900 - loss: 9.8323 getitem, batch_nr 1300 train is: True\n",
      "\u001b[1m1300/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:21\u001b[0m 5s/step - accuracy: 0.3900 - loss: 9.8317 getitem, batch_nr 1301 train is: True\n",
      "\u001b[1m1301/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:16\u001b[0m 5s/step - accuracy: 0.3901 - loss: 9.8311 getitem, batch_nr 1302 train is: True\n",
      "\u001b[1m1302/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:11\u001b[0m 5s/step - accuracy: 0.3901 - loss: 9.8305 getitem, batch_nr 1303 train is: True\n",
      "\u001b[1m1303/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:06\u001b[0m 5s/step - accuracy: 0.3901 - loss: 9.8298 getitem, batch_nr 1304 train is: True\n",
      "\u001b[1m1304/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:01\u001b[0m 5s/step - accuracy: 0.3902 - loss: 9.8292 getitem, batch_nr 1305 train is: True\n",
      "\u001b[1m1305/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m56s\u001b[0m 5s/step - accuracy: 0.3902 - loss: 9.8286  getitem, batch_nr 1306 train is: True\n",
      "\u001b[1m1306/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m51s\u001b[0m 5s/step - accuracy: 0.3903 - loss: 9.8280 getitem, batch_nr 1307 train is: True\n",
      "\u001b[1m1307/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.3903 - loss: 9.8274 getitem, batch_nr 1308 train is: True\n",
      "\u001b[1m1308/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m40s\u001b[0m 5s/step - accuracy: 0.3903 - loss: 9.8268 getitem, batch_nr 1309 train is: True\n",
      "\u001b[1m1309/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m35s\u001b[0m 5s/step - accuracy: 0.3904 - loss: 9.8262 getitem, batch_nr 1310 train is: True\n",
      "\u001b[1m1310/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m30s\u001b[0m 5s/step - accuracy: 0.3904 - loss: 9.8255 getitem, batch_nr 1311 train is: True\n",
      "\u001b[1m1311/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.3904 - loss: 9.8249 getitem, batch_nr 1312 train is: True\n",
      "\u001b[1m1312/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m20s\u001b[0m 5s/step - accuracy: 0.3905 - loss: 9.8243 getitem, batch_nr 1313 train is: True\n",
      "\u001b[1m1313/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 5s/step - accuracy: 0.3905 - loss: 9.8237 getitem, batch_nr 1314 train is: True\n",
      "\u001b[1m1314/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 5s/step - accuracy: 0.3906 - loss: 9.8231 getitem, batch_nr 1315 train is: True\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3906 - loss: 9.8219on_epoch_end_called\n",
      "   videoID  batches_in_video  random_order  total_batches\n",
      "0        4               260             1            260\n",
      "1        6               112             2            372\n",
      "2        1                92             3            464\n",
      "3        2               180             4            644\n",
      "4        3               186             5            830\n",
      "5        5               318             6           1148\n",
      "6        7               168             7           1316\n",
      "len called len is: 214\n",
      "len called len is: 214\n",
      " getitem, batch_nr 0 train is: False\n",
      " getitem, batch_nr 1 train is: False\n",
      "len called len is: 214\n",
      "len called len is: 214\n",
      " getitem, batch_nr 0 train is: False\n",
      " getitem, batch_nr 1 train is: False\n",
      " getitem, batch_nr 2 train is: False\n",
      " getitem, batch_nr 3 train is: False\n",
      " getitem, batch_nr 4 train is: False\n",
      " getitem, batch_nr 5 train is: False\n",
      " getitem, batch_nr 6 train is: False\n",
      " getitem, batch_nr 7 train is: False\n",
      " getitem, batch_nr 8 train is: False\n",
      " getitem, batch_nr 9 train is: False\n",
      " getitem, batch_nr 10 train is: False\n",
      " getitem, batch_nr 11 train is: False\n",
      " getitem, batch_nr 12 train is: False\n",
      " getitem, batch_nr 13 train is: False\n",
      " getitem, batch_nr 14 train is: False\n",
      " getitem, batch_nr 15 train is: False\n",
      " getitem, batch_nr 16 train is: False\n",
      " getitem, batch_nr 17 train is: False\n",
      " getitem, batch_nr 18 train is: False\n",
      " getitem, batch_nr 19 train is: False\n",
      " getitem, batch_nr 20 train is: False\n",
      " getitem, batch_nr 21 train is: False\n",
      " getitem, batch_nr 22 train is: False\n",
      " getitem, batch_nr 23 train is: False\n",
      " getitem, batch_nr 24 train is: False\n",
      " getitem, batch_nr 25 train is: False\n",
      " getitem, batch_nr 26 train is: False\n",
      " getitem, batch_nr 27 train is: False\n",
      " getitem, batch_nr 28 train is: False\n",
      " getitem, batch_nr 29 train is: False\n",
      " getitem, batch_nr 30 train is: False\n",
      " getitem, batch_nr 31 train is: False\n",
      " getitem, batch_nr 32 train is: False\n",
      " getitem, batch_nr 33 train is: False\n",
      " getitem, batch_nr 34 train is: False\n",
      " getitem, batch_nr 35 train is: False\n",
      " getitem, batch_nr 36 train is: False\n",
      " getitem, batch_nr 37 train is: False\n",
      " getitem, batch_nr 38 train is: False\n",
      " getitem, batch_nr 39 train is: False\n",
      " getitem, batch_nr 40 train is: False\n",
      " getitem, batch_nr 41 train is: False\n",
      " getitem, batch_nr 42 train is: False\n",
      " getitem, batch_nr 43 train is: False\n",
      " getitem, batch_nr 44 train is: False\n",
      " getitem, batch_nr 45 train is: False\n",
      " getitem, batch_nr 46 train is: False\n",
      " getitem, batch_nr 47 train is: False\n",
      " getitem, batch_nr 48 train is: False\n",
      " getitem, batch_nr 49 train is: False\n",
      " getitem, batch_nr 50 train is: False\n",
      " getitem, batch_nr 51 train is: False\n",
      " getitem, batch_nr 52 train is: False\n",
      " getitem, batch_nr 53 train is: False\n",
      " getitem, batch_nr 54 train is: False\n",
      " getitem, batch_nr 55 train is: False\n",
      " getitem, batch_nr 56 train is: False\n",
      " getitem, batch_nr 57 train is: False\n",
      " getitem, batch_nr 58 train is: False\n",
      " getitem, batch_nr 59 train is: False\n",
      " getitem, batch_nr 60 train is: False\n",
      " getitem, batch_nr 61 train is: False\n",
      " getitem, batch_nr 62 train is: False\n",
      " getitem, batch_nr 63 train is: False\n",
      " getitem, batch_nr 64 train is: False\n",
      " getitem, batch_nr 65 train is: False\n",
      " getitem, batch_nr 66 train is: False\n",
      " getitem, batch_nr 67 train is: False\n",
      " getitem, batch_nr 68 train is: False\n",
      " getitem, batch_nr 69 train is: False\n",
      " getitem, batch_nr 70 train is: False\n",
      " getitem, batch_nr 71 train is: False\n",
      " getitem, batch_nr 72 train is: False\n",
      " getitem, batch_nr 73 train is: False\n",
      " getitem, batch_nr 74 train is: False\n",
      " getitem, batch_nr 75 train is: False\n",
      " getitem, batch_nr 76 train is: False\n",
      " getitem, batch_nr 77 train is: False\n",
      " getitem, batch_nr 78 train is: False\n",
      " getitem, batch_nr 79 train is: False\n",
      " getitem, batch_nr 80 train is: False\n",
      " getitem, batch_nr 81 train is: False\n",
      " getitem, batch_nr 82 train is: False\n",
      " getitem, batch_nr 83 train is: False\n",
      " getitem, batch_nr 84 train is: False\n",
      " getitem, batch_nr 85 train is: False\n",
      " getitem, batch_nr 86 train is: False\n",
      " getitem, batch_nr 87 train is: False\n",
      " getitem, batch_nr 88 train is: False\n",
      " getitem, batch_nr 89 train is: False\n",
      " getitem, batch_nr 90 train is: False\n",
      " getitem, batch_nr 91 train is: False\n",
      " getitem, batch_nr 92 train is: False\n",
      " getitem, batch_nr 93 train is: False\n",
      " getitem, batch_nr 94 train is: False\n",
      " getitem, batch_nr 95 train is: False\n",
      " getitem, batch_nr 96 train is: False\n",
      " getitem, batch_nr 97 train is: False\n",
      " getitem, batch_nr 98 train is: False\n",
      " getitem, batch_nr 99 train is: False\n",
      " getitem, batch_nr 100 train is: False\n",
      " getitem, batch_nr 101 train is: False\n",
      " getitem, batch_nr 102 train is: False\n",
      " getitem, batch_nr 103 train is: False\n",
      " getitem, batch_nr 104 train is: False\n",
      " getitem, batch_nr 105 train is: False\n",
      " getitem, batch_nr 106 train is: False\n",
      " getitem, batch_nr 107 train is: False\n",
      " getitem, batch_nr 108 train is: False\n",
      " getitem, batch_nr 109 train is: False\n",
      " getitem, batch_nr 110 train is: False\n",
      " getitem, batch_nr 111 train is: False\n",
      " getitem, batch_nr 112 train is: False\n",
      " getitem, batch_nr 113 train is: False\n",
      " getitem, batch_nr 114 train is: False\n",
      " getitem, batch_nr 115 train is: False\n",
      " getitem, batch_nr 116 train is: False\n",
      " getitem, batch_nr 117 train is: False\n",
      " getitem, batch_nr 118 train is: False\n",
      " getitem, batch_nr 119 train is: False\n",
      " getitem, batch_nr 120 train is: False\n",
      " getitem, batch_nr 121 train is: False\n",
      " getitem, batch_nr 122 train is: False\n",
      " getitem, batch_nr 123 train is: False\n",
      " getitem, batch_nr 124 train is: False\n",
      " getitem, batch_nr 125 train is: False\n",
      " getitem, batch_nr 126 train is: False\n",
      "fill_time_length_dimension_called\n",
      " getitem, batch_nr 127 train is: False\n",
      " getitem, batch_nr 128 train is: False\n",
      " getitem, batch_nr 129 train is: False\n",
      " getitem, batch_nr 130 train is: False\n",
      " getitem, batch_nr 131 train is: False\n",
      " getitem, batch_nr 132 train is: False\n",
      " getitem, batch_nr 133 train is: False\n",
      " getitem, batch_nr 134 train is: False\n",
      " getitem, batch_nr 135 train is: False\n",
      " getitem, batch_nr 136 train is: False\n",
      " getitem, batch_nr 137 train is: False\n",
      " getitem, batch_nr 138 train is: False\n",
      " getitem, batch_nr 139 train is: False\n",
      " getitem, batch_nr 140 train is: False\n",
      " getitem, batch_nr 141 train is: False\n",
      " getitem, batch_nr 142 train is: False\n",
      " getitem, batch_nr 143 train is: False\n",
      " getitem, batch_nr 144 train is: False\n",
      " getitem, batch_nr 145 train is: False\n",
      " getitem, batch_nr 146 train is: False\n",
      " getitem, batch_nr 147 train is: False\n",
      " getitem, batch_nr 148 train is: False\n",
      " getitem, batch_nr 149 train is: False\n",
      " getitem, batch_nr 150 train is: False\n",
      " getitem, batch_nr 151 train is: False\n",
      " getitem, batch_nr 152 train is: False\n",
      " getitem, batch_nr 153 train is: False\n",
      " getitem, batch_nr 154 train is: False\n",
      " getitem, batch_nr 155 train is: False\n",
      " getitem, batch_nr 156 train is: False\n",
      " getitem, batch_nr 157 train is: False\n",
      " getitem, batch_nr 158 train is: False\n",
      " getitem, batch_nr 159 train is: False\n",
      " getitem, batch_nr 160 train is: False\n",
      " getitem, batch_nr 161 train is: False\n",
      " getitem, batch_nr 162 train is: False\n",
      " getitem, batch_nr 163 train is: False\n",
      " getitem, batch_nr 164 train is: False\n",
      " getitem, batch_nr 165 train is: False\n",
      " getitem, batch_nr 166 train is: False\n",
      " getitem, batch_nr 167 train is: False\n",
      " getitem, batch_nr 168 train is: False\n",
      " getitem, batch_nr 169 train is: False\n",
      " getitem, batch_nr 170 train is: False\n",
      " getitem, batch_nr 171 train is: False\n",
      " getitem, batch_nr 172 train is: False\n",
      " getitem, batch_nr 173 train is: False\n",
      " getitem, batch_nr 174 train is: False\n",
      " getitem, batch_nr 175 train is: False\n",
      " getitem, batch_nr 176 train is: False\n",
      " getitem, batch_nr 177 train is: False\n",
      " getitem, batch_nr 178 train is: False\n",
      " getitem, batch_nr 179 train is: False\n",
      " getitem, batch_nr 180 train is: False\n",
      " getitem, batch_nr 181 train is: False\n",
      " getitem, batch_nr 182 train is: False\n",
      " getitem, batch_nr 183 train is: False\n",
      " getitem, batch_nr 184 train is: False\n",
      " getitem, batch_nr 185 train is: False\n",
      " getitem, batch_nr 186 train is: False\n",
      " getitem, batch_nr 187 train is: False\n",
      " getitem, batch_nr 188 train is: False\n",
      " getitem, batch_nr 189 train is: False\n",
      " getitem, batch_nr 190 train is: False\n",
      " getitem, batch_nr 191 train is: False\n",
      " getitem, batch_nr 192 train is: False\n",
      " getitem, batch_nr 193 train is: False\n",
      " getitem, batch_nr 194 train is: False\n",
      " getitem, batch_nr 195 train is: False\n",
      " getitem, batch_nr 196 train is: False\n",
      " getitem, batch_nr 197 train is: False\n",
      " getitem, batch_nr 198 train is: False\n",
      " getitem, batch_nr 199 train is: False\n",
      " getitem, batch_nr 200 train is: False\n",
      " getitem, batch_nr 201 train is: False\n",
      " getitem, batch_nr 202 train is: False\n",
      " getitem, batch_nr 203 train is: False\n",
      " getitem, batch_nr 204 train is: False\n",
      " getitem, batch_nr 205 train is: False\n",
      " getitem, batch_nr 206 train is: False\n",
      " getitem, batch_nr 207 train is: False\n",
      " getitem, batch_nr 208 train is: False\n",
      " getitem, batch_nr 209 train is: False\n",
      " getitem, batch_nr 210 train is: False\n",
      " getitem, batch_nr 211 train is: False\n",
      " getitem, batch_nr 212 train is: False\n",
      " getitem, batch_nr 213 train is: False\n",
      "fill_time_length_dimension_called\n",
      "on_epoch_end_called\n",
      "   videoID  batches_in_video  random_order  total_batches\n",
      "0        9                87             1             87\n",
      "1        8               127             2            214\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6993s\u001b[0m 5s/step - accuracy: 0.3907 - loss: 9.8213 - val_accuracy: 0.4287 - val_loss: 9.1999\n",
      "Epoch 2/2\n",
      "len called len is: 1316\n",
      "len called len is: 1316\n",
      " getitem, batch_nr 0 train is: True\n",
      " getitem, batch_nr 1 train is: True\n",
      "\u001b[1m   1/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56:57\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0738 getitem, batch_nr 2 train is: True\n",
      "\u001b[1m   2/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:51\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0738 getitem, batch_nr 3 train is: True\n",
      "\u001b[1m   3/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:35\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0738 getitem, batch_nr 4 train is: True\n",
      "\u001b[1m   4/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:37\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0738 getitem, batch_nr 5 train is: True\n",
      "\u001b[1m   5/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:32\u001b[0m 5s/step - accuracy: 0.3750 - loss: 10.0738 getitem, batch_nr 6 train is: True\n",
      "\u001b[1m   6/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:30\u001b[0m 5s/step - accuracy: 0.3785 - loss: 10.0178 getitem, batch_nr 7 train is: True\n",
      "\u001b[1m   7/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:26\u001b[0m 5s/step - accuracy: 0.3831 - loss: 9.9436  getitem, batch_nr 8 train is: True\n",
      "\u001b[1m   8/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:42\u001b[0m 5s/step - accuracy: 0.3879 - loss: 9.8654 getitem, batch_nr 9 train is: True\n",
      "\u001b[1m   9/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:45\u001b[0m 5s/step - accuracy: 0.3927 - loss: 9.7891 getitem, batch_nr 10 train is: True\n",
      "\u001b[1m  10/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:28\u001b[0m 5s/step - accuracy: 0.3959 - loss: 9.7370 getitem, batch_nr 11 train is: True\n",
      "\u001b[1m  11/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:20\u001b[0m 5s/step - accuracy: 0.3981 - loss: 9.7010 getitem, batch_nr 12 train is: True\n",
      "\u001b[1m  12/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:26\u001b[0m 5s/step - accuracy: 0.3997 - loss: 9.6761 getitem, batch_nr 13 train is: True\n",
      "\u001b[1m  13/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:37\u001b[0m 5s/step - accuracy: 0.4007 - loss: 9.6590 getitem, batch_nr 14 train is: True\n",
      "\u001b[1m  14/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:33\u001b[0m 5s/step - accuracy: 0.4014 - loss: 9.6475 getitem, batch_nr 15 train is: True\n",
      "\u001b[1m  15/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:31\u001b[0m 5s/step - accuracy: 0.4019 - loss: 9.6401 getitem, batch_nr 16 train is: True\n",
      "\u001b[1m  16/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:27\u001b[0m 5s/step - accuracy: 0.4022 - loss: 9.6357 getitem, batch_nr 17 train is: True\n",
      "\u001b[1m  17/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:25\u001b[0m 5s/step - accuracy: 0.4023 - loss: 9.6336 getitem, batch_nr 18 train is: True\n",
      "\u001b[1m  18/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:19\u001b[0m 5s/step - accuracy: 0.4023 - loss: 9.6332 getitem, batch_nr 19 train is: True\n",
      "\u001b[1m  19/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:10\u001b[0m 5s/step - accuracy: 0.4026 - loss: 9.6285 getitem, batch_nr 20 train is: True\n",
      "\u001b[1m  20/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:09\u001b[0m 5s/step - accuracy: 0.4034 - loss: 9.6155 getitem, batch_nr 21 train is: True\n",
      "\u001b[1m  21/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:59\u001b[0m 5s/step - accuracy: 0.4046 - loss: 9.5962 getitem, batch_nr 22 train is: True\n",
      "\u001b[1m  22/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:50\u001b[0m 5s/step - accuracy: 0.4059 - loss: 9.5763 getitem, batch_nr 23 train is: True\n",
      "\u001b[1m  23/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:43\u001b[0m 5s/step - accuracy: 0.4074 - loss: 9.5522 getitem, batch_nr 24 train is: True\n",
      "\u001b[1m  24/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:38\u001b[0m 5s/step - accuracy: 0.4091 - loss: 9.5250 getitem, batch_nr 25 train is: True\n",
      "\u001b[1m  25/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:32\u001b[0m 5s/step - accuracy: 0.4109 - loss: 9.4954 getitem, batch_nr 26 train is: True\n",
      "\u001b[1m  26/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:24\u001b[0m 5s/step - accuracy: 0.4128 - loss: 9.4640 getitem, batch_nr 27 train is: True\n",
      "\u001b[1m  27/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:19\u001b[0m 5s/step - accuracy: 0.4144 - loss: 9.4396 getitem, batch_nr 28 train is: True\n",
      "\u001b[1m  28/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:14\u001b[0m 5s/step - accuracy: 0.4160 - loss: 9.4134 getitem, batch_nr 29 train is: True\n",
      "\u001b[1m  29/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:07\u001b[0m 5s/step - accuracy: 0.4172 - loss: 9.3930 getitem, batch_nr 30 train is: True\n",
      "\u001b[1m  30/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:06\u001b[0m 5s/step - accuracy: 0.4186 - loss: 9.3710 getitem, batch_nr 31 train is: True\n",
      "\u001b[1m  31/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:04\u001b[0m 5s/step - accuracy: 0.4198 - loss: 9.3517 getitem, batch_nr 32 train is: True\n",
      "\u001b[1m  32/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:02\u001b[0m 5s/step - accuracy: 0.4211 - loss: 9.3310 getitem, batch_nr 33 train is: True\n",
      "\u001b[1m  33/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:54\u001b[0m 5s/step - accuracy: 0.4221 - loss: 9.3146 getitem, batch_nr 34 train is: True\n",
      "\u001b[1m  34/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:49\u001b[0m 5s/step - accuracy: 0.4232 - loss: 9.2969 getitem, batch_nr 35 train is: True\n",
      "\u001b[1m  35/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:44\u001b[0m 5s/step - accuracy: 0.4242 - loss: 9.2812 getitem, batch_nr 36 train is: True\n",
      "\u001b[1m  36/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:36\u001b[0m 5s/step - accuracy: 0.4252 - loss: 9.2644 getitem, batch_nr 37 train is: True\n",
      "\u001b[1m  37/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:27\u001b[0m 5s/step - accuracy: 0.4262 - loss: 9.2480 getitem, batch_nr 38 train is: True\n",
      "\u001b[1m  38/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:22\u001b[0m 5s/step - accuracy: 0.4273 - loss: 9.2307 getitem, batch_nr 39 train is: True\n",
      "\u001b[1m  39/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:18\u001b[0m 5s/step - accuracy: 0.4284 - loss: 9.2139 getitem, batch_nr 40 train is: True\n",
      "\u001b[1m  40/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:10\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1963 getitem, batch_nr 41 train is: True\n",
      "\u001b[1m  41/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:03\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1806 getitem, batch_nr 42 train is: True\n",
      "\u001b[1m  42/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:00\u001b[0m 5s/step - accuracy: 0.4314 - loss: 9.1642 getitem, batch_nr 43 train is: True\n",
      "\u001b[1m  43/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:57\u001b[0m 5s/step - accuracy: 0.4325 - loss: 9.1472 getitem, batch_nr 44 train is: True\n",
      "\u001b[1m  44/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:50\u001b[0m 5s/step - accuracy: 0.4335 - loss: 9.1308 getitem, batch_nr 45 train is: True\n",
      "\u001b[1m  45/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:45\u001b[0m 5s/step - accuracy: 0.4346 - loss: 9.1139 getitem, batch_nr 46 train is: True\n",
      "\u001b[1m  46/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:41\u001b[0m 5s/step - accuracy: 0.4356 - loss: 9.0967 getitem, batch_nr 47 train is: True\n",
      "\u001b[1m  47/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:37\u001b[0m 5s/step - accuracy: 0.4365 - loss: 9.0819 getitem, batch_nr 48 train is: True\n",
      "\u001b[1m  48/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:33\u001b[0m 5s/step - accuracy: 0.4375 - loss: 9.0667 getitem, batch_nr 49 train is: True\n",
      "\u001b[1m  49/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:29\u001b[0m 5s/step - accuracy: 0.4384 - loss: 9.0512 getitem, batch_nr 50 train is: True\n",
      "\u001b[1m  50/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:23\u001b[0m 5s/step - accuracy: 0.4393 - loss: 9.0378 getitem, batch_nr 51 train is: True\n",
      "\u001b[1m  51/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:17\u001b[0m 5s/step - accuracy: 0.4400 - loss: 9.0256 getitem, batch_nr 52 train is: True\n",
      "\u001b[1m  52/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:11\u001b[0m 5s/step - accuracy: 0.4407 - loss: 9.0145 getitem, batch_nr 53 train is: True\n",
      "\u001b[1m  53/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:08\u001b[0m 5s/step - accuracy: 0.4414 - loss: 9.0029 getitem, batch_nr 54 train is: True\n",
      "\u001b[1m  54/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:06\u001b[0m 5s/step - accuracy: 0.4422 - loss: 8.9909 getitem, batch_nr 55 train is: True\n",
      "\u001b[1m  55/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48:00\u001b[0m 5s/step - accuracy: 0.4429 - loss: 8.9793 getitem, batch_nr 56 train is: True\n",
      "\u001b[1m  56/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:57\u001b[0m 5s/step - accuracy: 0.4436 - loss: 8.9674 getitem, batch_nr 57 train is: True\n",
      "\u001b[1m  57/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:51\u001b[0m 5s/step - accuracy: 0.4444 - loss: 8.9552 getitem, batch_nr 58 train is: True\n",
      "\u001b[1m  58/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:47\u001b[0m 5s/step - accuracy: 0.4452 - loss: 8.9427 getitem, batch_nr 59 train is: True\n",
      "\u001b[1m  59/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:42\u001b[0m 5s/step - accuracy: 0.4459 - loss: 8.9312 getitem, batch_nr 60 train is: True\n",
      "\u001b[1m  60/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:36\u001b[0m 5s/step - accuracy: 0.4466 - loss: 8.9195 getitem, batch_nr 61 train is: True\n",
      "\u001b[1m  61/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:30\u001b[0m 5s/step - accuracy: 0.4473 - loss: 8.9091 getitem, batch_nr 62 train is: True\n",
      "\u001b[1m  62/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:25\u001b[0m 5s/step - accuracy: 0.4479 - loss: 8.8986 getitem, batch_nr 63 train is: True\n",
      "\u001b[1m  63/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:19\u001b[0m 5s/step - accuracy: 0.4485 - loss: 8.8893 getitem, batch_nr 64 train is: True\n",
      "\u001b[1m  64/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:13\u001b[0m 5s/step - accuracy: 0.4491 - loss: 8.8798 getitem, batch_nr 65 train is: True\n",
      "\u001b[1m  65/1316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:09\u001b[0m 5s/step - accuracy: 0.4496 - loss: 8.8715 getitem, batch_nr 66 train is: True\n",
      "\u001b[1m  66/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:04\u001b[0m 5s/step - accuracy: 0.4501 - loss: 8.8628 getitem, batch_nr 67 train is: True\n",
      "\u001b[1m  67/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:58\u001b[0m 5s/step - accuracy: 0.4506 - loss: 8.8553 getitem, batch_nr 68 train is: True\n",
      "\u001b[1m  68/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:54\u001b[0m 5s/step - accuracy: 0.4511 - loss: 8.8475 getitem, batch_nr 69 train is: True\n",
      "\u001b[1m  69/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:50\u001b[0m 5s/step - accuracy: 0.4516 - loss: 8.8399 getitem, batch_nr 70 train is: True\n",
      "\u001b[1m  70/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:44\u001b[0m 5s/step - accuracy: 0.4520 - loss: 8.8321 getitem, batch_nr 71 train is: True\n",
      "\u001b[1m  71/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:40\u001b[0m 5s/step - accuracy: 0.4525 - loss: 8.8248 getitem, batch_nr 72 train is: True\n",
      "\u001b[1m  72/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:33\u001b[0m 5s/step - accuracy: 0.4530 - loss: 8.8172 getitem, batch_nr 73 train is: True\n",
      "\u001b[1m  73/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:28\u001b[0m 5s/step - accuracy: 0.4534 - loss: 8.8095 getitem, batch_nr 74 train is: True\n",
      "\u001b[1m  74/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:23\u001b[0m 5s/step - accuracy: 0.4539 - loss: 8.8023 getitem, batch_nr 75 train is: True\n",
      "\u001b[1m  75/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:17\u001b[0m 5s/step - accuracy: 0.4543 - loss: 8.7953 getitem, batch_nr 76 train is: True\n",
      "\u001b[1m  76/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:12\u001b[0m 5s/step - accuracy: 0.4548 - loss: 8.7880 getitem, batch_nr 77 train is: True\n",
      "\u001b[1m  77/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:08\u001b[0m 5s/step - accuracy: 0.4552 - loss: 8.7809 getitem, batch_nr 78 train is: True\n",
      "\u001b[1m  78/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46:04\u001b[0m 5s/step - accuracy: 0.4557 - loss: 8.7737 getitem, batch_nr 79 train is: True\n",
      "\u001b[1m  79/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:58\u001b[0m 5s/step - accuracy: 0.4561 - loss: 8.7662 getitem, batch_nr 80 train is: True\n",
      "\u001b[1m  80/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:54\u001b[0m 5s/step - accuracy: 0.4566 - loss: 8.7586 getitem, batch_nr 81 train is: True\n",
      "\u001b[1m  81/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:47\u001b[0m 5s/step - accuracy: 0.4571 - loss: 8.7509 getitem, batch_nr 82 train is: True\n",
      "\u001b[1m  82/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:42\u001b[0m 5s/step - accuracy: 0.4576 - loss: 8.7431 getitem, batch_nr 83 train is: True\n",
      "\u001b[1m  83/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:37\u001b[0m 5s/step - accuracy: 0.4580 - loss: 8.7360 getitem, batch_nr 84 train is: True\n",
      "\u001b[1m  84/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:32\u001b[0m 5s/step - accuracy: 0.4584 - loss: 8.7288 getitem, batch_nr 85 train is: True\n",
      "\u001b[1m  85/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:26\u001b[0m 5s/step - accuracy: 0.4589 - loss: 8.7215 getitem, batch_nr 86 train is: True\n",
      "\u001b[1m  86/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:20\u001b[0m 5s/step - accuracy: 0.4593 - loss: 8.7143 getitem, batch_nr 87 train is: True\n",
      "\u001b[1m  87/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:14\u001b[0m 5s/step - accuracy: 0.4598 - loss: 8.7071 getitem, batch_nr 88 train is: True\n",
      "\u001b[1m  88/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:10\u001b[0m 5s/step - accuracy: 0.4603 - loss: 8.6997 getitem, batch_nr 89 train is: True\n",
      "\u001b[1m  89/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:05\u001b[0m 5s/step - accuracy: 0.4607 - loss: 8.6930 getitem, batch_nr 90 train is: True\n",
      "\u001b[1m  90/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:01\u001b[0m 5s/step - accuracy: 0.4611 - loss: 8.6862 getitem, batch_nr 91 train is: True\n",
      "\u001b[1m  91/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:56\u001b[0m 5s/step - accuracy: 0.4615 - loss: 8.6793 getitem, batch_nr 92 train is: True\n",
      "\u001b[1m  92/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:51\u001b[0m 5s/step - accuracy: 0.4619 - loss: 8.6724 getitem, batch_nr 93 train is: True\n",
      "\u001b[1m  93/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:45\u001b[0m 5s/step - accuracy: 0.4624 - loss: 8.6653 getitem, batch_nr 94 train is: True\n",
      "\u001b[1m  94/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:39\u001b[0m 5s/step - accuracy: 0.4628 - loss: 8.6582 getitem, batch_nr 95 train is: True\n",
      "\u001b[1m  95/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:34\u001b[0m 5s/step - accuracy: 0.4633 - loss: 8.6510 getitem, batch_nr 96 train is: True\n",
      "\u001b[1m  96/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:28\u001b[0m 5s/step - accuracy: 0.4637 - loss: 8.6437 getitem, batch_nr 97 train is: True\n",
      "\u001b[1m  97/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:23\u001b[0m 5s/step - accuracy: 0.4642 - loss: 8.6364 getitem, batch_nr 98 train is: True\n",
      "\u001b[1m  98/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:18\u001b[0m 5s/step - accuracy: 0.4646 - loss: 8.6297 getitem, batch_nr 99 train is: True\n",
      "\u001b[1m  99/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:14\u001b[0m 5s/step - accuracy: 0.4650 - loss: 8.6229 getitem, batch_nr 100 train is: True\n",
      "\u001b[1m 100/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:09\u001b[0m 5s/step - accuracy: 0.4654 - loss: 8.6166 getitem, batch_nr 101 train is: True\n",
      "\u001b[1m 101/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:04\u001b[0m 5s/step - accuracy: 0.4658 - loss: 8.6103 getitem, batch_nr 102 train is: True\n",
      "\u001b[1m 102/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:01\u001b[0m 5s/step - accuracy: 0.4662 - loss: 8.6045 getitem, batch_nr 103 train is: True\n",
      "\u001b[1m 103/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:56\u001b[0m 5s/step - accuracy: 0.4665 - loss: 8.5987 getitem, batch_nr 104 train is: True\n",
      "\u001b[1m 104/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:50\u001b[0m 5s/step - accuracy: 0.4669 - loss: 8.5933 getitem, batch_nr 105 train is: True\n",
      "\u001b[1m 105/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:44\u001b[0m 5s/step - accuracy: 0.4672 - loss: 8.5878 getitem, batch_nr 106 train is: True\n",
      "\u001b[1m 106/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:40\u001b[0m 5s/step - accuracy: 0.4675 - loss: 8.5825 getitem, batch_nr 107 train is: True\n",
      "\u001b[1m 107/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:35\u001b[0m 5s/step - accuracy: 0.4679 - loss: 8.5771 getitem, batch_nr 108 train is: True\n",
      "\u001b[1m 108/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:30\u001b[0m 5s/step - accuracy: 0.4682 - loss: 8.5717 getitem, batch_nr 109 train is: True\n",
      "\u001b[1m 109/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:25\u001b[0m 5s/step - accuracy: 0.4685 - loss: 8.5664 getitem, batch_nr 110 train is: True\n",
      "\u001b[1m 110/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:20\u001b[0m 5s/step - accuracy: 0.4689 - loss: 8.5611 getitem, batch_nr 111 train is: True\n",
      "\u001b[1m 111/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:13\u001b[0m 5s/step - accuracy: 0.4692 - loss: 8.5557 getitem, batch_nr 112 train is: True\n",
      "\u001b[1m 112/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:08\u001b[0m 5s/step - accuracy: 0.4695 - loss: 8.5505 getitem, batch_nr 113 train is: True\n",
      "\u001b[1m 113/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:02\u001b[0m 5s/step - accuracy: 0.4698 - loss: 8.5452 getitem, batch_nr 114 train is: True\n",
      "\u001b[1m 114/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:59\u001b[0m 5s/step - accuracy: 0.4702 - loss: 8.5399 getitem, batch_nr 115 train is: True\n",
      "\u001b[1m 115/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:53\u001b[0m 5s/step - accuracy: 0.4705 - loss: 8.5346 getitem, batch_nr 116 train is: True\n",
      "\u001b[1m 116/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:48\u001b[0m 5s/step - accuracy: 0.4708 - loss: 8.5293 getitem, batch_nr 117 train is: True\n",
      "\u001b[1m 117/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:44\u001b[0m 5s/step - accuracy: 0.4711 - loss: 8.5243 getitem, batch_nr 118 train is: True\n",
      "\u001b[1m 118/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:38\u001b[0m 5s/step - accuracy: 0.4715 - loss: 8.5192 getitem, batch_nr 119 train is: True\n",
      "\u001b[1m 119/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:33\u001b[0m 5s/step - accuracy: 0.4718 - loss: 8.5140 getitem, batch_nr 120 train is: True\n",
      "\u001b[1m 120/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:28\u001b[0m 5s/step - accuracy: 0.4721 - loss: 8.5091 getitem, batch_nr 121 train is: True\n",
      "\u001b[1m 121/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:22\u001b[0m 5s/step - accuracy: 0.4724 - loss: 8.5042 getitem, batch_nr 122 train is: True\n",
      "\u001b[1m 122/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:17\u001b[0m 5s/step - accuracy: 0.4727 - loss: 8.4992 getitem, batch_nr 123 train is: True\n",
      "\u001b[1m 123/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:12\u001b[0m 5s/step - accuracy: 0.4730 - loss: 8.4941 getitem, batch_nr 124 train is: True\n",
      "\u001b[1m 124/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:06\u001b[0m 5s/step - accuracy: 0.4733 - loss: 8.4890 getitem, batch_nr 125 train is: True\n",
      "\u001b[1m 125/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:01\u001b[0m 5s/step - accuracy: 0.4736 - loss: 8.4839 getitem, batch_nr 126 train is: True\n",
      "\u001b[1m 126/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:57\u001b[0m 5s/step - accuracy: 0.4740 - loss: 8.4788 getitem, batch_nr 127 train is: True\n",
      "\u001b[1m 127/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:51\u001b[0m 5s/step - accuracy: 0.4743 - loss: 8.4736 getitem, batch_nr 128 train is: True\n",
      "\u001b[1m 128/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:46\u001b[0m 5s/step - accuracy: 0.4746 - loss: 8.4686 getitem, batch_nr 129 train is: True\n",
      "\u001b[1m 129/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:41\u001b[0m 5s/step - accuracy: 0.4749 - loss: 8.4636 getitem, batch_nr 130 train is: True\n",
      "\u001b[1m 130/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:35\u001b[0m 5s/step - accuracy: 0.4752 - loss: 8.4590 getitem, batch_nr 131 train is: True\n",
      "\u001b[1m 131/1316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:30\u001b[0m 5s/step - accuracy: 0.4755 - loss: 8.4543 getitem, batch_nr 132 train is: True\n",
      "\u001b[1m 132/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:25\u001b[0m 5s/step - accuracy: 0.4758 - loss: 8.4498 getitem, batch_nr 133 train is: True\n",
      "\u001b[1m 133/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:20\u001b[0m 5s/step - accuracy: 0.4760 - loss: 8.4452 getitem, batch_nr 134 train is: True\n",
      "\u001b[1m 134/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:16\u001b[0m 5s/step - accuracy: 0.4763 - loss: 8.4408 getitem, batch_nr 135 train is: True\n",
      "\u001b[1m 135/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:11\u001b[0m 5s/step - accuracy: 0.4766 - loss: 8.4363 getitem, batch_nr 136 train is: True\n",
      "\u001b[1m 136/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:05\u001b[0m 5s/step - accuracy: 0.4769 - loss: 8.4320 getitem, batch_nr 137 train is: True\n",
      "\u001b[1m 137/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:01\u001b[0m 5s/step - accuracy: 0.4771 - loss: 8.4277 getitem, batch_nr 138 train is: True\n",
      "\u001b[1m 138/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:56\u001b[0m 5s/step - accuracy: 0.4774 - loss: 8.4235 getitem, batch_nr 139 train is: True\n",
      "\u001b[1m 139/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:51\u001b[0m 5s/step - accuracy: 0.4776 - loss: 8.4193 getitem, batch_nr 140 train is: True\n",
      "\u001b[1m 140/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:45\u001b[0m 5s/step - accuracy: 0.4779 - loss: 8.4151 getitem, batch_nr 141 train is: True\n",
      "\u001b[1m 141/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:39\u001b[0m 5s/step - accuracy: 0.4782 - loss: 8.4111 getitem, batch_nr 142 train is: True\n",
      "\u001b[1m 142/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:34\u001b[0m 5s/step - accuracy: 0.4784 - loss: 8.4070 getitem, batch_nr 143 train is: True\n",
      "\u001b[1m 143/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:29\u001b[0m 5s/step - accuracy: 0.4787 - loss: 8.4029 getitem, batch_nr 144 train is: True\n",
      "\u001b[1m 144/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:25\u001b[0m 5s/step - accuracy: 0.4789 - loss: 8.3988 getitem, batch_nr 145 train is: True\n",
      "\u001b[1m 145/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:19\u001b[0m 5s/step - accuracy: 0.4792 - loss: 8.3946 getitem, batch_nr 146 train is: True\n",
      "\u001b[1m 146/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:14\u001b[0m 5s/step - accuracy: 0.4794 - loss: 8.3904 getitem, batch_nr 147 train is: True\n",
      "\u001b[1m 147/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:08\u001b[0m 5s/step - accuracy: 0.4797 - loss: 8.3865 getitem, batch_nr 148 train is: True\n",
      "\u001b[1m 148/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:04\u001b[0m 5s/step - accuracy: 0.4799 - loss: 8.3825 getitem, batch_nr 149 train is: True\n",
      "\u001b[1m 149/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:59\u001b[0m 5s/step - accuracy: 0.4802 - loss: 8.3785 getitem, batch_nr 150 train is: True\n",
      "\u001b[1m 150/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:54\u001b[0m 5s/step - accuracy: 0.4804 - loss: 8.3746 getitem, batch_nr 151 train is: True\n",
      "\u001b[1m 151/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:49\u001b[0m 5s/step - accuracy: 0.4807 - loss: 8.3709 getitem, batch_nr 152 train is: True\n",
      "\u001b[1m 152/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:44\u001b[0m 5s/step - accuracy: 0.4809 - loss: 8.3672 getitem, batch_nr 153 train is: True\n",
      "\u001b[1m 153/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:39\u001b[0m 5s/step - accuracy: 0.4811 - loss: 8.3637 getitem, batch_nr 154 train is: True\n",
      "\u001b[1m 154/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:35\u001b[0m 5s/step - accuracy: 0.4813 - loss: 8.3602 getitem, batch_nr 155 train is: True\n",
      "\u001b[1m 155/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:31\u001b[0m 5s/step - accuracy: 0.4815 - loss: 8.3569 getitem, batch_nr 156 train is: True\n",
      "\u001b[1m 156/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:25\u001b[0m 5s/step - accuracy: 0.4817 - loss: 8.3536 getitem, batch_nr 157 train is: True\n",
      "\u001b[1m 157/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:20\u001b[0m 5s/step - accuracy: 0.4819 - loss: 8.3504 getitem, batch_nr 158 train is: True\n",
      "\u001b[1m 158/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:15\u001b[0m 5s/step - accuracy: 0.4821 - loss: 8.3471 getitem, batch_nr 159 train is: True\n",
      "\u001b[1m 159/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:10\u001b[0m 5s/step - accuracy: 0.4823 - loss: 8.3440 getitem, batch_nr 160 train is: True\n",
      "\u001b[1m 160/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:05\u001b[0m 5s/step - accuracy: 0.4825 - loss: 8.3409 getitem, batch_nr 161 train is: True\n",
      "\u001b[1m 161/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:59\u001b[0m 5s/step - accuracy: 0.4827 - loss: 8.3379 getitem, batch_nr 162 train is: True\n",
      "\u001b[1m 162/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:54\u001b[0m 5s/step - accuracy: 0.4829 - loss: 8.3348 getitem, batch_nr 163 train is: True\n",
      "\u001b[1m 163/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:49\u001b[0m 5s/step - accuracy: 0.4831 - loss: 8.3319 getitem, batch_nr 164 train is: True\n",
      "\u001b[1m 164/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:43\u001b[0m 5s/step - accuracy: 0.4833 - loss: 8.3288 getitem, batch_nr 165 train is: True\n",
      "\u001b[1m 165/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:38\u001b[0m 5s/step - accuracy: 0.4834 - loss: 8.3260 getitem, batch_nr 166 train is: True\n",
      "\u001b[1m 166/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:33\u001b[0m 5s/step - accuracy: 0.4836 - loss: 8.3232 getitem, batch_nr 167 train is: True\n",
      "\u001b[1m 167/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:28\u001b[0m 5s/step - accuracy: 0.4838 - loss: 8.3204 getitem, batch_nr 168 train is: True\n",
      "\u001b[1m 168/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:23\u001b[0m 5s/step - accuracy: 0.4840 - loss: 8.3177 getitem, batch_nr 169 train is: True\n",
      "\u001b[1m 169/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:18\u001b[0m 5s/step - accuracy: 0.4841 - loss: 8.3149 getitem, batch_nr 170 train is: True\n",
      "\u001b[1m 170/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:13\u001b[0m 5s/step - accuracy: 0.4843 - loss: 8.3122 getitem, batch_nr 171 train is: True\n",
      "\u001b[1m 171/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:09\u001b[0m 5s/step - accuracy: 0.4845 - loss: 8.3094 getitem, batch_nr 172 train is: True\n",
      "\u001b[1m 172/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:03\u001b[0m 5s/step - accuracy: 0.4846 - loss: 8.3066 getitem, batch_nr 173 train is: True\n",
      "\u001b[1m 173/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:59\u001b[0m 5s/step - accuracy: 0.4848 - loss: 8.3039 getitem, batch_nr 174 train is: True\n",
      "\u001b[1m 174/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:54\u001b[0m 5s/step - accuracy: 0.4850 - loss: 8.3013 getitem, batch_nr 175 train is: True\n",
      "\u001b[1m 175/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:48\u001b[0m 5s/step - accuracy: 0.4851 - loss: 8.2986 getitem, batch_nr 176 train is: True\n",
      "\u001b[1m 176/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:43\u001b[0m 5s/step - accuracy: 0.4853 - loss: 8.2960 getitem, batch_nr 177 train is: True\n",
      "\u001b[1m 177/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:38\u001b[0m 5s/step - accuracy: 0.4855 - loss: 8.2934 getitem, batch_nr 178 train is: True\n",
      "\u001b[1m 178/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:33\u001b[0m 5s/step - accuracy: 0.4856 - loss: 8.2908 getitem, batch_nr 179 train is: True\n",
      "\u001b[1m 179/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:28\u001b[0m 5s/step - accuracy: 0.4858 - loss: 8.2883 getitem, batch_nr 180 train is: True\n",
      "\u001b[1m 180/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:22\u001b[0m 5s/step - accuracy: 0.4859 - loss: 8.2858 getitem, batch_nr 181 train is: True\n",
      "\u001b[1m 181/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:17\u001b[0m 5s/step - accuracy: 0.4861 - loss: 8.2834 getitem, batch_nr 182 train is: True\n",
      "\u001b[1m 182/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:12\u001b[0m 5s/step - accuracy: 0.4862 - loss: 8.2809 getitem, batch_nr 183 train is: True\n",
      "\u001b[1m 183/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:07\u001b[0m 5s/step - accuracy: 0.4864 - loss: 8.2785 getitem, batch_nr 184 train is: True\n",
      "\u001b[1m 184/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:02\u001b[0m 5s/step - accuracy: 0.4865 - loss: 8.2760 getitem, batch_nr 185 train is: True\n",
      "\u001b[1m 185/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:56\u001b[0m 5s/step - accuracy: 0.4867 - loss: 8.2734 getitem, batch_nr 186 train is: True\n",
      "\u001b[1m 186/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:50\u001b[0m 5s/step - accuracy: 0.4869 - loss: 8.2709 getitem, batch_nr 187 train is: True\n",
      "\u001b[1m 187/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:45\u001b[0m 5s/step - accuracy: 0.4870 - loss: 8.2685 getitem, batch_nr 188 train is: True\n",
      "\u001b[1m 188/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:41\u001b[0m 5s/step - accuracy: 0.4871 - loss: 8.2662 getitem, batch_nr 189 train is: True\n",
      "\u001b[1m 189/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:36\u001b[0m 5s/step - accuracy: 0.4873 - loss: 8.2640 getitem, batch_nr 190 train is: True\n",
      "\u001b[1m 190/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:30\u001b[0m 5s/step - accuracy: 0.4874 - loss: 8.2619 getitem, batch_nr 191 train is: True\n",
      "\u001b[1m 191/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:25\u001b[0m 5s/step - accuracy: 0.4875 - loss: 8.2598 getitem, batch_nr 192 train is: True\n",
      "\u001b[1m 192/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:20\u001b[0m 5s/step - accuracy: 0.4877 - loss: 8.2579 getitem, batch_nr 193 train is: True\n",
      "\u001b[1m 193/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:15\u001b[0m 5s/step - accuracy: 0.4878 - loss: 8.2559 getitem, batch_nr 194 train is: True\n",
      "\u001b[1m 194/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:11\u001b[0m 5s/step - accuracy: 0.4879 - loss: 8.2541 getitem, batch_nr 195 train is: True\n",
      "\u001b[1m 195/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:06\u001b[0m 5s/step - accuracy: 0.4880 - loss: 8.2522 getitem, batch_nr 196 train is: True\n",
      "\u001b[1m 196/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:00\u001b[0m 5s/step - accuracy: 0.4881 - loss: 8.2503 getitem, batch_nr 197 train is: True\n",
      "\u001b[1m 197/1316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:56\u001b[0m 5s/step - accuracy: 0.4882 - loss: 8.2485 getitem, batch_nr 198 train is: True\n",
      "\u001b[1m 198/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:50\u001b[0m 5s/step - accuracy: 0.4884 - loss: 8.2467 getitem, batch_nr 199 train is: True\n",
      "\u001b[1m 199/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:45\u001b[0m 5s/step - accuracy: 0.4885 - loss: 8.2448 getitem, batch_nr 200 train is: True\n",
      "\u001b[1m 200/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:40\u001b[0m 5s/step - accuracy: 0.4886 - loss: 8.2429 getitem, batch_nr 201 train is: True\n",
      "\u001b[1m 201/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:35\u001b[0m 5s/step - accuracy: 0.4887 - loss: 8.2412 getitem, batch_nr 202 train is: True\n",
      "\u001b[1m 202/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:30\u001b[0m 5s/step - accuracy: 0.4888 - loss: 8.2394 getitem, batch_nr 203 train is: True\n",
      "\u001b[1m 203/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:25\u001b[0m 5s/step - accuracy: 0.4889 - loss: 8.2377 getitem, batch_nr 204 train is: True\n",
      "\u001b[1m 204/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:20\u001b[0m 5s/step - accuracy: 0.4890 - loss: 8.2360 getitem, batch_nr 205 train is: True\n",
      "\u001b[1m 205/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:15\u001b[0m 5s/step - accuracy: 0.4891 - loss: 8.2344 getitem, batch_nr 206 train is: True\n",
      "\u001b[1m 206/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:10\u001b[0m 5s/step - accuracy: 0.4892 - loss: 8.2328 getitem, batch_nr 207 train is: True\n",
      "\u001b[1m 207/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:05\u001b[0m 5s/step - accuracy: 0.4893 - loss: 8.2313 getitem, batch_nr 208 train is: True\n",
      "\u001b[1m 208/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:00\u001b[0m 5s/step - accuracy: 0.4894 - loss: 8.2298 getitem, batch_nr 209 train is: True\n",
      "\u001b[1m 209/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:55\u001b[0m 5s/step - accuracy: 0.4895 - loss: 8.2283 getitem, batch_nr 210 train is: True\n",
      "\u001b[1m 210/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:50\u001b[0m 5s/step - accuracy: 0.4896 - loss: 8.2267 getitem, batch_nr 211 train is: True\n",
      "\u001b[1m 211/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 5s/step - accuracy: 0.4897 - loss: 8.2252 getitem, batch_nr 212 train is: True\n",
      "\u001b[1m 212/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:41\u001b[0m 5s/step - accuracy: 0.4898 - loss: 8.2237 getitem, batch_nr 213 train is: True\n",
      "\u001b[1m 213/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:36\u001b[0m 5s/step - accuracy: 0.4899 - loss: 8.2222 getitem, batch_nr 214 train is: True\n",
      "\u001b[1m 214/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:30\u001b[0m 5s/step - accuracy: 0.4900 - loss: 8.2208 getitem, batch_nr 215 train is: True\n",
      "\u001b[1m 215/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:25\u001b[0m 5s/step - accuracy: 0.4901 - loss: 8.2193 getitem, batch_nr 216 train is: True\n",
      "\u001b[1m 216/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:20\u001b[0m 5s/step - accuracy: 0.4901 - loss: 8.2178 getitem, batch_nr 217 train is: True\n",
      "\u001b[1m 217/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:15\u001b[0m 5s/step - accuracy: 0.4902 - loss: 8.2164 getitem, batch_nr 218 train is: True\n",
      "\u001b[1m 218/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:10\u001b[0m 5s/step - accuracy: 0.4903 - loss: 8.2149 getitem, batch_nr 219 train is: True\n",
      "\u001b[1m 219/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:05\u001b[0m 5s/step - accuracy: 0.4904 - loss: 8.2134 getitem, batch_nr 220 train is: True\n",
      "\u001b[1m 220/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:59\u001b[0m 5s/step - accuracy: 0.4905 - loss: 8.2118 getitem, batch_nr 221 train is: True\n",
      "\u001b[1m 221/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:54\u001b[0m 5s/step - accuracy: 0.4906 - loss: 8.2103 getitem, batch_nr 222 train is: True\n",
      "\u001b[1m 222/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:50\u001b[0m 5s/step - accuracy: 0.4907 - loss: 8.2088 getitem, batch_nr 223 train is: True\n",
      "\u001b[1m 223/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:45\u001b[0m 5s/step - accuracy: 0.4908 - loss: 8.2073 getitem, batch_nr 224 train is: True\n",
      "\u001b[1m 224/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:40\u001b[0m 5s/step - accuracy: 0.4909 - loss: 8.2058 getitem, batch_nr 225 train is: True\n",
      "\u001b[1m 225/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:34\u001b[0m 5s/step - accuracy: 0.4910 - loss: 8.2043 getitem, batch_nr 226 train is: True\n",
      "\u001b[1m 226/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:29\u001b[0m 5s/step - accuracy: 0.4911 - loss: 8.2029 getitem, batch_nr 227 train is: True\n",
      "\u001b[1m 227/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:24\u001b[0m 5s/step - accuracy: 0.4912 - loss: 8.2015 getitem, batch_nr 228 train is: True\n",
      "\u001b[1m 228/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:19\u001b[0m 5s/step - accuracy: 0.4912 - loss: 8.2001 getitem, batch_nr 229 train is: True\n",
      "\u001b[1m 229/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:14\u001b[0m 5s/step - accuracy: 0.4913 - loss: 8.1987 getitem, batch_nr 230 train is: True\n",
      "\u001b[1m 230/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:08\u001b[0m 5s/step - accuracy: 0.4914 - loss: 8.1974 getitem, batch_nr 231 train is: True\n",
      "\u001b[1m 231/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:03\u001b[0m 5s/step - accuracy: 0.4915 - loss: 8.1960 getitem, batch_nr 232 train is: True\n",
      "\u001b[1m 232/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:58\u001b[0m 5s/step - accuracy: 0.4916 - loss: 8.1947 getitem, batch_nr 233 train is: True\n",
      "\u001b[1m 233/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:53\u001b[0m 5s/step - accuracy: 0.4917 - loss: 8.1934 getitem, batch_nr 234 train is: True\n",
      "\u001b[1m 234/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:48\u001b[0m 5s/step - accuracy: 0.4918 - loss: 8.1920 getitem, batch_nr 235 train is: True\n",
      "\u001b[1m 235/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:43\u001b[0m 5s/step - accuracy: 0.4918 - loss: 8.1907 getitem, batch_nr 236 train is: True\n",
      "\u001b[1m 236/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:37\u001b[0m 5s/step - accuracy: 0.4919 - loss: 8.1893 getitem, batch_nr 237 train is: True\n",
      "\u001b[1m 237/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:33\u001b[0m 5s/step - accuracy: 0.4920 - loss: 8.1880 getitem, batch_nr 238 train is: True\n",
      "\u001b[1m 238/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:27\u001b[0m 5s/step - accuracy: 0.4921 - loss: 8.1866 getitem, batch_nr 239 train is: True\n",
      "\u001b[1m 239/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:23\u001b[0m 5s/step - accuracy: 0.4922 - loss: 8.1853 getitem, batch_nr 240 train is: True\n",
      "\u001b[1m 240/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:17\u001b[0m 5s/step - accuracy: 0.4923 - loss: 8.1839 getitem, batch_nr 241 train is: True\n",
      "\u001b[1m 241/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 5s/step - accuracy: 0.4923 - loss: 8.1827 getitem, batch_nr 242 train is: True\n",
      "\u001b[1m 242/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:08\u001b[0m 5s/step - accuracy: 0.4924 - loss: 8.1815 getitem, batch_nr 243 train is: True\n",
      "\u001b[1m 243/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:02\u001b[0m 5s/step - accuracy: 0.4925 - loss: 8.1803 getitem, batch_nr 244 train is: True\n",
      "\u001b[1m 244/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:57\u001b[0m 5s/step - accuracy: 0.4925 - loss: 8.1792 getitem, batch_nr 245 train is: True\n",
      "\u001b[1m 245/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:52\u001b[0m 5s/step - accuracy: 0.4926 - loss: 8.1782 getitem, batch_nr 246 train is: True\n",
      "\u001b[1m 246/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:47\u001b[0m 5s/step - accuracy: 0.4927 - loss: 8.1772 getitem, batch_nr 247 train is: True\n",
      "\u001b[1m 247/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:41\u001b[0m 5s/step - accuracy: 0.4927 - loss: 8.1762 getitem, batch_nr 248 train is: True\n",
      "\u001b[1m 248/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:36\u001b[0m 5s/step - accuracy: 0.4928 - loss: 8.1752 getitem, batch_nr 249 train is: True\n",
      "\u001b[1m 249/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:31\u001b[0m 5s/step - accuracy: 0.4928 - loss: 8.1743 getitem, batch_nr 250 train is: True\n",
      "\u001b[1m 250/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:26\u001b[0m 5s/step - accuracy: 0.4929 - loss: 8.1734 getitem, batch_nr 251 train is: True\n",
      "\u001b[1m 251/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:20\u001b[0m 5s/step - accuracy: 0.4930 - loss: 8.1725 getitem, batch_nr 252 train is: True\n",
      "\u001b[1m 252/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:15\u001b[0m 5s/step - accuracy: 0.4930 - loss: 8.1717 getitem, batch_nr 253 train is: True\n",
      "\u001b[1m 253/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:10\u001b[0m 5s/step - accuracy: 0.4931 - loss: 8.1709 getitem, batch_nr 254 train is: True\n",
      "\u001b[1m 254/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:05\u001b[0m 5s/step - accuracy: 0.4931 - loss: 8.1702 getitem, batch_nr 255 train is: True\n",
      "\u001b[1m 255/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:59\u001b[0m 5s/step - accuracy: 0.4932 - loss: 8.1695 getitem, batch_nr 256 train is: True\n",
      "\u001b[1m 256/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:55\u001b[0m 5s/step - accuracy: 0.4932 - loss: 8.1688 getitem, batch_nr 257 train is: True\n",
      "\u001b[1m 257/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:50\u001b[0m 5s/step - accuracy: 0.4932 - loss: 8.1681 getitem, batch_nr 258 train is: True\n",
      "\u001b[1m 258/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:45\u001b[0m 5s/step - accuracy: 0.4933 - loss: 8.1675 getitem, batch_nr 259 train is: True\n",
      "\u001b[1m 259/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:39\u001b[0m 5s/step - accuracy: 0.4933 - loss: 8.1670 getitem, batch_nr 260 train is: True\n",
      "\u001b[1m 260/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:34\u001b[0m 5s/step - accuracy: 0.4933 - loss: 8.1664 getitem, batch_nr 261 train is: True\n",
      "\u001b[1m 261/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:28\u001b[0m 5s/step - accuracy: 0.4934 - loss: 8.1659 getitem, batch_nr 262 train is: True\n",
      "\u001b[1m 262/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:23\u001b[0m 5s/step - accuracy: 0.4934 - loss: 8.1655 getitem, batch_nr 263 train is: True\n",
      "\u001b[1m 263/1316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:18\u001b[0m 5s/step - accuracy: 0.4934 - loss: 8.1650 getitem, batch_nr 264 train is: True\n",
      "\u001b[1m 264/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:13\u001b[0m 5s/step - accuracy: 0.4935 - loss: 8.1646 getitem, batch_nr 265 train is: True\n",
      "\u001b[1m 265/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:08\u001b[0m 5s/step - accuracy: 0.4935 - loss: 8.1642 getitem, batch_nr 266 train is: True\n",
      "\u001b[1m 266/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:03\u001b[0m 5s/step - accuracy: 0.4935 - loss: 8.1638 getitem, batch_nr 267 train is: True\n",
      "\u001b[1m 267/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:58\u001b[0m 5s/step - accuracy: 0.4935 - loss: 8.1634 getitem, batch_nr 268 train is: True\n",
      "\u001b[1m 268/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:53\u001b[0m 5s/step - accuracy: 0.4936 - loss: 8.1630 getitem, batch_nr 269 train is: True\n",
      "\u001b[1m 269/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:47\u001b[0m 5s/step - accuracy: 0.4936 - loss: 8.1626 getitem, batch_nr 270 train is: True\n",
      "\u001b[1m 270/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:42\u001b[0m 5s/step - accuracy: 0.4936 - loss: 8.1621 getitem, batch_nr 271 train is: True\n",
      "\u001b[1m 271/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:37\u001b[0m 5s/step - accuracy: 0.4936 - loss: 8.1616 getitem, batch_nr 272 train is: True\n",
      "\u001b[1m 272/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:32\u001b[0m 5s/step - accuracy: 0.4937 - loss: 8.1612 getitem, batch_nr 273 train is: True\n",
      "\u001b[1m 273/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:28\u001b[0m 5s/step - accuracy: 0.4937 - loss: 8.1607 getitem, batch_nr 274 train is: True\n",
      "\u001b[1m 274/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:23\u001b[0m 5s/step - accuracy: 0.4937 - loss: 8.1603 getitem, batch_nr 275 train is: True\n",
      "\u001b[1m 275/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:18\u001b[0m 5s/step - accuracy: 0.4938 - loss: 8.1598 getitem, batch_nr 276 train is: True\n",
      "\u001b[1m 276/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:13\u001b[0m 5s/step - accuracy: 0.4938 - loss: 8.1593 getitem, batch_nr 277 train is: True\n",
      "\u001b[1m 277/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:08\u001b[0m 5s/step - accuracy: 0.4938 - loss: 8.1588 getitem, batch_nr 278 train is: True\n",
      "\u001b[1m 278/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29:03\u001b[0m 5s/step - accuracy: 0.4938 - loss: 8.1582 getitem, batch_nr 279 train is: True\n",
      "\u001b[1m 279/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:58\u001b[0m 5s/step - accuracy: 0.4939 - loss: 8.1576 getitem, batch_nr 280 train is: True\n",
      "\u001b[1m 280/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:53\u001b[0m 5s/step - accuracy: 0.4939 - loss: 8.1570 getitem, batch_nr 281 train is: True\n",
      "\u001b[1m 281/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:47\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1565 getitem, batch_nr 282 train is: True\n",
      "\u001b[1m 282/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:42\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1560 getitem, batch_nr 283 train is: True\n",
      "\u001b[1m 283/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:37\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1556 getitem, batch_nr 284 train is: True\n",
      "\u001b[1m 284/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:32\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1553 getitem, batch_nr 285 train is: True\n",
      "\u001b[1m 285/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:27\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1550 getitem, batch_nr 286 train is: True\n",
      "\u001b[1m 286/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:22\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1548 getitem, batch_nr 287 train is: True\n",
      "\u001b[1m 287/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:16\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1546 getitem, batch_nr 288 train is: True\n",
      "\u001b[1m 288/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:12\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1544 getitem, batch_nr 289 train is: True\n",
      "\u001b[1m 289/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:06\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1544 getitem, batch_nr 290 train is: True\n",
      "\u001b[1m 290/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28:02\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1543 getitem, batch_nr 291 train is: True\n",
      "\u001b[1m 291/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:57\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1543 getitem, batch_nr 292 train is: True\n",
      "\u001b[1m 292/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:52\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1544 getitem, batch_nr 293 train is: True\n",
      "\u001b[1m 293/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:47\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1545 getitem, batch_nr 294 train is: True\n",
      "\u001b[1m 294/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:42\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1546 getitem, batch_nr 295 train is: True\n",
      "\u001b[1m 295/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:37\u001b[0m 5s/step - accuracy: 0.4941 - loss: 8.1548 getitem, batch_nr 296 train is: True\n",
      "\u001b[1m 296/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:32\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1550 getitem, batch_nr 297 train is: True\n",
      "\u001b[1m 297/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:26\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1553 getitem, batch_nr 298 train is: True\n",
      "\u001b[1m 298/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:21\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1556 getitem, batch_nr 299 train is: True\n",
      "\u001b[1m 299/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:16\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1560 getitem, batch_nr 300 train is: True\n",
      "\u001b[1m 300/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:11\u001b[0m 5s/step - accuracy: 0.4940 - loss: 8.1564 getitem, batch_nr 301 train is: True\n",
      "\u001b[1m 301/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:06\u001b[0m 5s/step - accuracy: 0.4939 - loss: 8.1568 getitem, batch_nr 302 train is: True\n",
      "\u001b[1m 302/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:01\u001b[0m 5s/step - accuracy: 0.4939 - loss: 8.1573 getitem, batch_nr 303 train is: True\n",
      "\u001b[1m 303/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:56\u001b[0m 5s/step - accuracy: 0.4939 - loss: 8.1579 getitem, batch_nr 304 train is: True\n",
      "\u001b[1m 304/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:50\u001b[0m 5s/step - accuracy: 0.4938 - loss: 8.1585 getitem, batch_nr 305 train is: True\n",
      "\u001b[1m 305/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:45\u001b[0m 5s/step - accuracy: 0.4938 - loss: 8.1592 getitem, batch_nr 306 train is: True\n",
      "\u001b[1m 306/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:40\u001b[0m 5s/step - accuracy: 0.4937 - loss: 8.1599 getitem, batch_nr 307 train is: True\n",
      "\u001b[1m 307/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:36\u001b[0m 5s/step - accuracy: 0.4937 - loss: 8.1607 getitem, batch_nr 308 train is: True\n",
      "\u001b[1m 308/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:31\u001b[0m 5s/step - accuracy: 0.4936 - loss: 8.1616 getitem, batch_nr 309 train is: True\n",
      "\u001b[1m 309/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:26\u001b[0m 5s/step - accuracy: 0.4936 - loss: 8.1624 getitem, batch_nr 310 train is: True\n",
      "\u001b[1m 310/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:21\u001b[0m 5s/step - accuracy: 0.4935 - loss: 8.1633 getitem, batch_nr 311 train is: True\n",
      "\u001b[1m 311/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:16\u001b[0m 5s/step - accuracy: 0.4935 - loss: 8.1643 getitem, batch_nr 312 train is: True\n",
      "\u001b[1m 312/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:11\u001b[0m 5s/step - accuracy: 0.4934 - loss: 8.1653 getitem, batch_nr 313 train is: True\n",
      "\u001b[1m 313/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:06\u001b[0m 5s/step - accuracy: 0.4933 - loss: 8.1664 getitem, batch_nr 314 train is: True\n",
      "\u001b[1m 314/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26:01\u001b[0m 5s/step - accuracy: 0.4933 - loss: 8.1675 getitem, batch_nr 315 train is: True\n",
      "\u001b[1m 315/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:56\u001b[0m 5s/step - accuracy: 0.4932 - loss: 8.1686 getitem, batch_nr 316 train is: True\n",
      "\u001b[1m 316/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:50\u001b[0m 5s/step - accuracy: 0.4931 - loss: 8.1698 getitem, batch_nr 317 train is: True\n",
      "\u001b[1m 317/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:45\u001b[0m 5s/step - accuracy: 0.4931 - loss: 8.1710 getitem, batch_nr 318 train is: True\n",
      "\u001b[1m 318/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:40\u001b[0m 5s/step - accuracy: 0.4930 - loss: 8.1722 getitem, batch_nr 319 train is: True\n",
      "\u001b[1m 319/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:35\u001b[0m 5s/step - accuracy: 0.4929 - loss: 8.1734 getitem, batch_nr 320 train is: True\n",
      "\u001b[1m 320/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:30\u001b[0m 5s/step - accuracy: 0.4928 - loss: 8.1747 getitem, batch_nr 321 train is: True\n",
      "\u001b[1m 321/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:25\u001b[0m 5s/step - accuracy: 0.4927 - loss: 8.1760 getitem, batch_nr 322 train is: True\n",
      "\u001b[1m 322/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:20\u001b[0m 5s/step - accuracy: 0.4927 - loss: 8.1774 getitem, batch_nr 323 train is: True\n",
      "\u001b[1m 323/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:15\u001b[0m 5s/step - accuracy: 0.4926 - loss: 8.1787 getitem, batch_nr 324 train is: True\n",
      "\u001b[1m 324/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:10\u001b[0m 5s/step - accuracy: 0.4925 - loss: 8.1801 getitem, batch_nr 325 train is: True\n",
      "\u001b[1m 325/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:05\u001b[0m 5s/step - accuracy: 0.4924 - loss: 8.1816 getitem, batch_nr 326 train is: True\n",
      "\u001b[1m 326/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:00\u001b[0m 5s/step - accuracy: 0.4923 - loss: 8.1830 getitem, batch_nr 327 train is: True\n",
      "\u001b[1m 327/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:55\u001b[0m 5s/step - accuracy: 0.4922 - loss: 8.1845 getitem, batch_nr 328 train is: True\n",
      "\u001b[1m 328/1316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:50\u001b[0m 5s/step - accuracy: 0.4921 - loss: 8.1860 getitem, batch_nr 329 train is: True\n",
      "\u001b[1m 329/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:45\u001b[0m 5s/step - accuracy: 0.4920 - loss: 8.1875 getitem, batch_nr 330 train is: True\n",
      "\u001b[1m 330/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:40\u001b[0m 5s/step - accuracy: 0.4919 - loss: 8.1890 getitem, batch_nr 331 train is: True\n",
      "\u001b[1m 331/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:35\u001b[0m 5s/step - accuracy: 0.4918 - loss: 8.1906 getitem, batch_nr 332 train is: True\n",
      "\u001b[1m 332/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:30\u001b[0m 5s/step - accuracy: 0.4917 - loss: 8.1922 getitem, batch_nr 333 train is: True\n",
      "\u001b[1m 333/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:25\u001b[0m 5s/step - accuracy: 0.4916 - loss: 8.1938 getitem, batch_nr 334 train is: True\n",
      "\u001b[1m 334/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:20\u001b[0m 5s/step - accuracy: 0.4915 - loss: 8.1954 getitem, batch_nr 335 train is: True\n",
      "\u001b[1m 335/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:14\u001b[0m 5s/step - accuracy: 0.4914 - loss: 8.1971 getitem, batch_nr 336 train is: True\n",
      "\u001b[1m 336/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:09\u001b[0m 5s/step - accuracy: 0.4913 - loss: 8.1988 getitem, batch_nr 337 train is: True\n",
      "\u001b[1m 337/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24:04\u001b[0m 5s/step - accuracy: 0.4912 - loss: 8.2005 getitem, batch_nr 338 train is: True\n",
      "\u001b[1m 338/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:59\u001b[0m 5s/step - accuracy: 0.4911 - loss: 8.2023 getitem, batch_nr 339 train is: True\n",
      "\u001b[1m 339/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:54\u001b[0m 5s/step - accuracy: 0.4910 - loss: 8.2040 getitem, batch_nr 340 train is: True\n",
      "\u001b[1m 340/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:49\u001b[0m 5s/step - accuracy: 0.4909 - loss: 8.2058 getitem, batch_nr 341 train is: True\n",
      "\u001b[1m 341/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:44\u001b[0m 5s/step - accuracy: 0.4908 - loss: 8.2077 getitem, batch_nr 342 train is: True\n",
      "\u001b[1m 342/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:38\u001b[0m 5s/step - accuracy: 0.4907 - loss: 8.2096 getitem, batch_nr 343 train is: True\n",
      "\u001b[1m 343/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:33\u001b[0m 5s/step - accuracy: 0.4905 - loss: 8.2115 getitem, batch_nr 344 train is: True\n",
      "\u001b[1m 344/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:28\u001b[0m 5s/step - accuracy: 0.4904 - loss: 8.2134 getitem, batch_nr 345 train is: True\n",
      "\u001b[1m 345/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:23\u001b[0m 5s/step - accuracy: 0.4903 - loss: 8.2154 getitem, batch_nr 346 train is: True\n",
      "\u001b[1m 346/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:18\u001b[0m 5s/step - accuracy: 0.4902 - loss: 8.2173 getitem, batch_nr 347 train is: True\n",
      "\u001b[1m 347/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:13\u001b[0m 5s/step - accuracy: 0.4901 - loss: 8.2193 getitem, batch_nr 348 train is: True\n",
      "\u001b[1m 348/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:08\u001b[0m 5s/step - accuracy: 0.4899 - loss: 8.2214 getitem, batch_nr 349 train is: True\n",
      "\u001b[1m 349/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:03\u001b[0m 5s/step - accuracy: 0.4898 - loss: 8.2234 getitem, batch_nr 350 train is: True\n",
      "\u001b[1m 350/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:58\u001b[0m 5s/step - accuracy: 0.4897 - loss: 8.2255 getitem, batch_nr 351 train is: True\n",
      "\u001b[1m 351/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:52\u001b[0m 5s/step - accuracy: 0.4895 - loss: 8.2276 getitem, batch_nr 352 train is: True\n",
      "\u001b[1m 352/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:47\u001b[0m 5s/step - accuracy: 0.4894 - loss: 8.2296 getitem, batch_nr 353 train is: True\n",
      "\u001b[1m 353/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:42\u001b[0m 5s/step - accuracy: 0.4893 - loss: 8.2317 getitem, batch_nr 354 train is: True\n",
      "\u001b[1m 354/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:37\u001b[0m 5s/step - accuracy: 0.4892 - loss: 8.2339 getitem, batch_nr 355 train is: True\n",
      "\u001b[1m 355/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:32\u001b[0m 5s/step - accuracy: 0.4890 - loss: 8.2360 getitem, batch_nr 356 train is: True\n",
      "\u001b[1m 356/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:27\u001b[0m 5s/step - accuracy: 0.4889 - loss: 8.2381 getitem, batch_nr 357 train is: True\n",
      "\u001b[1m 357/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:22\u001b[0m 5s/step - accuracy: 0.4888 - loss: 8.2403 getitem, batch_nr 358 train is: True\n",
      "\u001b[1m 358/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:17\u001b[0m 5s/step - accuracy: 0.4886 - loss: 8.2423 getitem, batch_nr 359 train is: True\n",
      "\u001b[1m 359/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:12\u001b[0m 5s/step - accuracy: 0.4885 - loss: 8.2444 getitem, batch_nr 360 train is: True\n",
      "\u001b[1m 360/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:07\u001b[0m 5s/step - accuracy: 0.4884 - loss: 8.2463 getitem, batch_nr 361 train is: True\n",
      "\u001b[1m 361/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:02\u001b[0m 5s/step - accuracy: 0.4883 - loss: 8.2483 getitem, batch_nr 362 train is: True\n",
      "\u001b[1m 362/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:56\u001b[0m 5s/step - accuracy: 0.4881 - loss: 8.2501 getitem, batch_nr 363 train is: True\n",
      "\u001b[1m 363/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:51\u001b[0m 5s/step - accuracy: 0.4880 - loss: 8.2520 getitem, batch_nr 364 train is: True\n",
      "\u001b[1m 364/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:46\u001b[0m 5s/step - accuracy: 0.4879 - loss: 8.2537 getitem, batch_nr 365 train is: True\n",
      "\u001b[1m 365/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:41\u001b[0m 5s/step - accuracy: 0.4878 - loss: 8.2555 getitem, batch_nr 366 train is: True\n",
      "\u001b[1m 366/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:36\u001b[0m 5s/step - accuracy: 0.4877 - loss: 8.2572 getitem, batch_nr 367 train is: True\n",
      "\u001b[1m 367/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:31\u001b[0m 5s/step - accuracy: 0.4876 - loss: 8.2588 getitem, batch_nr 368 train is: True\n",
      "\u001b[1m 368/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:26\u001b[0m 5s/step - accuracy: 0.4875 - loss: 8.2604 getitem, batch_nr 369 train is: True\n",
      "\u001b[1m 369/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:21\u001b[0m 5s/step - accuracy: 0.4874 - loss: 8.2620 getitem, batch_nr 370 train is: True\n",
      "\u001b[1m 370/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:16\u001b[0m 5s/step - accuracy: 0.4873 - loss: 8.2635 getitem, batch_nr 371 train is: True\n",
      "\u001b[1m 371/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:10\u001b[0m 5s/step - accuracy: 0.4872 - loss: 8.2650 getitem, batch_nr 372 train is: True\n",
      "\u001b[1m 372/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:05\u001b[0m 5s/step - accuracy: 0.4871 - loss: 8.2664 getitem, batch_nr 373 train is: True\n",
      "\u001b[1m 373/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21:00\u001b[0m 5s/step - accuracy: 0.4871 - loss: 8.2678 getitem, batch_nr 374 train is: True\n",
      "\u001b[1m 374/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:54\u001b[0m 5s/step - accuracy: 0.4870 - loss: 8.2691 getitem, batch_nr 375 train is: True\n",
      "\u001b[1m 375/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:49\u001b[0m 5s/step - accuracy: 0.4869 - loss: 8.2704 getitem, batch_nr 376 train is: True\n",
      "\u001b[1m 376/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:44\u001b[0m 5s/step - accuracy: 0.4868 - loss: 8.2717 getitem, batch_nr 377 train is: True\n",
      "\u001b[1m 377/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:39\u001b[0m 5s/step - accuracy: 0.4867 - loss: 8.2729 getitem, batch_nr 378 train is: True\n",
      "\u001b[1m 378/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:34\u001b[0m 5s/step - accuracy: 0.4867 - loss: 8.2741 getitem, batch_nr 379 train is: True\n",
      "\u001b[1m 379/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:29\u001b[0m 5s/step - accuracy: 0.4866 - loss: 8.2752 getitem, batch_nr 380 train is: True\n",
      "\u001b[1m 380/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:24\u001b[0m 5s/step - accuracy: 0.4865 - loss: 8.2763 getitem, batch_nr 381 train is: True\n",
      "\u001b[1m 381/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:19\u001b[0m 5s/step - accuracy: 0.4865 - loss: 8.2774 getitem, batch_nr 382 train is: True\n",
      "\u001b[1m 382/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:13\u001b[0m 5s/step - accuracy: 0.4864 - loss: 8.2784 getitem, batch_nr 383 train is: True\n",
      "\u001b[1m 383/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:08\u001b[0m 5s/step - accuracy: 0.4863 - loss: 8.2794 getitem, batch_nr 384 train is: True\n",
      "\u001b[1m 384/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20:03\u001b[0m 5s/step - accuracy: 0.4863 - loss: 8.2804 getitem, batch_nr 385 train is: True\n",
      "\u001b[1m 385/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:58\u001b[0m 5s/step - accuracy: 0.4862 - loss: 8.2813 getitem, batch_nr 386 train is: True\n",
      "\u001b[1m 386/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:53\u001b[0m 5s/step - accuracy: 0.4862 - loss: 8.2822 getitem, batch_nr 387 train is: True\n",
      "\u001b[1m 387/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:48\u001b[0m 5s/step - accuracy: 0.4861 - loss: 8.2832 getitem, batch_nr 388 train is: True\n",
      "\u001b[1m 388/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:43\u001b[0m 5s/step - accuracy: 0.4860 - loss: 8.2842 getitem, batch_nr 389 train is: True\n",
      "\u001b[1m 389/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:38\u001b[0m 5s/step - accuracy: 0.4860 - loss: 8.2853 getitem, batch_nr 390 train is: True\n",
      "\u001b[1m 390/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:32\u001b[0m 5s/step - accuracy: 0.4859 - loss: 8.2863 getitem, batch_nr 391 train is: True\n",
      "\u001b[1m 391/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:27\u001b[0m 5s/step - accuracy: 0.4858 - loss: 8.2874 getitem, batch_nr 392 train is: True\n",
      "\u001b[1m 392/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:22\u001b[0m 5s/step - accuracy: 0.4858 - loss: 8.2885 getitem, batch_nr 393 train is: True\n",
      "\u001b[1m 393/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:17\u001b[0m 5s/step - accuracy: 0.4857 - loss: 8.2896 getitem, batch_nr 394 train is: True\n",
      "\u001b[1m 394/1316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:12\u001b[0m 5s/step - accuracy: 0.4856 - loss: 8.2907 getitem, batch_nr 395 train is: True\n",
      "\u001b[1m 395/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:07\u001b[0m 5s/step - accuracy: 0.4856 - loss: 8.2919 getitem, batch_nr 396 train is: True\n",
      "\u001b[1m 396/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19:02\u001b[0m 5s/step - accuracy: 0.4855 - loss: 8.2930 getitem, batch_nr 397 train is: True\n",
      "\u001b[1m 397/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:56\u001b[0m 5s/step - accuracy: 0.4854 - loss: 8.2942 getitem, batch_nr 398 train is: True\n",
      "\u001b[1m 398/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:51\u001b[0m 5s/step - accuracy: 0.4853 - loss: 8.2955 getitem, batch_nr 399 train is: True\n",
      "\u001b[1m 399/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:46\u001b[0m 5s/step - accuracy: 0.4853 - loss: 8.2967 getitem, batch_nr 400 train is: True\n",
      "\u001b[1m 400/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:41\u001b[0m 5s/step - accuracy: 0.4852 - loss: 8.2980 getitem, batch_nr 401 train is: True\n",
      "\u001b[1m 401/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:36\u001b[0m 5s/step - accuracy: 0.4851 - loss: 8.2993 getitem, batch_nr 402 train is: True\n",
      "\u001b[1m 402/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:31\u001b[0m 5s/step - accuracy: 0.4850 - loss: 8.3006 getitem, batch_nr 403 train is: True\n",
      "\u001b[1m 403/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:26\u001b[0m 5s/step - accuracy: 0.4849 - loss: 8.3019 getitem, batch_nr 404 train is: True\n",
      "\u001b[1m 404/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:21\u001b[0m 5s/step - accuracy: 0.4848 - loss: 8.3033 getitem, batch_nr 405 train is: True\n",
      "\u001b[1m 405/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:15\u001b[0m 5s/step - accuracy: 0.4848 - loss: 8.3047 getitem, batch_nr 406 train is: True\n",
      "\u001b[1m 406/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:10\u001b[0m 5s/step - accuracy: 0.4847 - loss: 8.3061 getitem, batch_nr 407 train is: True\n",
      "\u001b[1m 407/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:05\u001b[0m 5s/step - accuracy: 0.4846 - loss: 8.3075 getitem, batch_nr 408 train is: True\n",
      "\u001b[1m 408/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:18:00\u001b[0m 5s/step - accuracy: 0.4845 - loss: 8.3090 getitem, batch_nr 409 train is: True\n",
      "\u001b[1m 409/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:55\u001b[0m 5s/step - accuracy: 0.4844 - loss: 8.3105 getitem, batch_nr 410 train is: True\n",
      "\u001b[1m 410/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:49\u001b[0m 5s/step - accuracy: 0.4843 - loss: 8.3120 getitem, batch_nr 411 train is: True\n",
      "\u001b[1m 411/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:44\u001b[0m 5s/step - accuracy: 0.4842 - loss: 8.3134 getitem, batch_nr 412 train is: True\n",
      "\u001b[1m 412/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:39\u001b[0m 5s/step - accuracy: 0.4841 - loss: 8.3150 getitem, batch_nr 413 train is: True\n",
      "\u001b[1m 413/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:34\u001b[0m 5s/step - accuracy: 0.4840 - loss: 8.3165 getitem, batch_nr 414 train is: True\n",
      "\u001b[1m 414/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:29\u001b[0m 5s/step - accuracy: 0.4839 - loss: 8.3180 getitem, batch_nr 415 train is: True\n",
      "\u001b[1m 415/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:24\u001b[0m 5s/step - accuracy: 0.4838 - loss: 8.3195 getitem, batch_nr 416 train is: True\n",
      "\u001b[1m 416/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:19\u001b[0m 5s/step - accuracy: 0.4837 - loss: 8.3211 getitem, batch_nr 417 train is: True\n",
      "\u001b[1m 417/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:13\u001b[0m 5s/step - accuracy: 0.4836 - loss: 8.3227 getitem, batch_nr 418 train is: True\n",
      "\u001b[1m 418/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:08\u001b[0m 5s/step - accuracy: 0.4835 - loss: 8.3242 getitem, batch_nr 419 train is: True\n",
      "\u001b[1m 419/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:03\u001b[0m 5s/step - accuracy: 0.4834 - loss: 8.3258 getitem, batch_nr 420 train is: True\n",
      "\u001b[1m 420/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:58\u001b[0m 5s/step - accuracy: 0.4834 - loss: 8.3274 getitem, batch_nr 421 train is: True\n",
      "\u001b[1m 421/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:53\u001b[0m 5s/step - accuracy: 0.4832 - loss: 8.3290 getitem, batch_nr 422 train is: True\n",
      "\u001b[1m 422/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:48\u001b[0m 5s/step - accuracy: 0.4831 - loss: 8.3307 getitem, batch_nr 423 train is: True\n",
      "\u001b[1m 423/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:43\u001b[0m 5s/step - accuracy: 0.4830 - loss: 8.3323 getitem, batch_nr 424 train is: True\n",
      "\u001b[1m 424/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:37\u001b[0m 5s/step - accuracy: 0.4829 - loss: 8.3339 getitem, batch_nr 425 train is: True\n",
      "\u001b[1m 425/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:32\u001b[0m 5s/step - accuracy: 0.4828 - loss: 8.3356 getitem, batch_nr 426 train is: True\n",
      "\u001b[1m 426/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:27\u001b[0m 5s/step - accuracy: 0.4827 - loss: 8.3372 getitem, batch_nr 427 train is: True\n",
      "\u001b[1m 427/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:22\u001b[0m 5s/step - accuracy: 0.4826 - loss: 8.3389 getitem, batch_nr 428 train is: True\n",
      "\u001b[1m 428/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:17\u001b[0m 5s/step - accuracy: 0.4825 - loss: 8.3406 getitem, batch_nr 429 train is: True\n",
      "\u001b[1m 429/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:12\u001b[0m 5s/step - accuracy: 0.4824 - loss: 8.3423 getitem, batch_nr 430 train is: True\n",
      "\u001b[1m 430/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:07\u001b[0m 5s/step - accuracy: 0.4823 - loss: 8.3440 getitem, batch_nr 431 train is: True\n",
      "\u001b[1m 431/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:02\u001b[0m 5s/step - accuracy: 0.4822 - loss: 8.3457 getitem, batch_nr 432 train is: True\n",
      "\u001b[1m 432/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:56\u001b[0m 5s/step - accuracy: 0.4821 - loss: 8.3474 getitem, batch_nr 433 train is: True\n",
      "\u001b[1m 433/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:52\u001b[0m 5s/step - accuracy: 0.4820 - loss: 8.3492 getitem, batch_nr 434 train is: True\n",
      "\u001b[1m 434/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:47\u001b[0m 5s/step - accuracy: 0.4819 - loss: 8.3509 getitem, batch_nr 435 train is: True\n",
      "\u001b[1m 435/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:41\u001b[0m 5s/step - accuracy: 0.4818 - loss: 8.3526 getitem, batch_nr 436 train is: True\n",
      "\u001b[1m 436/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:36\u001b[0m 5s/step - accuracy: 0.4817 - loss: 8.3544 getitem, batch_nr 437 train is: True\n",
      "\u001b[1m 437/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:31\u001b[0m 5s/step - accuracy: 0.4816 - loss: 8.3562 getitem, batch_nr 438 train is: True\n",
      "\u001b[1m 438/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:26\u001b[0m 5s/step - accuracy: 0.4815 - loss: 8.3580 getitem, batch_nr 439 train is: True\n",
      "\u001b[1m 439/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:21\u001b[0m 5s/step - accuracy: 0.4813 - loss: 8.3598 getitem, batch_nr 440 train is: True\n",
      "\u001b[1m 440/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:16\u001b[0m 5s/step - accuracy: 0.4812 - loss: 8.3617 getitem, batch_nr 441 train is: True\n",
      "\u001b[1m 441/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:11\u001b[0m 5s/step - accuracy: 0.4811 - loss: 8.3635 getitem, batch_nr 442 train is: True\n",
      "\u001b[1m 442/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:05\u001b[0m 5s/step - accuracy: 0.4810 - loss: 8.3654 getitem, batch_nr 443 train is: True\n",
      "\u001b[1m 443/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:00\u001b[0m 5s/step - accuracy: 0.4809 - loss: 8.3673 getitem, batch_nr 444 train is: True\n",
      "\u001b[1m 444/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:55\u001b[0m 5s/step - accuracy: 0.4808 - loss: 8.3692 getitem, batch_nr 445 train is: True\n",
      "\u001b[1m 445/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:50\u001b[0m 5s/step - accuracy: 0.4806 - loss: 8.3711 getitem, batch_nr 446 train is: True\n",
      "\u001b[1m 446/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:45\u001b[0m 5s/step - accuracy: 0.4805 - loss: 8.3730 getitem, batch_nr 447 train is: True\n",
      "\u001b[1m 447/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:40\u001b[0m 5s/step - accuracy: 0.4804 - loss: 8.3750 getitem, batch_nr 448 train is: True\n",
      "\u001b[1m 448/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:35\u001b[0m 5s/step - accuracy: 0.4803 - loss: 8.3769 getitem, batch_nr 449 train is: True\n",
      "\u001b[1m 449/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:30\u001b[0m 5s/step - accuracy: 0.4802 - loss: 8.3788 getitem, batch_nr 450 train is: True\n",
      "\u001b[1m 450/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:25\u001b[0m 5s/step - accuracy: 0.4800 - loss: 8.3808 getitem, batch_nr 451 train is: True\n",
      "\u001b[1m 451/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:20\u001b[0m 5s/step - accuracy: 0.4799 - loss: 8.3828 getitem, batch_nr 452 train is: True\n",
      "\u001b[1m 452/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:15\u001b[0m 5s/step - accuracy: 0.4798 - loss: 8.3848 getitem, batch_nr 453 train is: True\n",
      "\u001b[1m 453/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:09\u001b[0m 5s/step - accuracy: 0.4797 - loss: 8.3868 getitem, batch_nr 454 train is: True\n",
      "\u001b[1m 454/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:04\u001b[0m 5s/step - accuracy: 0.4795 - loss: 8.3887 getitem, batch_nr 455 train is: True\n",
      "\u001b[1m 455/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:59\u001b[0m 5s/step - accuracy: 0.4794 - loss: 8.3907 getitem, batch_nr 456 train is: True\n",
      "\u001b[1m 456/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:54\u001b[0m 5s/step - accuracy: 0.4793 - loss: 8.3926 getitem, batch_nr 457 train is: True\n",
      "\u001b[1m 457/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:49\u001b[0m 5s/step - accuracy: 0.4792 - loss: 8.3945 getitem, batch_nr 458 train is: True\n",
      "\u001b[1m 458/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:43\u001b[0m 5s/step - accuracy: 0.4791 - loss: 8.3963 getitem, batch_nr 459 train is: True\n",
      "\u001b[1m 459/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:38\u001b[0m 5s/step - accuracy: 0.4790 - loss: 8.3982 getitem, batch_nr 460 train is: True\n",
      "\u001b[1m 460/1316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:33\u001b[0m 5s/step - accuracy: 0.4789 - loss: 8.3999 getitem, batch_nr 461 train is: True\n",
      "\u001b[1m 461/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:28\u001b[0m 5s/step - accuracy: 0.4787 - loss: 8.4017 getitem, batch_nr 462 train is: True\n",
      "\u001b[1m 462/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:23\u001b[0m 5s/step - accuracy: 0.4786 - loss: 8.4034 getitem, batch_nr 463 train is: True\n",
      "\u001b[1m 463/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:18\u001b[0m 5s/step - accuracy: 0.4785 - loss: 8.4051 getitem, batch_nr 464 train is: True\n",
      "\u001b[1m 464/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:13\u001b[0m 5s/step - accuracy: 0.4784 - loss: 8.4068 getitem, batch_nr 465 train is: True\n",
      "\u001b[1m 465/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:07\u001b[0m 5s/step - accuracy: 0.4783 - loss: 8.4084 getitem, batch_nr 466 train is: True\n",
      "\u001b[1m 466/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13:02\u001b[0m 5s/step - accuracy: 0.4782 - loss: 8.4100 getitem, batch_nr 467 train is: True\n",
      "\u001b[1m 467/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:57\u001b[0m 5s/step - accuracy: 0.4781 - loss: 8.4116 getitem, batch_nr 468 train is: True\n",
      "\u001b[1m 468/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:52\u001b[0m 5s/step - accuracy: 0.4780 - loss: 8.4131 getitem, batch_nr 469 train is: True\n",
      "\u001b[1m 469/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:46\u001b[0m 5s/step - accuracy: 0.4779 - loss: 8.4146 getitem, batch_nr 470 train is: True\n",
      "\u001b[1m 470/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:41\u001b[0m 5s/step - accuracy: 0.4778 - loss: 8.4161 getitem, batch_nr 471 train is: True\n",
      "\u001b[1m 471/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:36\u001b[0m 5s/step - accuracy: 0.4778 - loss: 8.4175 getitem, batch_nr 472 train is: True\n",
      "\u001b[1m 472/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:31\u001b[0m 5s/step - accuracy: 0.4777 - loss: 8.4190 getitem, batch_nr 473 train is: True\n",
      "\u001b[1m 473/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:26\u001b[0m 5s/step - accuracy: 0.4776 - loss: 8.4203 getitem, batch_nr 474 train is: True\n",
      "\u001b[1m 474/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:20\u001b[0m 5s/step - accuracy: 0.4775 - loss: 8.4217 getitem, batch_nr 475 train is: True\n",
      "\u001b[1m 475/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:15\u001b[0m 5s/step - accuracy: 0.4774 - loss: 8.4230 getitem, batch_nr 476 train is: True\n",
      "\u001b[1m 476/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:10\u001b[0m 5s/step - accuracy: 0.4773 - loss: 8.4244 getitem, batch_nr 477 train is: True\n",
      "\u001b[1m 477/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:05\u001b[0m 5s/step - accuracy: 0.4773 - loss: 8.4257 getitem, batch_nr 478 train is: True\n",
      "\u001b[1m 478/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:00\u001b[0m 5s/step - accuracy: 0.4772 - loss: 8.4270 getitem, batch_nr 479 train is: True\n",
      "\u001b[1m 479/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:55\u001b[0m 5s/step - accuracy: 0.4771 - loss: 8.4283 getitem, batch_nr 480 train is: True\n",
      "\u001b[1m 480/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:50\u001b[0m 5s/step - accuracy: 0.4770 - loss: 8.4297 getitem, batch_nr 481 train is: True\n",
      "\u001b[1m 481/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:45\u001b[0m 5s/step - accuracy: 0.4769 - loss: 8.4310 getitem, batch_nr 482 train is: True\n",
      "\u001b[1m 482/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:39\u001b[0m 5s/step - accuracy: 0.4768 - loss: 8.4324 getitem, batch_nr 483 train is: True\n",
      "\u001b[1m 483/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:34\u001b[0m 5s/step - accuracy: 0.4768 - loss: 8.4337 getitem, batch_nr 484 train is: True\n",
      "\u001b[1m 484/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:29\u001b[0m 5s/step - accuracy: 0.4767 - loss: 8.4351 getitem, batch_nr 485 train is: True\n",
      "\u001b[1m 485/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:24\u001b[0m 5s/step - accuracy: 0.4766 - loss: 8.4365 getitem, batch_nr 486 train is: True\n",
      "\u001b[1m 486/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:19\u001b[0m 5s/step - accuracy: 0.4765 - loss: 8.4379 getitem, batch_nr 487 train is: True\n",
      "\u001b[1m 487/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:13\u001b[0m 5s/step - accuracy: 0.4764 - loss: 8.4393 getitem, batch_nr 488 train is: True\n",
      "\u001b[1m 488/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:08\u001b[0m 5s/step - accuracy: 0.4763 - loss: 8.4407 getitem, batch_nr 489 train is: True\n",
      "\u001b[1m 489/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:03\u001b[0m 5s/step - accuracy: 0.4762 - loss: 8.4421 getitem, batch_nr 490 train is: True\n",
      "\u001b[1m 490/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:58\u001b[0m 5s/step - accuracy: 0.4761 - loss: 8.4435 getitem, batch_nr 491 train is: True\n",
      "\u001b[1m 491/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:52\u001b[0m 5s/step - accuracy: 0.4761 - loss: 8.4449 getitem, batch_nr 492 train is: True\n",
      "\u001b[1m 492/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:47\u001b[0m 5s/step - accuracy: 0.4760 - loss: 8.4464 getitem, batch_nr 493 train is: True\n",
      "\u001b[1m 493/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:42\u001b[0m 5s/step - accuracy: 0.4759 - loss: 8.4478 getitem, batch_nr 494 train is: True\n",
      "\u001b[1m 494/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:37\u001b[0m 5s/step - accuracy: 0.4758 - loss: 8.4493 getitem, batch_nr 495 train is: True\n",
      "\u001b[1m 495/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:32\u001b[0m 5s/step - accuracy: 0.4757 - loss: 8.4508 getitem, batch_nr 496 train is: True\n",
      "\u001b[1m 496/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:27\u001b[0m 5s/step - accuracy: 0.4756 - loss: 8.4523 getitem, batch_nr 497 train is: True\n",
      "\u001b[1m 497/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:22\u001b[0m 5s/step - accuracy: 0.4755 - loss: 8.4537 getitem, batch_nr 498 train is: True\n",
      "\u001b[1m 498/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:16\u001b[0m 5s/step - accuracy: 0.4754 - loss: 8.4552 getitem, batch_nr 499 train is: True\n",
      "\u001b[1m 499/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:11\u001b[0m 5s/step - accuracy: 0.4753 - loss: 8.4568 getitem, batch_nr 500 train is: True\n",
      "\u001b[1m 500/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:06\u001b[0m 5s/step - accuracy: 0.4752 - loss: 8.4583 getitem, batch_nr 501 train is: True\n",
      "\u001b[1m 501/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:01\u001b[0m 5s/step - accuracy: 0.4751 - loss: 8.4598 getitem, batch_nr 502 train is: True\n",
      "\u001b[1m 502/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:56\u001b[0m 5s/step - accuracy: 0.4750 - loss: 8.4614 getitem, batch_nr 503 train is: True\n",
      "\u001b[1m 503/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:51\u001b[0m 5s/step - accuracy: 0.4749 - loss: 8.4629 getitem, batch_nr 504 train is: True\n",
      "\u001b[1m 504/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:45\u001b[0m 5s/step - accuracy: 0.4748 - loss: 8.4645 getitem, batch_nr 505 train is: True\n",
      "\u001b[1m 505/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:40\u001b[0m 5s/step - accuracy: 0.4747 - loss: 8.4661 getitem, batch_nr 506 train is: True\n",
      "\u001b[1m 506/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:35\u001b[0m 5s/step - accuracy: 0.4746 - loss: 8.4677 getitem, batch_nr 507 train is: True\n",
      "\u001b[1m 507/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:30\u001b[0m 5s/step - accuracy: 0.4746 - loss: 8.4693 getitem, batch_nr 508 train is: True\n",
      "\u001b[1m 508/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:25\u001b[0m 5s/step - accuracy: 0.4745 - loss: 8.4709 getitem, batch_nr 509 train is: True\n",
      "\u001b[1m 509/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:20\u001b[0m 5s/step - accuracy: 0.4744 - loss: 8.4725 getitem, batch_nr 510 train is: True\n",
      "\u001b[1m 510/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:15\u001b[0m 5s/step - accuracy: 0.4743 - loss: 8.4741 getitem, batch_nr 511 train is: True\n",
      "\u001b[1m 511/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:10\u001b[0m 5s/step - accuracy: 0.4742 - loss: 8.4757 getitem, batch_nr 512 train is: True\n",
      "\u001b[1m 512/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:05\u001b[0m 5s/step - accuracy: 0.4740 - loss: 8.4773 getitem, batch_nr 513 train is: True\n",
      "\u001b[1m 513/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:59\u001b[0m 5s/step - accuracy: 0.4739 - loss: 8.4790 getitem, batch_nr 514 train is: True\n",
      "\u001b[1m 514/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:54\u001b[0m 5s/step - accuracy: 0.4738 - loss: 8.4806 getitem, batch_nr 515 train is: True\n",
      "\u001b[1m 515/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:49\u001b[0m 5s/step - accuracy: 0.4737 - loss: 8.4823 getitem, batch_nr 516 train is: True\n",
      "\u001b[1m 516/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:44\u001b[0m 5s/step - accuracy: 0.4736 - loss: 8.4839 getitem, batch_nr 517 train is: True\n",
      "\u001b[1m 517/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:39\u001b[0m 5s/step - accuracy: 0.4735 - loss: 8.4856 getitem, batch_nr 518 train is: True\n",
      "\u001b[1m 518/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:34\u001b[0m 5s/step - accuracy: 0.4734 - loss: 8.4872 getitem, batch_nr 519 train is: True\n",
      "\u001b[1m 519/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:29\u001b[0m 5s/step - accuracy: 0.4733 - loss: 8.4889 getitem, batch_nr 520 train is: True\n",
      "\u001b[1m 520/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:23\u001b[0m 5s/step - accuracy: 0.4732 - loss: 8.4906 getitem, batch_nr 521 train is: True\n",
      "\u001b[1m 521/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:18\u001b[0m 5s/step - accuracy: 0.4731 - loss: 8.4922 getitem, batch_nr 522 train is: True\n",
      "\u001b[1m 522/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:13\u001b[0m 5s/step - accuracy: 0.4730 - loss: 8.4939 getitem, batch_nr 523 train is: True\n",
      "\u001b[1m 523/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:08\u001b[0m 5s/step - accuracy: 0.4729 - loss: 8.4956 getitem, batch_nr 524 train is: True\n",
      "\u001b[1m 524/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08:03\u001b[0m 5s/step - accuracy: 0.4728 - loss: 8.4973 getitem, batch_nr 525 train is: True\n",
      "\u001b[1m 525/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:57\u001b[0m 5s/step - accuracy: 0.4727 - loss: 8.4990 getitem, batch_nr 526 train is: True\n",
      "\u001b[1m 526/1316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:52\u001b[0m 5s/step - accuracy: 0.4726 - loss: 8.5007 getitem, batch_nr 527 train is: True\n",
      "\u001b[1m 527/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:47\u001b[0m 5s/step - accuracy: 0.4725 - loss: 8.5024 getitem, batch_nr 528 train is: True\n",
      "\u001b[1m 528/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:42\u001b[0m 5s/step - accuracy: 0.4724 - loss: 8.5042 getitem, batch_nr 529 train is: True\n",
      "\u001b[1m 529/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:37\u001b[0m 5s/step - accuracy: 0.4723 - loss: 8.5059 getitem, batch_nr 530 train is: True\n",
      "\u001b[1m 530/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:31\u001b[0m 5s/step - accuracy: 0.4722 - loss: 8.5076 getitem, batch_nr 531 train is: True\n",
      "\u001b[1m 531/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:26\u001b[0m 5s/step - accuracy: 0.4721 - loss: 8.5093 getitem, batch_nr 532 train is: True\n",
      "\u001b[1m 532/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:21\u001b[0m 5s/step - accuracy: 0.4720 - loss: 8.5111 getitem, batch_nr 533 train is: True\n",
      "\u001b[1m 533/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:16\u001b[0m 5s/step - accuracy: 0.4718 - loss: 8.5128 getitem, batch_nr 534 train is: True\n",
      "\u001b[1m 534/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:11\u001b[0m 5s/step - accuracy: 0.4717 - loss: 8.5146 getitem, batch_nr 535 train is: True\n",
      "\u001b[1m 535/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:06\u001b[0m 5s/step - accuracy: 0.4716 - loss: 8.5163 getitem, batch_nr 536 train is: True\n",
      "\u001b[1m 536/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:00\u001b[0m 5s/step - accuracy: 0.4715 - loss: 8.5181 getitem, batch_nr 537 train is: True\n",
      "\u001b[1m 537/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:55\u001b[0m 5s/step - accuracy: 0.4714 - loss: 8.5199 getitem, batch_nr 538 train is: True\n",
      "\u001b[1m 538/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:50\u001b[0m 5s/step - accuracy: 0.4713 - loss: 8.5216 getitem, batch_nr 539 train is: True\n",
      "\u001b[1m 539/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:45\u001b[0m 5s/step - accuracy: 0.4712 - loss: 8.5234 getitem, batch_nr 540 train is: True\n",
      "\u001b[1m 540/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:40\u001b[0m 5s/step - accuracy: 0.4711 - loss: 8.5252 getitem, batch_nr 541 train is: True\n",
      "\u001b[1m 541/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:35\u001b[0m 5s/step - accuracy: 0.4710 - loss: 8.5270 getitem, batch_nr 542 train is: True\n",
      "\u001b[1m 542/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:29\u001b[0m 5s/step - accuracy: 0.4709 - loss: 8.5288 getitem, batch_nr 543 train is: True\n",
      "\u001b[1m 543/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:24\u001b[0m 5s/step - accuracy: 0.4707 - loss: 8.5306 getitem, batch_nr 544 train is: True\n",
      "\u001b[1m 544/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:19\u001b[0m 5s/step - accuracy: 0.4706 - loss: 8.5324 getitem, batch_nr 545 train is: True\n",
      "\u001b[1m 545/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:14\u001b[0m 5s/step - accuracy: 0.4705 - loss: 8.5342 getitem, batch_nr 546 train is: True\n",
      "\u001b[1m 546/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:09\u001b[0m 5s/step - accuracy: 0.4704 - loss: 8.5360 getitem, batch_nr 547 train is: True\n",
      "\u001b[1m 547/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:04\u001b[0m 5s/step - accuracy: 0.4703 - loss: 8.5378 getitem, batch_nr 548 train is: True\n",
      "\u001b[1m 548/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:59\u001b[0m 5s/step - accuracy: 0.4702 - loss: 8.5396 getitem, batch_nr 549 train is: True\n",
      "\u001b[1m 549/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:53\u001b[0m 5s/step - accuracy: 0.4701 - loss: 8.5414 getitem, batch_nr 550 train is: True\n",
      "\u001b[1m 550/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:48\u001b[0m 5s/step - accuracy: 0.4700 - loss: 8.5432 getitem, batch_nr 551 train is: True\n",
      "\u001b[1m 551/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:43\u001b[0m 5s/step - accuracy: 0.4699 - loss: 8.5449 getitem, batch_nr 552 train is: True\n",
      "\u001b[1m 552/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:38\u001b[0m 5s/step - accuracy: 0.4697 - loss: 8.5466 getitem, batch_nr 553 train is: True\n",
      "\u001b[1m 553/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:33\u001b[0m 5s/step - accuracy: 0.4696 - loss: 8.5483 getitem, batch_nr 554 train is: True\n",
      "\u001b[1m 554/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:27\u001b[0m 5s/step - accuracy: 0.4695 - loss: 8.5500 getitem, batch_nr 555 train is: True\n",
      "\u001b[1m 555/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:22\u001b[0m 5s/step - accuracy: 0.4694 - loss: 8.5517 getitem, batch_nr 556 train is: True\n",
      "\u001b[1m 556/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:18\u001b[0m 5s/step - accuracy: 0.4693 - loss: 8.5533 getitem, batch_nr 557 train is: True\n",
      "\u001b[1m 557/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:14\u001b[0m 5s/step - accuracy: 0.4692 - loss: 8.5550 getitem, batch_nr 558 train is: True\n",
      "\u001b[1m 558/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:10\u001b[0m 5s/step - accuracy: 0.4691 - loss: 8.5567 getitem, batch_nr 559 train is: True\n",
      "\u001b[1m 559/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:05\u001b[0m 5s/step - accuracy: 0.4690 - loss: 8.5584 getitem, batch_nr 560 train is: True\n",
      "\u001b[1m 560/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:05:00\u001b[0m 5s/step - accuracy: 0.4689 - loss: 8.5601 getitem, batch_nr 561 train is: True\n",
      "\u001b[1m 561/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:55\u001b[0m 5s/step - accuracy: 0.4688 - loss: 8.5618 getitem, batch_nr 562 train is: True\n",
      "\u001b[1m 562/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:50\u001b[0m 5s/step - accuracy: 0.4687 - loss: 8.5635 getitem, batch_nr 563 train is: True\n",
      "\u001b[1m 563/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:45\u001b[0m 5s/step - accuracy: 0.4686 - loss: 8.5652 getitem, batch_nr 564 train is: True\n",
      "\u001b[1m 564/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:40\u001b[0m 5s/step - accuracy: 0.4685 - loss: 8.5669 getitem, batch_nr 565 train is: True\n",
      "\u001b[1m 565/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:34\u001b[0m 5s/step - accuracy: 0.4684 - loss: 8.5686 getitem, batch_nr 566 train is: True\n",
      "\u001b[1m 566/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:29\u001b[0m 5s/step - accuracy: 0.4683 - loss: 8.5703 getitem, batch_nr 567 train is: True\n",
      "\u001b[1m 567/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:24\u001b[0m 5s/step - accuracy: 0.4682 - loss: 8.5720 getitem, batch_nr 568 train is: True\n",
      "\u001b[1m 568/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:19\u001b[0m 5s/step - accuracy: 0.4681 - loss: 8.5737 getitem, batch_nr 569 train is: True\n",
      "\u001b[1m 569/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:14\u001b[0m 5s/step - accuracy: 0.4680 - loss: 8.5754 getitem, batch_nr 570 train is: True\n",
      "\u001b[1m 570/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:08\u001b[0m 5s/step - accuracy: 0.4679 - loss: 8.5771 getitem, batch_nr 571 train is: True\n",
      "\u001b[1m 571/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:04:03\u001b[0m 5s/step - accuracy: 0.4678 - loss: 8.5788 getitem, batch_nr 572 train is: True\n",
      "\u001b[1m 572/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:58\u001b[0m 5s/step - accuracy: 0.4676 - loss: 8.5805 getitem, batch_nr 573 train is: True\n",
      "\u001b[1m 573/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:53\u001b[0m 5s/step - accuracy: 0.4675 - loss: 8.5823 getitem, batch_nr 574 train is: True\n",
      "\u001b[1m 574/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:47\u001b[0m 5s/step - accuracy: 0.4674 - loss: 8.5840 getitem, batch_nr 575 train is: True\n",
      "\u001b[1m 575/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:42\u001b[0m 5s/step - accuracy: 0.4673 - loss: 8.5857 getitem, batch_nr 576 train is: True\n",
      "\u001b[1m 576/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:37\u001b[0m 5s/step - accuracy: 0.4672 - loss: 8.5875 getitem, batch_nr 577 train is: True\n",
      "\u001b[1m 577/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:32\u001b[0m 5s/step - accuracy: 0.4671 - loss: 8.5892 getitem, batch_nr 578 train is: True\n",
      "\u001b[1m 578/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:27\u001b[0m 5s/step - accuracy: 0.4670 - loss: 8.5909 getitem, batch_nr 579 train is: True\n",
      "\u001b[1m 579/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:21\u001b[0m 5s/step - accuracy: 0.4669 - loss: 8.5927 getitem, batch_nr 580 train is: True\n",
      "\u001b[1m 580/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:16\u001b[0m 5s/step - accuracy: 0.4668 - loss: 8.5944 getitem, batch_nr 581 train is: True\n",
      "\u001b[1m 581/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:11\u001b[0m 5s/step - accuracy: 0.4667 - loss: 8.5962 getitem, batch_nr 582 train is: True\n",
      "\u001b[1m 582/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:06\u001b[0m 5s/step - accuracy: 0.4666 - loss: 8.5979 getitem, batch_nr 583 train is: True\n",
      "\u001b[1m 583/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:00\u001b[0m 5s/step - accuracy: 0.4665 - loss: 8.5997 getitem, batch_nr 584 train is: True\n",
      "\u001b[1m 584/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:55\u001b[0m 5s/step - accuracy: 0.4663 - loss: 8.6015 getitem, batch_nr 585 train is: True\n",
      "\u001b[1m 585/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:50\u001b[0m 5s/step - accuracy: 0.4662 - loss: 8.6032 getitem, batch_nr 586 train is: True\n",
      "\u001b[1m 586/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:45\u001b[0m 5s/step - accuracy: 0.4661 - loss: 8.6050 getitem, batch_nr 587 train is: True\n",
      "\u001b[1m 587/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:40\u001b[0m 5s/step - accuracy: 0.4660 - loss: 8.6068 getitem, batch_nr 588 train is: True\n",
      "\u001b[1m 588/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:34\u001b[0m 5s/step - accuracy: 0.4659 - loss: 8.6086 getitem, batch_nr 589 train is: True\n",
      "\u001b[1m 589/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:29\u001b[0m 5s/step - accuracy: 0.4658 - loss: 8.6104 getitem, batch_nr 590 train is: True\n",
      "\u001b[1m 590/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:24\u001b[0m 5s/step - accuracy: 0.4657 - loss: 8.6121 getitem, batch_nr 591 train is: True\n",
      "\u001b[1m 591/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:19\u001b[0m 5s/step - accuracy: 0.4656 - loss: 8.6139 getitem, batch_nr 592 train is: True\n",
      "\u001b[1m 592/1316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:02:13\u001b[0m 5s/step - accuracy: 0.4655 - loss: 8.6157 getitem, batch_nr 593 train is: True\n",
      "\u001b[1m 593/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:02:08\u001b[0m 5s/step - accuracy: 0.4653 - loss: 8.6176 getitem, batch_nr 594 train is: True\n",
      "\u001b[1m 594/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:02:03\u001b[0m 5s/step - accuracy: 0.4652 - loss: 8.6194 getitem, batch_nr 595 train is: True\n",
      "\u001b[1m 595/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:58\u001b[0m 5s/step - accuracy: 0.4651 - loss: 8.6212 getitem, batch_nr 596 train is: True\n",
      "\u001b[1m 596/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:52\u001b[0m 5s/step - accuracy: 0.4650 - loss: 8.6230 getitem, batch_nr 597 train is: True\n",
      "\u001b[1m 597/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:47\u001b[0m 5s/step - accuracy: 0.4649 - loss: 8.6248 getitem, batch_nr 598 train is: True\n",
      "\u001b[1m 598/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:42\u001b[0m 5s/step - accuracy: 0.4648 - loss: 8.6266 getitem, batch_nr 599 train is: True\n",
      "\u001b[1m 599/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:37\u001b[0m 5s/step - accuracy: 0.4647 - loss: 8.6285 getitem, batch_nr 600 train is: True\n",
      "\u001b[1m 600/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:32\u001b[0m 5s/step - accuracy: 0.4646 - loss: 8.6303 getitem, batch_nr 601 train is: True\n",
      "\u001b[1m 601/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:27\u001b[0m 5s/step - accuracy: 0.4644 - loss: 8.6321 getitem, batch_nr 602 train is: True\n",
      "\u001b[1m 602/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:21\u001b[0m 5s/step - accuracy: 0.4643 - loss: 8.6339 getitem, batch_nr 603 train is: True\n",
      "\u001b[1m 603/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:16\u001b[0m 5s/step - accuracy: 0.4642 - loss: 8.6358 getitem, batch_nr 604 train is: True\n",
      "\u001b[1m 604/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:11\u001b[0m 5s/step - accuracy: 0.4641 - loss: 8.6376 getitem, batch_nr 605 train is: True\n",
      "\u001b[1m 605/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:06\u001b[0m 5s/step - accuracy: 0.4640 - loss: 8.6394 getitem, batch_nr 606 train is: True\n",
      "\u001b[1m 606/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01:00\u001b[0m 5s/step - accuracy: 0.4639 - loss: 8.6412 getitem, batch_nr 607 train is: True\n",
      "\u001b[1m 607/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:55\u001b[0m 5s/step - accuracy: 0.4638 - loss: 8.6431 getitem, batch_nr 608 train is: True\n",
      "\u001b[1m 608/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:50\u001b[0m 5s/step - accuracy: 0.4637 - loss: 8.6449 getitem, batch_nr 609 train is: True\n",
      "\u001b[1m 609/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:45\u001b[0m 5s/step - accuracy: 0.4635 - loss: 8.6467 getitem, batch_nr 610 train is: True\n",
      "\u001b[1m 610/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:40\u001b[0m 5s/step - accuracy: 0.4634 - loss: 8.6486 getitem, batch_nr 611 train is: True\n",
      "\u001b[1m 611/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:35\u001b[0m 5s/step - accuracy: 0.4633 - loss: 8.6504 getitem, batch_nr 612 train is: True\n",
      "\u001b[1m 612/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:29\u001b[0m 5s/step - accuracy: 0.4632 - loss: 8.6522 getitem, batch_nr 613 train is: True\n",
      "\u001b[1m 613/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:24\u001b[0m 5s/step - accuracy: 0.4631 - loss: 8.6541 getitem, batch_nr 614 train is: True\n",
      "\u001b[1m 614/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:19\u001b[0m 5s/step - accuracy: 0.4630 - loss: 8.6559 getitem, batch_nr 615 train is: True\n",
      "\u001b[1m 615/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:14\u001b[0m 5s/step - accuracy: 0.4629 - loss: 8.6577 getitem, batch_nr 616 train is: True\n",
      "\u001b[1m 616/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:09\u001b[0m 5s/step - accuracy: 0.4627 - loss: 8.6596 getitem, batch_nr 617 train is: True\n",
      "\u001b[1m 617/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00:04\u001b[0m 5s/step - accuracy: 0.4626 - loss: 8.6614 getitem, batch_nr 618 train is: True\n",
      "\u001b[1m 618/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:58\u001b[0m 5s/step - accuracy: 0.4625 - loss: 8.6632   getitem, batch_nr 619 train is: True\n",
      "\u001b[1m 619/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:53\u001b[0m 5s/step - accuracy: 0.4624 - loss: 8.6651 getitem, batch_nr 620 train is: True\n",
      "\u001b[1m 620/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:48\u001b[0m 5s/step - accuracy: 0.4623 - loss: 8.6669 getitem, batch_nr 621 train is: True\n",
      "\u001b[1m 621/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:43\u001b[0m 5s/step - accuracy: 0.4622 - loss: 8.6688 getitem, batch_nr 622 train is: True\n",
      "\u001b[1m 622/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:37\u001b[0m 5s/step - accuracy: 0.4621 - loss: 8.6706 getitem, batch_nr 623 train is: True\n",
      "\u001b[1m 623/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:32\u001b[0m 5s/step - accuracy: 0.4619 - loss: 8.6725 getitem, batch_nr 624 train is: True\n",
      "\u001b[1m 624/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:27\u001b[0m 5s/step - accuracy: 0.4618 - loss: 8.6743 getitem, batch_nr 625 train is: True\n",
      "\u001b[1m 625/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:22\u001b[0m 5s/step - accuracy: 0.4617 - loss: 8.6762 getitem, batch_nr 626 train is: True\n",
      "\u001b[1m 626/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:17\u001b[0m 5s/step - accuracy: 0.4616 - loss: 8.6780 getitem, batch_nr 627 train is: True\n",
      "\u001b[1m 627/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:11\u001b[0m 5s/step - accuracy: 0.4615 - loss: 8.6798 getitem, batch_nr 628 train is: True\n",
      "\u001b[1m 628/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:06\u001b[0m 5s/step - accuracy: 0.4614 - loss: 8.6815 getitem, batch_nr 629 train is: True\n",
      "\u001b[1m 629/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59:01\u001b[0m 5s/step - accuracy: 0.4613 - loss: 8.6833 getitem, batch_nr 630 train is: True\n",
      "\u001b[1m 630/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:56\u001b[0m 5s/step - accuracy: 0.4612 - loss: 8.6850 getitem, batch_nr 631 train is: True\n",
      "\u001b[1m 631/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:51\u001b[0m 5s/step - accuracy: 0.4611 - loss: 8.6867 getitem, batch_nr 632 train is: True\n",
      "\u001b[1m 632/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:46\u001b[0m 5s/step - accuracy: 0.4610 - loss: 8.6884 getitem, batch_nr 633 train is: True\n",
      "\u001b[1m 633/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:40\u001b[0m 5s/step - accuracy: 0.4609 - loss: 8.6901 getitem, batch_nr 634 train is: True\n",
      "\u001b[1m 634/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:35\u001b[0m 5s/step - accuracy: 0.4607 - loss: 8.6917 getitem, batch_nr 635 train is: True\n",
      "\u001b[1m 635/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:30\u001b[0m 5s/step - accuracy: 0.4606 - loss: 8.6934 getitem, batch_nr 636 train is: True\n",
      "\u001b[1m 636/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:25\u001b[0m 5s/step - accuracy: 0.4605 - loss: 8.6950 getitem, batch_nr 637 train is: True\n",
      "\u001b[1m 637/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:20\u001b[0m 5s/step - accuracy: 0.4604 - loss: 8.6966 getitem, batch_nr 638 train is: True\n",
      "\u001b[1m 638/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:14\u001b[0m 5s/step - accuracy: 0.4604 - loss: 8.6981 getitem, batch_nr 639 train is: True\n",
      "\u001b[1m 639/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:09\u001b[0m 5s/step - accuracy: 0.4603 - loss: 8.6997 getitem, batch_nr 640 train is: True\n",
      "\u001b[1m 640/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m58:04\u001b[0m 5s/step - accuracy: 0.4602 - loss: 8.7012 getitem, batch_nr 641 train is: True\n",
      "\u001b[1m 641/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:59\u001b[0m 5s/step - accuracy: 0.4601 - loss: 8.7027 getitem, batch_nr 642 train is: True\n",
      "\u001b[1m 642/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:54\u001b[0m 5s/step - accuracy: 0.4600 - loss: 8.7042 getitem, batch_nr 643 train is: True\n",
      "fill_time_length_dimension_called\n",
      "\u001b[1m 643/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:48\u001b[0m 5s/step - accuracy: 0.4599 - loss: 8.7057 getitem, batch_nr 644 train is: True\n",
      "\u001b[1m 644/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:43\u001b[0m 5s/step - accuracy: 0.4598 - loss: 8.7072 getitem, batch_nr 645 train is: True\n",
      "\u001b[1m 645/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:38\u001b[0m 5s/step - accuracy: 0.4597 - loss: 8.7086 getitem, batch_nr 646 train is: True\n",
      "\u001b[1m 646/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:33\u001b[0m 5s/step - accuracy: 0.4596 - loss: 8.7101 getitem, batch_nr 647 train is: True\n",
      "\u001b[1m 647/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:27\u001b[0m 5s/step - accuracy: 0.4595 - loss: 8.7115 getitem, batch_nr 648 train is: True\n",
      "\u001b[1m 648/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:22\u001b[0m 5s/step - accuracy: 0.4594 - loss: 8.7129 getitem, batch_nr 649 train is: True\n",
      "\u001b[1m 649/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:17\u001b[0m 5s/step - accuracy: 0.4593 - loss: 8.7143 getitem, batch_nr 650 train is: True\n",
      "\u001b[1m 650/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:12\u001b[0m 5s/step - accuracy: 0.4593 - loss: 8.7156 getitem, batch_nr 651 train is: True\n",
      "\u001b[1m 651/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:07\u001b[0m 5s/step - accuracy: 0.4592 - loss: 8.7170 getitem, batch_nr 652 train is: True\n",
      "\u001b[1m 652/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57:02\u001b[0m 5s/step - accuracy: 0.4591 - loss: 8.7183 getitem, batch_nr 653 train is: True\n",
      "\u001b[1m 653/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:56\u001b[0m 5s/step - accuracy: 0.4590 - loss: 8.7196 getitem, batch_nr 654 train is: True\n",
      "\u001b[1m 654/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:51\u001b[0m 5s/step - accuracy: 0.4589 - loss: 8.7209 getitem, batch_nr 655 train is: True\n",
      "\u001b[1m 655/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:46\u001b[0m 5s/step - accuracy: 0.4589 - loss: 8.7222 getitem, batch_nr 656 train is: True\n",
      "\u001b[1m 656/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:41\u001b[0m 5s/step - accuracy: 0.4588 - loss: 8.7234 getitem, batch_nr 657 train is: True\n",
      "\u001b[1m 657/1316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m56:36\u001b[0m 5s/step - accuracy: 0.4587 - loss: 8.7247 getitem, batch_nr 658 train is: True\n",
      "\u001b[1m 658/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:31\u001b[0m 5s/step - accuracy: 0.4586 - loss: 8.7259 getitem, batch_nr 659 train is: True\n",
      "\u001b[1m 659/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:26\u001b[0m 5s/step - accuracy: 0.4586 - loss: 8.7271 getitem, batch_nr 660 train is: True\n",
      "\u001b[1m 660/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:21\u001b[0m 5s/step - accuracy: 0.4585 - loss: 8.7283 getitem, batch_nr 661 train is: True\n",
      "\u001b[1m 661/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:16\u001b[0m 5s/step - accuracy: 0.4584 - loss: 8.7295 getitem, batch_nr 662 train is: True\n",
      "\u001b[1m 662/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:10\u001b[0m 5s/step - accuracy: 0.4583 - loss: 8.7307 getitem, batch_nr 663 train is: True\n",
      "\u001b[1m 663/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:05\u001b[0m 5s/step - accuracy: 0.4583 - loss: 8.7319 getitem, batch_nr 664 train is: True\n",
      "\u001b[1m 664/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56:00\u001b[0m 5s/step - accuracy: 0.4582 - loss: 8.7331 getitem, batch_nr 665 train is: True\n",
      "\u001b[1m 665/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:55\u001b[0m 5s/step - accuracy: 0.4581 - loss: 8.7343 getitem, batch_nr 666 train is: True\n",
      "\u001b[1m 666/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:50\u001b[0m 5s/step - accuracy: 0.4580 - loss: 8.7355 getitem, batch_nr 667 train is: True\n",
      "\u001b[1m 667/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:44\u001b[0m 5s/step - accuracy: 0.4580 - loss: 8.7367 getitem, batch_nr 668 train is: True\n",
      "\u001b[1m 668/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:39\u001b[0m 5s/step - accuracy: 0.4579 - loss: 8.7379 getitem, batch_nr 669 train is: True\n",
      "\u001b[1m 669/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:34\u001b[0m 5s/step - accuracy: 0.4578 - loss: 8.7391 getitem, batch_nr 670 train is: True\n",
      "\u001b[1m 670/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:29\u001b[0m 5s/step - accuracy: 0.4577 - loss: 8.7403 getitem, batch_nr 671 train is: True\n",
      "\u001b[1m 671/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:24\u001b[0m 5s/step - accuracy: 0.4577 - loss: 8.7416 getitem, batch_nr 672 train is: True\n",
      "\u001b[1m 672/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:19\u001b[0m 5s/step - accuracy: 0.4576 - loss: 8.7428 getitem, batch_nr 673 train is: True\n",
      "\u001b[1m 673/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:13\u001b[0m 5s/step - accuracy: 0.4575 - loss: 8.7440 getitem, batch_nr 674 train is: True\n",
      "\u001b[1m 674/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:08\u001b[0m 5s/step - accuracy: 0.4574 - loss: 8.7453 getitem, batch_nr 675 train is: True\n",
      "\u001b[1m 675/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55:03\u001b[0m 5s/step - accuracy: 0.4573 - loss: 8.7465 getitem, batch_nr 676 train is: True\n",
      "\u001b[1m 676/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:58\u001b[0m 5s/step - accuracy: 0.4573 - loss: 8.7478 getitem, batch_nr 677 train is: True\n",
      "\u001b[1m 677/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:53\u001b[0m 5s/step - accuracy: 0.4572 - loss: 8.7490 getitem, batch_nr 678 train is: True\n",
      "\u001b[1m 678/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:48\u001b[0m 5s/step - accuracy: 0.4571 - loss: 8.7503 getitem, batch_nr 679 train is: True\n",
      "\u001b[1m 679/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:43\u001b[0m 5s/step - accuracy: 0.4570 - loss: 8.7515 getitem, batch_nr 680 train is: True\n",
      "\u001b[1m 680/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:37\u001b[0m 5s/step - accuracy: 0.4570 - loss: 8.7528 getitem, batch_nr 681 train is: True\n",
      "\u001b[1m 681/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:32\u001b[0m 5s/step - accuracy: 0.4569 - loss: 8.7541 getitem, batch_nr 682 train is: True\n",
      "\u001b[1m 682/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:27\u001b[0m 5s/step - accuracy: 0.4568 - loss: 8.7553 getitem, batch_nr 683 train is: True\n",
      "\u001b[1m 683/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:22\u001b[0m 5s/step - accuracy: 0.4567 - loss: 8.7566 getitem, batch_nr 684 train is: True\n",
      "\u001b[1m 684/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:17\u001b[0m 5s/step - accuracy: 0.4566 - loss: 8.7579 getitem, batch_nr 685 train is: True\n",
      "\u001b[1m 685/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:11\u001b[0m 5s/step - accuracy: 0.4566 - loss: 8.7592 getitem, batch_nr 686 train is: True\n",
      "\u001b[1m 686/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:06\u001b[0m 5s/step - accuracy: 0.4565 - loss: 8.7604 getitem, batch_nr 687 train is: True\n",
      "\u001b[1m 687/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m54:01\u001b[0m 5s/step - accuracy: 0.4564 - loss: 8.7617 getitem, batch_nr 688 train is: True\n",
      "\u001b[1m 688/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:56\u001b[0m 5s/step - accuracy: 0.4563 - loss: 8.7630 getitem, batch_nr 689 train is: True\n",
      "\u001b[1m 689/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:51\u001b[0m 5s/step - accuracy: 0.4562 - loss: 8.7643 getitem, batch_nr 690 train is: True\n",
      "\u001b[1m 690/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:45\u001b[0m 5s/step - accuracy: 0.4562 - loss: 8.7656 getitem, batch_nr 691 train is: True\n",
      "\u001b[1m 691/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:40\u001b[0m 5s/step - accuracy: 0.4561 - loss: 8.7668 getitem, batch_nr 692 train is: True\n",
      "\u001b[1m 692/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:35\u001b[0m 5s/step - accuracy: 0.4560 - loss: 8.7681 getitem, batch_nr 693 train is: True\n",
      "\u001b[1m 693/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:30\u001b[0m 5s/step - accuracy: 0.4559 - loss: 8.7694 getitem, batch_nr 694 train is: True\n",
      "\u001b[1m 694/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:25\u001b[0m 5s/step - accuracy: 0.4558 - loss: 8.7707 getitem, batch_nr 695 train is: True\n",
      "\u001b[1m 695/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:20\u001b[0m 5s/step - accuracy: 0.4558 - loss: 8.7720 getitem, batch_nr 696 train is: True\n",
      "\u001b[1m 696/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:14\u001b[0m 5s/step - accuracy: 0.4557 - loss: 8.7733 getitem, batch_nr 697 train is: True\n",
      "\u001b[1m 697/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:09\u001b[0m 5s/step - accuracy: 0.4556 - loss: 8.7746 getitem, batch_nr 698 train is: True\n",
      "\u001b[1m 698/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m53:04\u001b[0m 5s/step - accuracy: 0.4555 - loss: 8.7760 getitem, batch_nr 699 train is: True\n",
      "\u001b[1m 699/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:59\u001b[0m 5s/step - accuracy: 0.4554 - loss: 8.7773 getitem, batch_nr 700 train is: True\n",
      "\u001b[1m 700/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:54\u001b[0m 5s/step - accuracy: 0.4554 - loss: 8.7786 getitem, batch_nr 701 train is: True\n",
      "\u001b[1m 701/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:49\u001b[0m 5s/step - accuracy: 0.4553 - loss: 8.7799 getitem, batch_nr 702 train is: True\n",
      "\u001b[1m 702/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:43\u001b[0m 5s/step - accuracy: 0.4552 - loss: 8.7812 getitem, batch_nr 703 train is: True\n",
      "\u001b[1m 703/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:38\u001b[0m 5s/step - accuracy: 0.4551 - loss: 8.7826 getitem, batch_nr 704 train is: True\n",
      "\u001b[1m 704/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:33\u001b[0m 5s/step - accuracy: 0.4550 - loss: 8.7839 getitem, batch_nr 705 train is: True\n",
      "\u001b[1m 705/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:28\u001b[0m 5s/step - accuracy: 0.4549 - loss: 8.7852 getitem, batch_nr 706 train is: True\n",
      "\u001b[1m 706/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:23\u001b[0m 5s/step - accuracy: 0.4549 - loss: 8.7865 getitem, batch_nr 707 train is: True\n",
      "\u001b[1m 707/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:18\u001b[0m 5s/step - accuracy: 0.4548 - loss: 8.7878 getitem, batch_nr 708 train is: True\n",
      "\u001b[1m 708/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:12\u001b[0m 5s/step - accuracy: 0.4547 - loss: 8.7891 getitem, batch_nr 709 train is: True\n",
      "\u001b[1m 709/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:07\u001b[0m 5s/step - accuracy: 0.4546 - loss: 8.7904 getitem, batch_nr 710 train is: True\n",
      "\u001b[1m 710/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m52:02\u001b[0m 5s/step - accuracy: 0.4545 - loss: 8.7917 getitem, batch_nr 711 train is: True\n",
      "\u001b[1m 711/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:57\u001b[0m 5s/step - accuracy: 0.4545 - loss: 8.7931 getitem, batch_nr 712 train is: True\n",
      "\u001b[1m 712/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:52\u001b[0m 5s/step - accuracy: 0.4544 - loss: 8.7944 getitem, batch_nr 713 train is: True\n",
      "\u001b[1m 713/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:47\u001b[0m 5s/step - accuracy: 0.4543 - loss: 8.7957 getitem, batch_nr 714 train is: True\n",
      "\u001b[1m 714/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:41\u001b[0m 5s/step - accuracy: 0.4542 - loss: 8.7970 getitem, batch_nr 715 train is: True\n",
      "\u001b[1m 715/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:36\u001b[0m 5s/step - accuracy: 0.4541 - loss: 8.7983 getitem, batch_nr 716 train is: True\n",
      "\u001b[1m 716/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:31\u001b[0m 5s/step - accuracy: 0.4541 - loss: 8.7996 getitem, batch_nr 717 train is: True\n",
      "\u001b[1m 717/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:26\u001b[0m 5s/step - accuracy: 0.4540 - loss: 8.8009 getitem, batch_nr 718 train is: True\n",
      "\u001b[1m 718/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:21\u001b[0m 5s/step - accuracy: 0.4539 - loss: 8.8023 getitem, batch_nr 719 train is: True\n",
      "\u001b[1m 719/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:16\u001b[0m 5s/step - accuracy: 0.4538 - loss: 8.8036 getitem, batch_nr 720 train is: True\n",
      "\u001b[1m 720/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:10\u001b[0m 5s/step - accuracy: 0.4537 - loss: 8.8049 getitem, batch_nr 721 train is: True\n",
      "\u001b[1m 721/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:05\u001b[0m 5s/step - accuracy: 0.4536 - loss: 8.8062 getitem, batch_nr 722 train is: True\n",
      "\u001b[1m 722/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51:00\u001b[0m 5s/step - accuracy: 0.4536 - loss: 8.8076 getitem, batch_nr 723 train is: True\n",
      "\u001b[1m 723/1316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m50:55\u001b[0m 5s/step - accuracy: 0.4535 - loss: 8.8089 getitem, batch_nr 724 train is: True\n",
      "\u001b[1m 724/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:50\u001b[0m 5s/step - accuracy: 0.4534 - loss: 8.8102 getitem, batch_nr 725 train is: True\n",
      "\u001b[1m 725/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:45\u001b[0m 5s/step - accuracy: 0.4533 - loss: 8.8116 getitem, batch_nr 726 train is: True\n",
      "\u001b[1m 726/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:39\u001b[0m 5s/step - accuracy: 0.4532 - loss: 8.8129 getitem, batch_nr 727 train is: True\n",
      "\u001b[1m 727/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:34\u001b[0m 5s/step - accuracy: 0.4531 - loss: 8.8142 getitem, batch_nr 728 train is: True\n",
      "\u001b[1m 728/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:29\u001b[0m 5s/step - accuracy: 0.4531 - loss: 8.8156 getitem, batch_nr 729 train is: True\n",
      "\u001b[1m 729/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:24\u001b[0m 5s/step - accuracy: 0.4530 - loss: 8.8169 getitem, batch_nr 730 train is: True\n",
      "\u001b[1m 730/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:19\u001b[0m 5s/step - accuracy: 0.4529 - loss: 8.8183 getitem, batch_nr 731 train is: True\n",
      "\u001b[1m 731/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:14\u001b[0m 5s/step - accuracy: 0.4528 - loss: 8.8196 getitem, batch_nr 732 train is: True\n",
      "\u001b[1m 732/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:08\u001b[0m 5s/step - accuracy: 0.4527 - loss: 8.8210 getitem, batch_nr 733 train is: True\n",
      "\u001b[1m 733/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50:03\u001b[0m 5s/step - accuracy: 0.4526 - loss: 8.8223 getitem, batch_nr 734 train is: True\n",
      "\u001b[1m 734/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:58\u001b[0m 5s/step - accuracy: 0.4526 - loss: 8.8237 getitem, batch_nr 735 train is: True\n",
      "\u001b[1m 735/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:53\u001b[0m 5s/step - accuracy: 0.4525 - loss: 8.8250 getitem, batch_nr 736 train is: True\n",
      "\u001b[1m 736/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:48\u001b[0m 5s/step - accuracy: 0.4524 - loss: 8.8264 getitem, batch_nr 737 train is: True\n",
      "\u001b[1m 737/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:43\u001b[0m 5s/step - accuracy: 0.4523 - loss: 8.8277 getitem, batch_nr 738 train is: True\n",
      "\u001b[1m 738/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:37\u001b[0m 5s/step - accuracy: 0.4522 - loss: 8.8291 getitem, batch_nr 739 train is: True\n",
      "\u001b[1m 739/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:32\u001b[0m 5s/step - accuracy: 0.4521 - loss: 8.8305 getitem, batch_nr 740 train is: True\n",
      "\u001b[1m 740/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:27\u001b[0m 5s/step - accuracy: 0.4521 - loss: 8.8318 getitem, batch_nr 741 train is: True\n",
      "\u001b[1m 741/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:22\u001b[0m 5s/step - accuracy: 0.4520 - loss: 8.8332 getitem, batch_nr 742 train is: True\n",
      "\u001b[1m 742/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:17\u001b[0m 5s/step - accuracy: 0.4519 - loss: 8.8346 getitem, batch_nr 743 train is: True\n",
      "\u001b[1m 743/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:12\u001b[0m 5s/step - accuracy: 0.4518 - loss: 8.8360 getitem, batch_nr 744 train is: True\n",
      "\u001b[1m 744/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:06\u001b[0m 5s/step - accuracy: 0.4517 - loss: 8.8373 getitem, batch_nr 745 train is: True\n",
      "\u001b[1m 745/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49:01\u001b[0m 5s/step - accuracy: 0.4516 - loss: 8.8387 getitem, batch_nr 746 train is: True\n",
      "\u001b[1m 746/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:56\u001b[0m 5s/step - accuracy: 0.4515 - loss: 8.8401 getitem, batch_nr 747 train is: True\n",
      "\u001b[1m 747/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:51\u001b[0m 5s/step - accuracy: 0.4515 - loss: 8.8415 getitem, batch_nr 748 train is: True\n",
      "\u001b[1m 748/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:46\u001b[0m 5s/step - accuracy: 0.4514 - loss: 8.8429 getitem, batch_nr 749 train is: True\n",
      "\u001b[1m 749/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:41\u001b[0m 5s/step - accuracy: 0.4513 - loss: 8.8443 getitem, batch_nr 750 train is: True\n",
      "\u001b[1m 750/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:35\u001b[0m 5s/step - accuracy: 0.4512 - loss: 8.8457 getitem, batch_nr 751 train is: True\n",
      "\u001b[1m 751/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:30\u001b[0m 5s/step - accuracy: 0.4511 - loss: 8.8470 getitem, batch_nr 752 train is: True\n",
      "\u001b[1m 752/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:25\u001b[0m 5s/step - accuracy: 0.4510 - loss: 8.8484 getitem, batch_nr 753 train is: True\n",
      "\u001b[1m 753/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:20\u001b[0m 5s/step - accuracy: 0.4509 - loss: 8.8498 getitem, batch_nr 754 train is: True\n",
      "\u001b[1m 754/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:15\u001b[0m 5s/step - accuracy: 0.4509 - loss: 8.8512 getitem, batch_nr 755 train is: True\n",
      "\u001b[1m 755/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:10\u001b[0m 5s/step - accuracy: 0.4508 - loss: 8.8526 getitem, batch_nr 756 train is: True\n",
      "\u001b[1m 756/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48:04\u001b[0m 5s/step - accuracy: 0.4507 - loss: 8.8540 getitem, batch_nr 757 train is: True\n",
      "\u001b[1m 757/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:59\u001b[0m 5s/step - accuracy: 0.4506 - loss: 8.8554 getitem, batch_nr 758 train is: True\n",
      "\u001b[1m 758/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:54\u001b[0m 5s/step - accuracy: 0.4505 - loss: 8.8568 getitem, batch_nr 759 train is: True\n",
      "\u001b[1m 759/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:49\u001b[0m 5s/step - accuracy: 0.4504 - loss: 8.8582 getitem, batch_nr 760 train is: True\n",
      "\u001b[1m 760/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:44\u001b[0m 5s/step - accuracy: 0.4503 - loss: 8.8596 getitem, batch_nr 761 train is: True\n",
      "\u001b[1m 761/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:39\u001b[0m 5s/step - accuracy: 0.4502 - loss: 8.8610 getitem, batch_nr 762 train is: True\n",
      "\u001b[1m 762/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:34\u001b[0m 5s/step - accuracy: 0.4502 - loss: 8.8624 getitem, batch_nr 763 train is: True\n",
      "\u001b[1m 763/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:28\u001b[0m 5s/step - accuracy: 0.4501 - loss: 8.8638 getitem, batch_nr 764 train is: True\n",
      "\u001b[1m 764/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:23\u001b[0m 5s/step - accuracy: 0.4500 - loss: 8.8652 getitem, batch_nr 765 train is: True\n",
      "\u001b[1m 765/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:18\u001b[0m 5s/step - accuracy: 0.4499 - loss: 8.8666 getitem, batch_nr 766 train is: True\n",
      "\u001b[1m 766/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:13\u001b[0m 5s/step - accuracy: 0.4498 - loss: 8.8680 getitem, batch_nr 767 train is: True\n",
      "\u001b[1m 767/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:08\u001b[0m 5s/step - accuracy: 0.4497 - loss: 8.8694 getitem, batch_nr 768 train is: True\n",
      "\u001b[1m 768/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47:03\u001b[0m 5s/step - accuracy: 0.4496 - loss: 8.8708 getitem, batch_nr 769 train is: True\n",
      "\u001b[1m 769/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:58\u001b[0m 5s/step - accuracy: 0.4495 - loss: 8.8722 getitem, batch_nr 770 train is: True\n",
      "\u001b[1m 770/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:52\u001b[0m 5s/step - accuracy: 0.4495 - loss: 8.8736 getitem, batch_nr 771 train is: True\n",
      "\u001b[1m 771/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:47\u001b[0m 5s/step - accuracy: 0.4494 - loss: 8.8750 getitem, batch_nr 772 train is: True\n",
      "\u001b[1m 772/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:42\u001b[0m 5s/step - accuracy: 0.4493 - loss: 8.8764 getitem, batch_nr 773 train is: True\n",
      "\u001b[1m 773/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:37\u001b[0m 5s/step - accuracy: 0.4492 - loss: 8.8778 getitem, batch_nr 774 train is: True\n",
      "\u001b[1m 774/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:32\u001b[0m 5s/step - accuracy: 0.4491 - loss: 8.8792 getitem, batch_nr 775 train is: True\n",
      "\u001b[1m 775/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:27\u001b[0m 5s/step - accuracy: 0.4490 - loss: 8.8806 getitem, batch_nr 776 train is: True\n",
      "\u001b[1m 776/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:22\u001b[0m 5s/step - accuracy: 0.4489 - loss: 8.8820 getitem, batch_nr 777 train is: True\n",
      "\u001b[1m 777/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:17\u001b[0m 5s/step - accuracy: 0.4489 - loss: 8.8834 getitem, batch_nr 778 train is: True\n",
      "\u001b[1m 778/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:11\u001b[0m 5s/step - accuracy: 0.4488 - loss: 8.8849 getitem, batch_nr 779 train is: True\n",
      "\u001b[1m 779/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:06\u001b[0m 5s/step - accuracy: 0.4487 - loss: 8.8863 getitem, batch_nr 780 train is: True\n",
      "\u001b[1m 780/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m46:01\u001b[0m 5s/step - accuracy: 0.4486 - loss: 8.8877 getitem, batch_nr 781 train is: True\n",
      "\u001b[1m 781/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:56\u001b[0m 5s/step - accuracy: 0.4485 - loss: 8.8891 getitem, batch_nr 782 train is: True\n",
      "\u001b[1m 782/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:51\u001b[0m 5s/step - accuracy: 0.4484 - loss: 8.8905 getitem, batch_nr 783 train is: True\n",
      "\u001b[1m 783/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:46\u001b[0m 5s/step - accuracy: 0.4483 - loss: 8.8919 getitem, batch_nr 784 train is: True\n",
      "\u001b[1m 784/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:40\u001b[0m 5s/step - accuracy: 0.4482 - loss: 8.8933 getitem, batch_nr 785 train is: True\n",
      "\u001b[1m 785/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:35\u001b[0m 5s/step - accuracy: 0.4482 - loss: 8.8948 getitem, batch_nr 786 train is: True\n",
      "\u001b[1m 786/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:30\u001b[0m 5s/step - accuracy: 0.4481 - loss: 8.8962 getitem, batch_nr 787 train is: True\n",
      "\u001b[1m 787/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:25\u001b[0m 5s/step - accuracy: 0.4480 - loss: 8.8976 getitem, batch_nr 788 train is: True\n",
      "\u001b[1m 788/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:20\u001b[0m 5s/step - accuracy: 0.4479 - loss: 8.8990 getitem, batch_nr 789 train is: True\n",
      "\u001b[1m 789/1316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m45:15\u001b[0m 5s/step - accuracy: 0.4478 - loss: 8.9004 getitem, batch_nr 790 train is: True\n",
      "\u001b[1m 790/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m45:10\u001b[0m 5s/step - accuracy: 0.4477 - loss: 8.9018 getitem, batch_nr 791 train is: True\n",
      "\u001b[1m 791/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m45:04\u001b[0m 5s/step - accuracy: 0.4476 - loss: 8.9032 getitem, batch_nr 792 train is: True\n",
      "\u001b[1m 792/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:59\u001b[0m 5s/step - accuracy: 0.4475 - loss: 8.9046 getitem, batch_nr 793 train is: True\n",
      "\u001b[1m 793/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:54\u001b[0m 5s/step - accuracy: 0.4475 - loss: 8.9060 getitem, batch_nr 794 train is: True\n",
      "\u001b[1m 794/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:49\u001b[0m 5s/step - accuracy: 0.4474 - loss: 8.9074 getitem, batch_nr 795 train is: True\n",
      "\u001b[1m 795/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:44\u001b[0m 5s/step - accuracy: 0.4473 - loss: 8.9088 getitem, batch_nr 796 train is: True\n",
      "\u001b[1m 796/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:39\u001b[0m 5s/step - accuracy: 0.4472 - loss: 8.9102 getitem, batch_nr 797 train is: True\n",
      "\u001b[1m 797/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:34\u001b[0m 5s/step - accuracy: 0.4471 - loss: 8.9116 getitem, batch_nr 798 train is: True\n",
      "\u001b[1m 798/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:28\u001b[0m 5s/step - accuracy: 0.4470 - loss: 8.9130 getitem, batch_nr 799 train is: True\n",
      "\u001b[1m 799/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:23\u001b[0m 5s/step - accuracy: 0.4469 - loss: 8.9144 getitem, batch_nr 800 train is: True\n",
      "\u001b[1m 800/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:18\u001b[0m 5s/step - accuracy: 0.4468 - loss: 8.9158 getitem, batch_nr 801 train is: True\n",
      "\u001b[1m 801/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:13\u001b[0m 5s/step - accuracy: 0.4468 - loss: 8.9172 getitem, batch_nr 802 train is: True\n",
      "\u001b[1m 802/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:08\u001b[0m 5s/step - accuracy: 0.4467 - loss: 8.9186 getitem, batch_nr 803 train is: True\n",
      "\u001b[1m 803/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44:03\u001b[0m 5s/step - accuracy: 0.4466 - loss: 8.9200 getitem, batch_nr 804 train is: True\n",
      "\u001b[1m 804/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:58\u001b[0m 5s/step - accuracy: 0.4465 - loss: 8.9213 getitem, batch_nr 805 train is: True\n",
      "\u001b[1m 805/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:52\u001b[0m 5s/step - accuracy: 0.4464 - loss: 8.9226 getitem, batch_nr 806 train is: True\n",
      "\u001b[1m 806/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:47\u001b[0m 5s/step - accuracy: 0.4463 - loss: 8.9240 getitem, batch_nr 807 train is: True\n",
      "\u001b[1m 807/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:42\u001b[0m 5s/step - accuracy: 0.4463 - loss: 8.9253 getitem, batch_nr 808 train is: True\n",
      "\u001b[1m 808/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:37\u001b[0m 5s/step - accuracy: 0.4462 - loss: 8.9266 getitem, batch_nr 809 train is: True\n",
      "\u001b[1m 809/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:32\u001b[0m 5s/step - accuracy: 0.4461 - loss: 8.9279 getitem, batch_nr 810 train is: True\n",
      "\u001b[1m 810/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:27\u001b[0m 5s/step - accuracy: 0.4460 - loss: 8.9291 getitem, batch_nr 811 train is: True\n",
      "\u001b[1m 811/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:21\u001b[0m 5s/step - accuracy: 0.4459 - loss: 8.9304 getitem, batch_nr 812 train is: True\n",
      "\u001b[1m 812/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:16\u001b[0m 5s/step - accuracy: 0.4459 - loss: 8.9316 getitem, batch_nr 813 train is: True\n",
      "\u001b[1m 813/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:11\u001b[0m 5s/step - accuracy: 0.4458 - loss: 8.9329 getitem, batch_nr 814 train is: True\n",
      "\u001b[1m 814/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:06\u001b[0m 5s/step - accuracy: 0.4457 - loss: 8.9341 getitem, batch_nr 815 train is: True\n",
      "\u001b[1m 815/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43:01\u001b[0m 5s/step - accuracy: 0.4456 - loss: 8.9353 getitem, batch_nr 816 train is: True\n",
      "\u001b[1m 816/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:56\u001b[0m 5s/step - accuracy: 0.4456 - loss: 8.9365 getitem, batch_nr 817 train is: True\n",
      "\u001b[1m 817/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:50\u001b[0m 5s/step - accuracy: 0.4455 - loss: 8.9377 getitem, batch_nr 818 train is: True\n",
      "\u001b[1m 818/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:45\u001b[0m 5s/step - accuracy: 0.4454 - loss: 8.9389 getitem, batch_nr 819 train is: True\n",
      "\u001b[1m 819/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:40\u001b[0m 5s/step - accuracy: 0.4453 - loss: 8.9401 getitem, batch_nr 820 train is: True\n",
      "\u001b[1m 820/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:35\u001b[0m 5s/step - accuracy: 0.4453 - loss: 8.9413 getitem, batch_nr 821 train is: True\n",
      "\u001b[1m 821/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:30\u001b[0m 5s/step - accuracy: 0.4452 - loss: 8.9424 getitem, batch_nr 822 train is: True\n",
      "\u001b[1m 822/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:25\u001b[0m 5s/step - accuracy: 0.4451 - loss: 8.9436 getitem, batch_nr 823 train is: True\n",
      "\u001b[1m 823/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:19\u001b[0m 5s/step - accuracy: 0.4450 - loss: 8.9448 getitem, batch_nr 824 train is: True\n",
      "\u001b[1m 824/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:14\u001b[0m 5s/step - accuracy: 0.4450 - loss: 8.9459 getitem, batch_nr 825 train is: True\n",
      "\u001b[1m 825/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:09\u001b[0m 5s/step - accuracy: 0.4449 - loss: 8.9471 getitem, batch_nr 826 train is: True\n",
      "\u001b[1m 826/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42:04\u001b[0m 5s/step - accuracy: 0.4448 - loss: 8.9482 getitem, batch_nr 827 train is: True\n",
      "\u001b[1m 827/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:59\u001b[0m 5s/step - accuracy: 0.4448 - loss: 8.9493 getitem, batch_nr 828 train is: True\n",
      "\u001b[1m 828/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:53\u001b[0m 5s/step - accuracy: 0.4447 - loss: 8.9505 getitem, batch_nr 829 train is: True\n",
      "\u001b[1m 829/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:48\u001b[0m 5s/step - accuracy: 0.4446 - loss: 8.9516 getitem, batch_nr 830 train is: True\n",
      "\u001b[1m 830/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:43\u001b[0m 5s/step - accuracy: 0.4446 - loss: 8.9527 getitem, batch_nr 831 train is: True\n",
      "\u001b[1m 831/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:38\u001b[0m 5s/step - accuracy: 0.4445 - loss: 8.9538 getitem, batch_nr 832 train is: True\n",
      "\u001b[1m 832/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:33\u001b[0m 5s/step - accuracy: 0.4444 - loss: 8.9549 getitem, batch_nr 833 train is: True\n",
      "\u001b[1m 833/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:27\u001b[0m 5s/step - accuracy: 0.4443 - loss: 8.9560 getitem, batch_nr 834 train is: True\n",
      "\u001b[1m 834/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:22\u001b[0m 5s/step - accuracy: 0.4443 - loss: 8.9571 getitem, batch_nr 835 train is: True\n",
      "\u001b[1m 835/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:17\u001b[0m 5s/step - accuracy: 0.4442 - loss: 8.9582 getitem, batch_nr 836 train is: True\n",
      "\u001b[1m 836/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:12\u001b[0m 5s/step - accuracy: 0.4441 - loss: 8.9593 getitem, batch_nr 837 train is: True\n",
      "\u001b[1m 837/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:07\u001b[0m 5s/step - accuracy: 0.4441 - loss: 8.9604 getitem, batch_nr 838 train is: True\n",
      "\u001b[1m 838/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m41:02\u001b[0m 5s/step - accuracy: 0.4440 - loss: 8.9615 getitem, batch_nr 839 train is: True\n",
      "\u001b[1m 839/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:57\u001b[0m 5s/step - accuracy: 0.4439 - loss: 8.9626 getitem, batch_nr 840 train is: True\n",
      "\u001b[1m 840/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:51\u001b[0m 5s/step - accuracy: 0.4439 - loss: 8.9637 getitem, batch_nr 841 train is: True\n",
      "\u001b[1m 841/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:46\u001b[0m 5s/step - accuracy: 0.4438 - loss: 8.9647 getitem, batch_nr 842 train is: True\n",
      "\u001b[1m 842/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:41\u001b[0m 5s/step - accuracy: 0.4437 - loss: 8.9658 getitem, batch_nr 843 train is: True\n",
      "\u001b[1m 843/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:36\u001b[0m 5s/step - accuracy: 0.4437 - loss: 8.9669 getitem, batch_nr 844 train is: True\n",
      "\u001b[1m 844/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:31\u001b[0m 5s/step - accuracy: 0.4436 - loss: 8.9679 getitem, batch_nr 845 train is: True\n",
      "\u001b[1m 845/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:25\u001b[0m 5s/step - accuracy: 0.4435 - loss: 8.9690 getitem, batch_nr 846 train is: True\n",
      "\u001b[1m 846/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:20\u001b[0m 5s/step - accuracy: 0.4435 - loss: 8.9701 getitem, batch_nr 847 train is: True\n",
      "\u001b[1m 847/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:15\u001b[0m 5s/step - accuracy: 0.4434 - loss: 8.9711 getitem, batch_nr 848 train is: True\n",
      "\u001b[1m 848/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:10\u001b[0m 5s/step - accuracy: 0.4433 - loss: 8.9722 getitem, batch_nr 849 train is: True\n",
      "\u001b[1m 849/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:05\u001b[0m 5s/step - accuracy: 0.4433 - loss: 8.9732 getitem, batch_nr 850 train is: True\n",
      "\u001b[1m 850/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40:00\u001b[0m 5s/step - accuracy: 0.4432 - loss: 8.9742 getitem, batch_nr 851 train is: True\n",
      "\u001b[1m 851/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:55\u001b[0m 5s/step - accuracy: 0.4432 - loss: 8.9753 getitem, batch_nr 852 train is: True\n",
      "\u001b[1m 852/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:50\u001b[0m 5s/step - accuracy: 0.4431 - loss: 8.9763 getitem, batch_nr 853 train is: True\n",
      "\u001b[1m 853/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:44\u001b[0m 5s/step - accuracy: 0.4430 - loss: 8.9773 getitem, batch_nr 854 train is: True\n",
      "\u001b[1m 854/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:39\u001b[0m 5s/step - accuracy: 0.4430 - loss: 8.9783 getitem, batch_nr 855 train is: True\n",
      "\u001b[1m 855/1316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39:34\u001b[0m 5s/step - accuracy: 0.4429 - loss: 8.9794 getitem, batch_nr 856 train is: True\n",
      "\u001b[1m 856/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:29\u001b[0m 5s/step - accuracy: 0.4428 - loss: 8.9804 getitem, batch_nr 857 train is: True\n",
      "\u001b[1m 857/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:24\u001b[0m 5s/step - accuracy: 0.4428 - loss: 8.9814 getitem, batch_nr 858 train is: True\n",
      "\u001b[1m 858/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:18\u001b[0m 5s/step - accuracy: 0.4427 - loss: 8.9824 getitem, batch_nr 859 train is: True\n",
      "\u001b[1m 859/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:13\u001b[0m 5s/step - accuracy: 0.4426 - loss: 8.9834 getitem, batch_nr 860 train is: True\n",
      "\u001b[1m 860/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:08\u001b[0m 5s/step - accuracy: 0.4426 - loss: 8.9844 getitem, batch_nr 861 train is: True\n",
      "\u001b[1m 861/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39:03\u001b[0m 5s/step - accuracy: 0.4425 - loss: 8.9854 getitem, batch_nr 862 train is: True\n",
      "\u001b[1m 862/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:58\u001b[0m 5s/step - accuracy: 0.4425 - loss: 8.9864 getitem, batch_nr 863 train is: True\n",
      "\u001b[1m 863/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:53\u001b[0m 5s/step - accuracy: 0.4424 - loss: 8.9874 getitem, batch_nr 864 train is: True\n",
      "\u001b[1m 864/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:47\u001b[0m 5s/step - accuracy: 0.4423 - loss: 8.9884 getitem, batch_nr 865 train is: True\n",
      "\u001b[1m 865/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:42\u001b[0m 5s/step - accuracy: 0.4423 - loss: 8.9894 getitem, batch_nr 866 train is: True\n",
      "\u001b[1m 866/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:37\u001b[0m 5s/step - accuracy: 0.4422 - loss: 8.9903 getitem, batch_nr 867 train is: True\n",
      "\u001b[1m 867/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:32\u001b[0m 5s/step - accuracy: 0.4422 - loss: 8.9913 getitem, batch_nr 868 train is: True\n",
      "\u001b[1m 868/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:27\u001b[0m 5s/step - accuracy: 0.4421 - loss: 8.9923 getitem, batch_nr 869 train is: True\n",
      "\u001b[1m 869/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:22\u001b[0m 5s/step - accuracy: 0.4420 - loss: 8.9933 getitem, batch_nr 870 train is: True\n",
      "\u001b[1m 870/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:16\u001b[0m 5s/step - accuracy: 0.4420 - loss: 8.9942 getitem, batch_nr 871 train is: True\n",
      "\u001b[1m 871/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:11\u001b[0m 5s/step - accuracy: 0.4419 - loss: 8.9952 getitem, batch_nr 872 train is: True\n",
      "\u001b[1m 872/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:06\u001b[0m 5s/step - accuracy: 0.4419 - loss: 8.9961 getitem, batch_nr 873 train is: True\n",
      "\u001b[1m 873/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m38:01\u001b[0m 5s/step - accuracy: 0.4418 - loss: 8.9971 getitem, batch_nr 874 train is: True\n",
      "\u001b[1m 874/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:56\u001b[0m 5s/step - accuracy: 0.4417 - loss: 8.9980 getitem, batch_nr 875 train is: True\n",
      "\u001b[1m 875/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:51\u001b[0m 5s/step - accuracy: 0.4417 - loss: 8.9989 getitem, batch_nr 876 train is: True\n",
      "\u001b[1m 876/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:46\u001b[0m 5s/step - accuracy: 0.4416 - loss: 8.9999 getitem, batch_nr 877 train is: True\n",
      "\u001b[1m 877/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:40\u001b[0m 5s/step - accuracy: 0.4416 - loss: 9.0008 getitem, batch_nr 878 train is: True\n",
      "\u001b[1m 878/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:35\u001b[0m 5s/step - accuracy: 0.4415 - loss: 9.0017 getitem, batch_nr 879 train is: True\n",
      "\u001b[1m 879/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:30\u001b[0m 5s/step - accuracy: 0.4415 - loss: 9.0026 getitem, batch_nr 880 train is: True\n",
      "\u001b[1m 880/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:25\u001b[0m 5s/step - accuracy: 0.4414 - loss: 9.0036 getitem, batch_nr 881 train is: True\n",
      "\u001b[1m 881/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:20\u001b[0m 5s/step - accuracy: 0.4413 - loss: 9.0045 getitem, batch_nr 882 train is: True\n",
      "\u001b[1m 882/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:15\u001b[0m 5s/step - accuracy: 0.4413 - loss: 9.0054 getitem, batch_nr 883 train is: True\n",
      "\u001b[1m 883/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:09\u001b[0m 5s/step - accuracy: 0.4412 - loss: 9.0063 getitem, batch_nr 884 train is: True\n",
      "\u001b[1m 884/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37:04\u001b[0m 5s/step - accuracy: 0.4412 - loss: 9.0072 getitem, batch_nr 885 train is: True\n",
      "\u001b[1m 885/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:59\u001b[0m 5s/step - accuracy: 0.4411 - loss: 9.0081 getitem, batch_nr 886 train is: True\n",
      "\u001b[1m 886/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:54\u001b[0m 5s/step - accuracy: 0.4411 - loss: 9.0089 getitem, batch_nr 887 train is: True\n",
      "\u001b[1m 887/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:49\u001b[0m 5s/step - accuracy: 0.4410 - loss: 9.0098 getitem, batch_nr 888 train is: True\n",
      "\u001b[1m 888/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:44\u001b[0m 5s/step - accuracy: 0.4410 - loss: 9.0107 getitem, batch_nr 889 train is: True\n",
      "\u001b[1m 889/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:38\u001b[0m 5s/step - accuracy: 0.4409 - loss: 9.0116 getitem, batch_nr 890 train is: True\n",
      "\u001b[1m 890/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:33\u001b[0m 5s/step - accuracy: 0.4408 - loss: 9.0124 getitem, batch_nr 891 train is: True\n",
      "\u001b[1m 891/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:28\u001b[0m 5s/step - accuracy: 0.4408 - loss: 9.0133 getitem, batch_nr 892 train is: True\n",
      "\u001b[1m 892/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:23\u001b[0m 5s/step - accuracy: 0.4407 - loss: 9.0142 getitem, batch_nr 893 train is: True\n",
      "\u001b[1m 893/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:18\u001b[0m 5s/step - accuracy: 0.4407 - loss: 9.0150 getitem, batch_nr 894 train is: True\n",
      "\u001b[1m 894/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:13\u001b[0m 5s/step - accuracy: 0.4406 - loss: 9.0158 getitem, batch_nr 895 train is: True\n",
      "\u001b[1m 895/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:07\u001b[0m 5s/step - accuracy: 0.4406 - loss: 9.0167 getitem, batch_nr 896 train is: True\n",
      "\u001b[1m 896/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m36:02\u001b[0m 5s/step - accuracy: 0.4405 - loss: 9.0175 getitem, batch_nr 897 train is: True\n",
      "\u001b[1m 897/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:57\u001b[0m 5s/step - accuracy: 0.4405 - loss: 9.0183 getitem, batch_nr 898 train is: True\n",
      "\u001b[1m 898/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:52\u001b[0m 5s/step - accuracy: 0.4404 - loss: 9.0192 getitem, batch_nr 899 train is: True\n",
      "\u001b[1m 899/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:47\u001b[0m 5s/step - accuracy: 0.4404 - loss: 9.0200 getitem, batch_nr 900 train is: True\n",
      "\u001b[1m 900/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:42\u001b[0m 5s/step - accuracy: 0.4403 - loss: 9.0208 getitem, batch_nr 901 train is: True\n",
      "\u001b[1m 901/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:37\u001b[0m 5s/step - accuracy: 0.4403 - loss: 9.0216 getitem, batch_nr 902 train is: True\n",
      "\u001b[1m 902/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:31\u001b[0m 5s/step - accuracy: 0.4402 - loss: 9.0224 getitem, batch_nr 903 train is: True\n",
      "\u001b[1m 903/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:26\u001b[0m 5s/step - accuracy: 0.4402 - loss: 9.0232 getitem, batch_nr 904 train is: True\n",
      "\u001b[1m 904/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:21\u001b[0m 5s/step - accuracy: 0.4401 - loss: 9.0240 getitem, batch_nr 905 train is: True\n",
      "\u001b[1m 905/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:16\u001b[0m 5s/step - accuracy: 0.4401 - loss: 9.0248 getitem, batch_nr 906 train is: True\n",
      "\u001b[1m 906/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:11\u001b[0m 5s/step - accuracy: 0.4400 - loss: 9.0256 getitem, batch_nr 907 train is: True\n",
      "\u001b[1m 907/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:06\u001b[0m 5s/step - accuracy: 0.4400 - loss: 9.0264 getitem, batch_nr 908 train is: True\n",
      "\u001b[1m 908/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m35:01\u001b[0m 5s/step - accuracy: 0.4399 - loss: 9.0271 getitem, batch_nr 909 train is: True\n",
      "\u001b[1m 909/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:55\u001b[0m 5s/step - accuracy: 0.4399 - loss: 9.0279 getitem, batch_nr 910 train is: True\n",
      "\u001b[1m 910/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:50\u001b[0m 5s/step - accuracy: 0.4398 - loss: 9.0287 getitem, batch_nr 911 train is: True\n",
      "\u001b[1m 911/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:45\u001b[0m 5s/step - accuracy: 0.4398 - loss: 9.0294 getitem, batch_nr 912 train is: True\n",
      "\u001b[1m 912/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:40\u001b[0m 5s/step - accuracy: 0.4397 - loss: 9.0302 getitem, batch_nr 913 train is: True\n",
      "\u001b[1m 913/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:35\u001b[0m 5s/step - accuracy: 0.4397 - loss: 9.0310 getitem, batch_nr 914 train is: True\n",
      "\u001b[1m 914/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:30\u001b[0m 5s/step - accuracy: 0.4396 - loss: 9.0317 getitem, batch_nr 915 train is: True\n",
      "\u001b[1m 915/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:25\u001b[0m 5s/step - accuracy: 0.4396 - loss: 9.0325 getitem, batch_nr 916 train is: True\n",
      "\u001b[1m 916/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:19\u001b[0m 5s/step - accuracy: 0.4396 - loss: 9.0332 getitem, batch_nr 917 train is: True\n",
      "\u001b[1m 917/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:14\u001b[0m 5s/step - accuracy: 0.4395 - loss: 9.0340 getitem, batch_nr 918 train is: True\n",
      "\u001b[1m 918/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:09\u001b[0m 5s/step - accuracy: 0.4395 - loss: 9.0347 getitem, batch_nr 919 train is: True\n",
      "\u001b[1m 919/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m34:04\u001b[0m 5s/step - accuracy: 0.4394 - loss: 9.0355 getitem, batch_nr 920 train is: True\n",
      "\u001b[1m 920/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33:59\u001b[0m 5s/step - accuracy: 0.4394 - loss: 9.0362 getitem, batch_nr 921 train is: True\n",
      "\u001b[1m 921/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33:54\u001b[0m 5s/step - accuracy: 0.4393 - loss: 9.0369 getitem, batch_nr 922 train is: True\n",
      "\u001b[1m 922/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:49\u001b[0m 5s/step - accuracy: 0.4393 - loss: 9.0376 getitem, batch_nr 923 train is: True\n",
      "\u001b[1m 923/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:43\u001b[0m 5s/step - accuracy: 0.4392 - loss: 9.0384 getitem, batch_nr 924 train is: True\n",
      "\u001b[1m 924/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:38\u001b[0m 5s/step - accuracy: 0.4392 - loss: 9.0391 getitem, batch_nr 925 train is: True\n",
      "\u001b[1m 925/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:33\u001b[0m 5s/step - accuracy: 0.4391 - loss: 9.0398 getitem, batch_nr 926 train is: True\n",
      "\u001b[1m 926/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:28\u001b[0m 5s/step - accuracy: 0.4391 - loss: 9.0405 getitem, batch_nr 927 train is: True\n",
      "\u001b[1m 927/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:23\u001b[0m 5s/step - accuracy: 0.4391 - loss: 9.0412 getitem, batch_nr 928 train is: True\n",
      "\u001b[1m 928/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:18\u001b[0m 5s/step - accuracy: 0.4390 - loss: 9.0419 getitem, batch_nr 929 train is: True\n",
      "\u001b[1m 929/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:12\u001b[0m 5s/step - accuracy: 0.4390 - loss: 9.0426 getitem, batch_nr 930 train is: True\n",
      "\u001b[1m 930/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:07\u001b[0m 5s/step - accuracy: 0.4389 - loss: 9.0433 getitem, batch_nr 931 train is: True\n",
      "\u001b[1m 931/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33:02\u001b[0m 5s/step - accuracy: 0.4389 - loss: 9.0440 getitem, batch_nr 932 train is: True\n",
      "\u001b[1m 932/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:57\u001b[0m 5s/step - accuracy: 0.4388 - loss: 9.0447 getitem, batch_nr 933 train is: True\n",
      "\u001b[1m 933/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:52\u001b[0m 5s/step - accuracy: 0.4388 - loss: 9.0453 getitem, batch_nr 934 train is: True\n",
      "\u001b[1m 934/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:47\u001b[0m 5s/step - accuracy: 0.4388 - loss: 9.0460 getitem, batch_nr 935 train is: True\n",
      "\u001b[1m 935/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:41\u001b[0m 5s/step - accuracy: 0.4387 - loss: 9.0467 getitem, batch_nr 936 train is: True\n",
      "\u001b[1m 936/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:36\u001b[0m 5s/step - accuracy: 0.4387 - loss: 9.0474 getitem, batch_nr 937 train is: True\n",
      "\u001b[1m 937/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:31\u001b[0m 5s/step - accuracy: 0.4386 - loss: 9.0481 getitem, batch_nr 938 train is: True\n",
      "\u001b[1m 938/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:26\u001b[0m 5s/step - accuracy: 0.4386 - loss: 9.0487 getitem, batch_nr 939 train is: True\n",
      "\u001b[1m 939/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:21\u001b[0m 5s/step - accuracy: 0.4385 - loss: 9.0494 getitem, batch_nr 940 train is: True\n",
      "\u001b[1m 940/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:16\u001b[0m 5s/step - accuracy: 0.4385 - loss: 9.0501 getitem, batch_nr 941 train is: True\n",
      "\u001b[1m 941/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:11\u001b[0m 5s/step - accuracy: 0.4385 - loss: 9.0508 getitem, batch_nr 942 train is: True\n",
      "\u001b[1m 942/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:05\u001b[0m 5s/step - accuracy: 0.4384 - loss: 9.0514 getitem, batch_nr 943 train is: True\n",
      "\u001b[1m 943/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m32:00\u001b[0m 5s/step - accuracy: 0.4384 - loss: 9.0521 getitem, batch_nr 944 train is: True\n",
      "\u001b[1m 944/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:55\u001b[0m 5s/step - accuracy: 0.4383 - loss: 9.0527 getitem, batch_nr 945 train is: True\n",
      "\u001b[1m 945/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:50\u001b[0m 5s/step - accuracy: 0.4383 - loss: 9.0534 getitem, batch_nr 946 train is: True\n",
      "\u001b[1m 946/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:45\u001b[0m 5s/step - accuracy: 0.4383 - loss: 9.0540 getitem, batch_nr 947 train is: True\n",
      "\u001b[1m 947/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:40\u001b[0m 5s/step - accuracy: 0.4382 - loss: 9.0547 getitem, batch_nr 948 train is: True\n",
      "\u001b[1m 948/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:34\u001b[0m 5s/step - accuracy: 0.4382 - loss: 9.0553 getitem, batch_nr 949 train is: True\n",
      "\u001b[1m 949/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:29\u001b[0m 5s/step - accuracy: 0.4381 - loss: 9.0560 getitem, batch_nr 950 train is: True\n",
      "\u001b[1m 950/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:24\u001b[0m 5s/step - accuracy: 0.4381 - loss: 9.0566 getitem, batch_nr 951 train is: True\n",
      "\u001b[1m 951/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:19\u001b[0m 5s/step - accuracy: 0.4381 - loss: 9.0572 getitem, batch_nr 952 train is: True\n",
      "\u001b[1m 952/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:14\u001b[0m 5s/step - accuracy: 0.4380 - loss: 9.0579 getitem, batch_nr 953 train is: True\n",
      "\u001b[1m 953/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:09\u001b[0m 5s/step - accuracy: 0.4380 - loss: 9.0585 getitem, batch_nr 954 train is: True\n",
      "\u001b[1m 954/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31:04\u001b[0m 5s/step - accuracy: 0.4379 - loss: 9.0591 getitem, batch_nr 955 train is: True\n",
      "\u001b[1m 955/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:58\u001b[0m 5s/step - accuracy: 0.4379 - loss: 9.0598 getitem, batch_nr 956 train is: True\n",
      "\u001b[1m 956/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:53\u001b[0m 5s/step - accuracy: 0.4379 - loss: 9.0604 getitem, batch_nr 957 train is: True\n",
      "\u001b[1m 957/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:48\u001b[0m 5s/step - accuracy: 0.4378 - loss: 9.0610 getitem, batch_nr 958 train is: True\n",
      "\u001b[1m 958/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:43\u001b[0m 5s/step - accuracy: 0.4378 - loss: 9.0616 getitem, batch_nr 959 train is: True\n",
      "\u001b[1m 959/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:38\u001b[0m 5s/step - accuracy: 0.4378 - loss: 9.0622 getitem, batch_nr 960 train is: True\n",
      "\u001b[1m 960/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:33\u001b[0m 5s/step - accuracy: 0.4377 - loss: 9.0628 getitem, batch_nr 961 train is: True\n",
      "\u001b[1m 961/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:27\u001b[0m 5s/step - accuracy: 0.4377 - loss: 9.0634 getitem, batch_nr 962 train is: True\n",
      "\u001b[1m 962/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:22\u001b[0m 5s/step - accuracy: 0.4376 - loss: 9.0640 getitem, batch_nr 963 train is: True\n",
      "\u001b[1m 963/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:17\u001b[0m 5s/step - accuracy: 0.4376 - loss: 9.0646 getitem, batch_nr 964 train is: True\n",
      "\u001b[1m 964/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:12\u001b[0m 5s/step - accuracy: 0.4376 - loss: 9.0652 getitem, batch_nr 965 train is: True\n",
      "\u001b[1m 965/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:07\u001b[0m 5s/step - accuracy: 0.4375 - loss: 9.0658 getitem, batch_nr 966 train is: True\n",
      "\u001b[1m 966/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m30:02\u001b[0m 5s/step - accuracy: 0.4375 - loss: 9.0664 getitem, batch_nr 967 train is: True\n",
      "\u001b[1m 967/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:57\u001b[0m 5s/step - accuracy: 0.4375 - loss: 9.0669 getitem, batch_nr 968 train is: True\n",
      "\u001b[1m 968/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:51\u001b[0m 5s/step - accuracy: 0.4374 - loss: 9.0675 getitem, batch_nr 969 train is: True\n",
      "\u001b[1m 969/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:46\u001b[0m 5s/step - accuracy: 0.4374 - loss: 9.0681 getitem, batch_nr 970 train is: True\n",
      "\u001b[1m 970/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:41\u001b[0m 5s/step - accuracy: 0.4374 - loss: 9.0687 getitem, batch_nr 971 train is: True\n",
      "\u001b[1m 971/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:36\u001b[0m 5s/step - accuracy: 0.4373 - loss: 9.0692 getitem, batch_nr 972 train is: True\n",
      "\u001b[1m 972/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:31\u001b[0m 5s/step - accuracy: 0.4373 - loss: 9.0698 getitem, batch_nr 973 train is: True\n",
      "\u001b[1m 973/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:26\u001b[0m 5s/step - accuracy: 0.4373 - loss: 9.0703 getitem, batch_nr 974 train is: True\n",
      "\u001b[1m 974/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:20\u001b[0m 5s/step - accuracy: 0.4372 - loss: 9.0709 getitem, batch_nr 975 train is: True\n",
      "\u001b[1m 975/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:15\u001b[0m 5s/step - accuracy: 0.4372 - loss: 9.0715 getitem, batch_nr 976 train is: True\n",
      "\u001b[1m 976/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:10\u001b[0m 5s/step - accuracy: 0.4371 - loss: 9.0720 getitem, batch_nr 977 train is: True\n",
      "\u001b[1m 977/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:05\u001b[0m 5s/step - accuracy: 0.4371 - loss: 9.0726 getitem, batch_nr 978 train is: True\n",
      "\u001b[1m 978/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m29:00\u001b[0m 5s/step - accuracy: 0.4371 - loss: 9.0731 getitem, batch_nr 979 train is: True\n",
      "\u001b[1m 979/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:55\u001b[0m 5s/step - accuracy: 0.4370 - loss: 9.0737 getitem, batch_nr 980 train is: True\n",
      "\u001b[1m 980/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:49\u001b[0m 5s/step - accuracy: 0.4370 - loss: 9.0742 getitem, batch_nr 981 train is: True\n",
      "\u001b[1m 981/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:44\u001b[0m 5s/step - accuracy: 0.4370 - loss: 9.0748 getitem, batch_nr 982 train is: True\n",
      "\u001b[1m 982/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:39\u001b[0m 5s/step - accuracy: 0.4369 - loss: 9.0754 getitem, batch_nr 983 train is: True\n",
      "\u001b[1m 983/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:34\u001b[0m 5s/step - accuracy: 0.4369 - loss: 9.0759 getitem, batch_nr 984 train is: True\n",
      "\u001b[1m 984/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:29\u001b[0m 5s/step - accuracy: 0.4369 - loss: 9.0765 getitem, batch_nr 985 train is: True\n",
      "\u001b[1m 985/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:24\u001b[0m 5s/step - accuracy: 0.4368 - loss: 9.0770 getitem, batch_nr 986 train is: True\n",
      "\u001b[1m 986/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m28:18\u001b[0m 5s/step - accuracy: 0.4368 - loss: 9.0776 getitem, batch_nr 987 train is: True\n",
      "\u001b[1m 987/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28:13\u001b[0m 5s/step - accuracy: 0.4368 - loss: 9.0781 getitem, batch_nr 988 train is: True\n",
      "\u001b[1m 988/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28:08\u001b[0m 5s/step - accuracy: 0.4367 - loss: 9.0787 getitem, batch_nr 989 train is: True\n",
      "\u001b[1m 989/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28:03\u001b[0m 5s/step - accuracy: 0.4367 - loss: 9.0792 getitem, batch_nr 990 train is: True\n",
      "\u001b[1m 990/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:58\u001b[0m 5s/step - accuracy: 0.4367 - loss: 9.0798 getitem, batch_nr 991 train is: True\n",
      "\u001b[1m 991/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:53\u001b[0m 5s/step - accuracy: 0.4366 - loss: 9.0803 getitem, batch_nr 992 train is: True\n",
      "\u001b[1m 992/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:48\u001b[0m 5s/step - accuracy: 0.4366 - loss: 9.0809 getitem, batch_nr 993 train is: True\n",
      "\u001b[1m 993/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:42\u001b[0m 5s/step - accuracy: 0.4366 - loss: 9.0814 getitem, batch_nr 994 train is: True\n",
      "\u001b[1m 994/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:37\u001b[0m 5s/step - accuracy: 0.4365 - loss: 9.0820 getitem, batch_nr 995 train is: True\n",
      "\u001b[1m 995/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:32\u001b[0m 5s/step - accuracy: 0.4365 - loss: 9.0825 getitem, batch_nr 996 train is: True\n",
      "\u001b[1m 996/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:27\u001b[0m 5s/step - accuracy: 0.4365 - loss: 9.0830 getitem, batch_nr 997 train is: True\n",
      "\u001b[1m 997/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:22\u001b[0m 5s/step - accuracy: 0.4364 - loss: 9.0836 getitem, batch_nr 998 train is: True\n",
      "\u001b[1m 998/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:17\u001b[0m 5s/step - accuracy: 0.4364 - loss: 9.0841 getitem, batch_nr 999 train is: True\n",
      "\u001b[1m 999/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:12\u001b[0m 5s/step - accuracy: 0.4364 - loss: 9.0847 getitem, batch_nr 1000 train is: True\n",
      "\u001b[1m1000/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:06\u001b[0m 5s/step - accuracy: 0.4363 - loss: 9.0852 getitem, batch_nr 1001 train is: True\n",
      "\u001b[1m1001/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27:01\u001b[0m 5s/step - accuracy: 0.4363 - loss: 9.0858 getitem, batch_nr 1002 train is: True\n",
      "\u001b[1m1002/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:56\u001b[0m 5s/step - accuracy: 0.4363 - loss: 9.0863 getitem, batch_nr 1003 train is: True\n",
      "\u001b[1m1003/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:51\u001b[0m 5s/step - accuracy: 0.4362 - loss: 9.0868 getitem, batch_nr 1004 train is: True\n",
      "\u001b[1m1004/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:46\u001b[0m 5s/step - accuracy: 0.4362 - loss: 9.0874 getitem, batch_nr 1005 train is: True\n",
      "\u001b[1m1005/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:41\u001b[0m 5s/step - accuracy: 0.4362 - loss: 9.0879 getitem, batch_nr 1006 train is: True\n",
      "\u001b[1m1006/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:35\u001b[0m 5s/step - accuracy: 0.4361 - loss: 9.0884 getitem, batch_nr 1007 train is: True\n",
      "\u001b[1m1007/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:30\u001b[0m 5s/step - accuracy: 0.4361 - loss: 9.0890 getitem, batch_nr 1008 train is: True\n",
      "\u001b[1m1008/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:25\u001b[0m 5s/step - accuracy: 0.4361 - loss: 9.0895 getitem, batch_nr 1009 train is: True\n",
      "\u001b[1m1009/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:20\u001b[0m 5s/step - accuracy: 0.4360 - loss: 9.0900 getitem, batch_nr 1010 train is: True\n",
      "\u001b[1m1010/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:15\u001b[0m 5s/step - accuracy: 0.4360 - loss: 9.0905 getitem, batch_nr 1011 train is: True\n",
      "\u001b[1m1011/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:10\u001b[0m 5s/step - accuracy: 0.4360 - loss: 9.0911 getitem, batch_nr 1012 train is: True\n",
      "\u001b[1m1012/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26:05\u001b[0m 5s/step - accuracy: 0.4359 - loss: 9.0916 getitem, batch_nr 1013 train is: True\n",
      "\u001b[1m1013/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:59\u001b[0m 5s/step - accuracy: 0.4359 - loss: 9.0921 getitem, batch_nr 1014 train is: True\n",
      "\u001b[1m1014/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:54\u001b[0m 5s/step - accuracy: 0.4359 - loss: 9.0926 getitem, batch_nr 1015 train is: True\n",
      "\u001b[1m1015/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:49\u001b[0m 5s/step - accuracy: 0.4358 - loss: 9.0931 getitem, batch_nr 1016 train is: True\n",
      "\u001b[1m1016/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:44\u001b[0m 5s/step - accuracy: 0.4358 - loss: 9.0936 getitem, batch_nr 1017 train is: True\n",
      "\u001b[1m1017/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:39\u001b[0m 5s/step - accuracy: 0.4358 - loss: 9.0941 getitem, batch_nr 1018 train is: True\n",
      "\u001b[1m1018/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:34\u001b[0m 5s/step - accuracy: 0.4357 - loss: 9.0946 getitem, batch_nr 1019 train is: True\n",
      "\u001b[1m1019/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:29\u001b[0m 5s/step - accuracy: 0.4357 - loss: 9.0951 getitem, batch_nr 1020 train is: True\n",
      "\u001b[1m1020/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:23\u001b[0m 5s/step - accuracy: 0.4357 - loss: 9.0956 getitem, batch_nr 1021 train is: True\n",
      "\u001b[1m1021/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:18\u001b[0m 5s/step - accuracy: 0.4356 - loss: 9.0961 getitem, batch_nr 1022 train is: True\n",
      "\u001b[1m1022/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:13\u001b[0m 5s/step - accuracy: 0.4356 - loss: 9.0966 getitem, batch_nr 1023 train is: True\n",
      "\u001b[1m1023/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:08\u001b[0m 5s/step - accuracy: 0.4356 - loss: 9.0971 getitem, batch_nr 1024 train is: True\n",
      "\u001b[1m1024/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25:03\u001b[0m 5s/step - accuracy: 0.4356 - loss: 9.0976 getitem, batch_nr 1025 train is: True\n",
      "\u001b[1m1025/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:58\u001b[0m 5s/step - accuracy: 0.4355 - loss: 9.0981 getitem, batch_nr 1026 train is: True\n",
      "\u001b[1m1026/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:52\u001b[0m 5s/step - accuracy: 0.4355 - loss: 9.0986 getitem, batch_nr 1027 train is: True\n",
      "\u001b[1m1027/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:47\u001b[0m 5s/step - accuracy: 0.4355 - loss: 9.0991 getitem, batch_nr 1028 train is: True\n",
      "\u001b[1m1028/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:42\u001b[0m 5s/step - accuracy: 0.4354 - loss: 9.0996 getitem, batch_nr 1029 train is: True\n",
      "\u001b[1m1029/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:37\u001b[0m 5s/step - accuracy: 0.4354 - loss: 9.1001 getitem, batch_nr 1030 train is: True\n",
      "\u001b[1m1030/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:32\u001b[0m 5s/step - accuracy: 0.4354 - loss: 9.1006 getitem, batch_nr 1031 train is: True\n",
      "\u001b[1m1031/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:27\u001b[0m 5s/step - accuracy: 0.4353 - loss: 9.1010 getitem, batch_nr 1032 train is: True\n",
      "\u001b[1m1032/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:22\u001b[0m 5s/step - accuracy: 0.4353 - loss: 9.1015 getitem, batch_nr 1033 train is: True\n",
      "\u001b[1m1033/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:16\u001b[0m 5s/step - accuracy: 0.4353 - loss: 9.1020 getitem, batch_nr 1034 train is: True\n",
      "\u001b[1m1034/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:11\u001b[0m 5s/step - accuracy: 0.4353 - loss: 9.1025 getitem, batch_nr 1035 train is: True\n",
      "\u001b[1m1035/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:06\u001b[0m 5s/step - accuracy: 0.4352 - loss: 9.1029 getitem, batch_nr 1036 train is: True\n",
      "\u001b[1m1036/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24:01\u001b[0m 5s/step - accuracy: 0.4352 - loss: 9.1034 getitem, batch_nr 1037 train is: True\n",
      "\u001b[1m1037/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:56\u001b[0m 5s/step - accuracy: 0.4352 - loss: 9.1039 getitem, batch_nr 1038 train is: True\n",
      "\u001b[1m1038/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:51\u001b[0m 5s/step - accuracy: 0.4351 - loss: 9.1044 getitem, batch_nr 1039 train is: True\n",
      "\u001b[1m1039/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:46\u001b[0m 5s/step - accuracy: 0.4351 - loss: 9.1048 getitem, batch_nr 1040 train is: True\n",
      "\u001b[1m1040/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:40\u001b[0m 5s/step - accuracy: 0.4351 - loss: 9.1053 getitem, batch_nr 1041 train is: True\n",
      "\u001b[1m1041/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:35\u001b[0m 5s/step - accuracy: 0.4350 - loss: 9.1058 getitem, batch_nr 1042 train is: True\n",
      "\u001b[1m1042/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:30\u001b[0m 5s/step - accuracy: 0.4350 - loss: 9.1062 getitem, batch_nr 1043 train is: True\n",
      "\u001b[1m1043/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:25\u001b[0m 5s/step - accuracy: 0.4350 - loss: 9.1067 getitem, batch_nr 1044 train is: True\n",
      "\u001b[1m1044/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:20\u001b[0m 5s/step - accuracy: 0.4350 - loss: 9.1072 getitem, batch_nr 1045 train is: True\n",
      "\u001b[1m1045/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:15\u001b[0m 5s/step - accuracy: 0.4349 - loss: 9.1076 getitem, batch_nr 1046 train is: True\n",
      "\u001b[1m1046/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:10\u001b[0m 5s/step - accuracy: 0.4349 - loss: 9.1081 getitem, batch_nr 1047 train is: True\n",
      "\u001b[1m1047/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m23:04\u001b[0m 5s/step - accuracy: 0.4349 - loss: 9.1085 getitem, batch_nr 1048 train is: True\n",
      "\u001b[1m1048/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:59\u001b[0m 5s/step - accuracy: 0.4348 - loss: 9.1090 getitem, batch_nr 1049 train is: True\n",
      "\u001b[1m1049/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:54\u001b[0m 5s/step - accuracy: 0.4348 - loss: 9.1094 getitem, batch_nr 1050 train is: True\n",
      "\u001b[1m1050/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:49\u001b[0m 5s/step - accuracy: 0.4348 - loss: 9.1099 getitem, batch_nr 1051 train is: True\n",
      "\u001b[1m1051/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:44\u001b[0m 5s/step - accuracy: 0.4348 - loss: 9.1104 getitem, batch_nr 1052 train is: True\n",
      "\u001b[1m1052/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:39\u001b[0m 5s/step - accuracy: 0.4347 - loss: 9.1108 getitem, batch_nr 1053 train is: True\n",
      "\u001b[1m1053/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:34\u001b[0m 5s/step - accuracy: 0.4347 - loss: 9.1113 getitem, batch_nr 1054 train is: True\n",
      "\u001b[1m1054/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:28\u001b[0m 5s/step - accuracy: 0.4347 - loss: 9.1117 getitem, batch_nr 1055 train is: True\n",
      "\u001b[1m1055/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:23\u001b[0m 5s/step - accuracy: 0.4347 - loss: 9.1122 getitem, batch_nr 1056 train is: True\n",
      "\u001b[1m1056/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:18\u001b[0m 5s/step - accuracy: 0.4346 - loss: 9.1126 getitem, batch_nr 1057 train is: True\n",
      "\u001b[1m1057/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:13\u001b[0m 5s/step - accuracy: 0.4346 - loss: 9.1131 getitem, batch_nr 1058 train is: True\n",
      "\u001b[1m1058/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:08\u001b[0m 5s/step - accuracy: 0.4346 - loss: 9.1136 getitem, batch_nr 1059 train is: True\n",
      "\u001b[1m1059/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m22:03\u001b[0m 5s/step - accuracy: 0.4345 - loss: 9.1140 getitem, batch_nr 1060 train is: True\n",
      "\u001b[1m1060/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:58\u001b[0m 5s/step - accuracy: 0.4345 - loss: 9.1145 getitem, batch_nr 1061 train is: True\n",
      "\u001b[1m1061/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:52\u001b[0m 5s/step - accuracy: 0.4345 - loss: 9.1149 getitem, batch_nr 1062 train is: True\n",
      "\u001b[1m1062/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:47\u001b[0m 5s/step - accuracy: 0.4345 - loss: 9.1154 getitem, batch_nr 1063 train is: True\n",
      "\u001b[1m1063/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:42\u001b[0m 5s/step - accuracy: 0.4344 - loss: 9.1158 getitem, batch_nr 1064 train is: True\n",
      "\u001b[1m1064/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:37\u001b[0m 5s/step - accuracy: 0.4344 - loss: 9.1163 getitem, batch_nr 1065 train is: True\n",
      "\u001b[1m1065/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:32\u001b[0m 5s/step - accuracy: 0.4344 - loss: 9.1168 getitem, batch_nr 1066 train is: True\n",
      "\u001b[1m1066/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:27\u001b[0m 5s/step - accuracy: 0.4343 - loss: 9.1172 getitem, batch_nr 1067 train is: True\n",
      "\u001b[1m1067/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:21\u001b[0m 5s/step - accuracy: 0.4343 - loss: 9.1177 getitem, batch_nr 1068 train is: True\n",
      "\u001b[1m1068/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:16\u001b[0m 5s/step - accuracy: 0.4343 - loss: 9.1181 getitem, batch_nr 1069 train is: True\n",
      "\u001b[1m1069/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:11\u001b[0m 5s/step - accuracy: 0.4343 - loss: 9.1186 getitem, batch_nr 1070 train is: True\n",
      "\u001b[1m1070/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:06\u001b[0m 5s/step - accuracy: 0.4342 - loss: 9.1190 getitem, batch_nr 1071 train is: True\n",
      "\u001b[1m1071/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21:01\u001b[0m 5s/step - accuracy: 0.4342 - loss: 9.1195 getitem, batch_nr 1072 train is: True\n",
      "\u001b[1m1072/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:56\u001b[0m 5s/step - accuracy: 0.4342 - loss: 9.1200 getitem, batch_nr 1073 train is: True\n",
      "\u001b[1m1073/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:51\u001b[0m 5s/step - accuracy: 0.4341 - loss: 9.1204 getitem, batch_nr 1074 train is: True\n",
      "\u001b[1m1074/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:45\u001b[0m 5s/step - accuracy: 0.4341 - loss: 9.1209 getitem, batch_nr 1075 train is: True\n",
      "\u001b[1m1075/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:40\u001b[0m 5s/step - accuracy: 0.4341 - loss: 9.1213 getitem, batch_nr 1076 train is: True\n",
      "\u001b[1m1076/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:35\u001b[0m 5s/step - accuracy: 0.4341 - loss: 9.1218 getitem, batch_nr 1077 train is: True\n",
      "\u001b[1m1077/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:30\u001b[0m 5s/step - accuracy: 0.4340 - loss: 9.1222 getitem, batch_nr 1078 train is: True\n",
      "\u001b[1m1078/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:25\u001b[0m 5s/step - accuracy: 0.4340 - loss: 9.1227 getitem, batch_nr 1079 train is: True\n",
      "\u001b[1m1079/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:20\u001b[0m 5s/step - accuracy: 0.4340 - loss: 9.1231 getitem, batch_nr 1080 train is: True\n",
      "\u001b[1m1080/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:15\u001b[0m 5s/step - accuracy: 0.4339 - loss: 9.1235 getitem, batch_nr 1081 train is: True\n",
      "\u001b[1m1081/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:09\u001b[0m 5s/step - accuracy: 0.4339 - loss: 9.1240 getitem, batch_nr 1082 train is: True\n",
      "\u001b[1m1082/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m20:04\u001b[0m 5s/step - accuracy: 0.4339 - loss: 9.1244 getitem, batch_nr 1083 train is: True\n",
      "\u001b[1m1083/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:59\u001b[0m 5s/step - accuracy: 0.4339 - loss: 9.1249 getitem, batch_nr 1084 train is: True\n",
      "\u001b[1m1084/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:54\u001b[0m 5s/step - accuracy: 0.4338 - loss: 9.1253 getitem, batch_nr 1085 train is: True\n",
      "\u001b[1m1085/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:49\u001b[0m 5s/step - accuracy: 0.4338 - loss: 9.1258 getitem, batch_nr 1086 train is: True\n",
      "\u001b[1m1086/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:44\u001b[0m 5s/step - accuracy: 0.4338 - loss: 9.1262 getitem, batch_nr 1087 train is: True\n",
      "\u001b[1m1087/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:38\u001b[0m 5s/step - accuracy: 0.4338 - loss: 9.1266 getitem, batch_nr 1088 train is: True\n",
      "\u001b[1m1088/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:33\u001b[0m 5s/step - accuracy: 0.4337 - loss: 9.1271 getitem, batch_nr 1089 train is: True\n",
      "\u001b[1m1089/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:28\u001b[0m 5s/step - accuracy: 0.4337 - loss: 9.1275 getitem, batch_nr 1090 train is: True\n",
      "\u001b[1m1090/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:23\u001b[0m 5s/step - accuracy: 0.4337 - loss: 9.1279 getitem, batch_nr 1091 train is: True\n",
      "\u001b[1m1091/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:18\u001b[0m 5s/step - accuracy: 0.4336 - loss: 9.1284 getitem, batch_nr 1092 train is: True\n",
      "\u001b[1m1092/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:13\u001b[0m 5s/step - accuracy: 0.4336 - loss: 9.1288 getitem, batch_nr 1093 train is: True\n",
      "\u001b[1m1093/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:08\u001b[0m 5s/step - accuracy: 0.4336 - loss: 9.1292 getitem, batch_nr 1094 train is: True\n",
      "\u001b[1m1094/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19:02\u001b[0m 5s/step - accuracy: 0.4336 - loss: 9.1296 getitem, batch_nr 1095 train is: True\n",
      "\u001b[1m1095/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:57\u001b[0m 5s/step - accuracy: 0.4335 - loss: 9.1301 getitem, batch_nr 1096 train is: True\n",
      "\u001b[1m1096/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:52\u001b[0m 5s/step - accuracy: 0.4335 - loss: 9.1305 getitem, batch_nr 1097 train is: True\n",
      "\u001b[1m1097/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:47\u001b[0m 5s/step - accuracy: 0.4335 - loss: 9.1309 getitem, batch_nr 1098 train is: True\n",
      "\u001b[1m1098/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:42\u001b[0m 5s/step - accuracy: 0.4335 - loss: 9.1313 getitem, batch_nr 1099 train is: True\n",
      "\u001b[1m1099/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:37\u001b[0m 5s/step - accuracy: 0.4334 - loss: 9.1318 getitem, batch_nr 1100 train is: True\n",
      "\u001b[1m1100/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:32\u001b[0m 5s/step - accuracy: 0.4334 - loss: 9.1322 getitem, batch_nr 1101 train is: True\n",
      "\u001b[1m1101/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:26\u001b[0m 5s/step - accuracy: 0.4334 - loss: 9.1326 getitem, batch_nr 1102 train is: True\n",
      "\u001b[1m1102/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:21\u001b[0m 5s/step - accuracy: 0.4334 - loss: 9.1330 getitem, batch_nr 1103 train is: True\n",
      "\u001b[1m1103/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:16\u001b[0m 5s/step - accuracy: 0.4333 - loss: 9.1335 getitem, batch_nr 1104 train is: True\n",
      "\u001b[1m1104/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:11\u001b[0m 5s/step - accuracy: 0.4333 - loss: 9.1339 getitem, batch_nr 1105 train is: True\n",
      "\u001b[1m1105/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:06\u001b[0m 5s/step - accuracy: 0.4333 - loss: 9.1343 getitem, batch_nr 1106 train is: True\n",
      "\u001b[1m1106/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18:01\u001b[0m 5s/step - accuracy: 0.4333 - loss: 9.1347 getitem, batch_nr 1107 train is: True\n",
      "\u001b[1m1107/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:56\u001b[0m 5s/step - accuracy: 0.4332 - loss: 9.1352 getitem, batch_nr 1108 train is: True\n",
      "\u001b[1m1108/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:50\u001b[0m 5s/step - accuracy: 0.4332 - loss: 9.1356 getitem, batch_nr 1109 train is: True\n",
      "\u001b[1m1109/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:45\u001b[0m 5s/step - accuracy: 0.4332 - loss: 9.1360 getitem, batch_nr 1110 train is: True\n",
      "\u001b[1m1110/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:40\u001b[0m 5s/step - accuracy: 0.4331 - loss: 9.1364 getitem, batch_nr 1111 train is: True\n",
      "\u001b[1m1111/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:35\u001b[0m 5s/step - accuracy: 0.4331 - loss: 9.1368 getitem, batch_nr 1112 train is: True\n",
      "\u001b[1m1112/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:30\u001b[0m 5s/step - accuracy: 0.4331 - loss: 9.1373 getitem, batch_nr 1113 train is: True\n",
      "\u001b[1m1113/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:25\u001b[0m 5s/step - accuracy: 0.4331 - loss: 9.1377 getitem, batch_nr 1114 train is: True\n",
      "\u001b[1m1114/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:19\u001b[0m 5s/step - accuracy: 0.4330 - loss: 9.1381 getitem, batch_nr 1115 train is: True\n",
      "\u001b[1m1115/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:14\u001b[0m 5s/step - accuracy: 0.4330 - loss: 9.1385 getitem, batch_nr 1116 train is: True\n",
      "\u001b[1m1116/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:09\u001b[0m 5s/step - accuracy: 0.4330 - loss: 9.1389 getitem, batch_nr 1117 train is: True\n",
      "\u001b[1m1117/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m17:04\u001b[0m 5s/step - accuracy: 0.4330 - loss: 9.1393 getitem, batch_nr 1118 train is: True\n",
      "\u001b[1m1118/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m16:59\u001b[0m 5s/step - accuracy: 0.4329 - loss: 9.1398 getitem, batch_nr 1119 train is: True\n",
      "\u001b[1m1119/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:54\u001b[0m 5s/step - accuracy: 0.4329 - loss: 9.1402 getitem, batch_nr 1120 train is: True\n",
      "\u001b[1m1120/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:49\u001b[0m 5s/step - accuracy: 0.4329 - loss: 9.1406 getitem, batch_nr 1121 train is: True\n",
      "\u001b[1m1121/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:43\u001b[0m 5s/step - accuracy: 0.4329 - loss: 9.1410 getitem, batch_nr 1122 train is: True\n",
      "\u001b[1m1122/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:38\u001b[0m 5s/step - accuracy: 0.4328 - loss: 9.1414 getitem, batch_nr 1123 train is: True\n",
      "\u001b[1m1123/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:33\u001b[0m 5s/step - accuracy: 0.4328 - loss: 9.1418 getitem, batch_nr 1124 train is: True\n",
      "\u001b[1m1124/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:28\u001b[0m 5s/step - accuracy: 0.4328 - loss: 9.1422 getitem, batch_nr 1125 train is: True\n",
      "\u001b[1m1125/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:23\u001b[0m 5s/step - accuracy: 0.4328 - loss: 9.1426 getitem, batch_nr 1126 train is: True\n",
      "\u001b[1m1126/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:18\u001b[0m 5s/step - accuracy: 0.4327 - loss: 9.1430 getitem, batch_nr 1127 train is: True\n",
      "\u001b[1m1127/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:13\u001b[0m 5s/step - accuracy: 0.4327 - loss: 9.1434 getitem, batch_nr 1128 train is: True\n",
      "\u001b[1m1128/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:07\u001b[0m 5s/step - accuracy: 0.4327 - loss: 9.1438 getitem, batch_nr 1129 train is: True\n",
      "\u001b[1m1129/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16:02\u001b[0m 5s/step - accuracy: 0.4327 - loss: 9.1442 getitem, batch_nr 1130 train is: True\n",
      "\u001b[1m1130/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:57\u001b[0m 5s/step - accuracy: 0.4326 - loss: 9.1446 getitem, batch_nr 1131 train is: True\n",
      "\u001b[1m1131/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:52\u001b[0m 5s/step - accuracy: 0.4326 - loss: 9.1450 getitem, batch_nr 1132 train is: True\n",
      "\u001b[1m1132/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:47\u001b[0m 5s/step - accuracy: 0.4326 - loss: 9.1454 getitem, batch_nr 1133 train is: True\n",
      "\u001b[1m1133/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:42\u001b[0m 5s/step - accuracy: 0.4326 - loss: 9.1458 getitem, batch_nr 1134 train is: True\n",
      "\u001b[1m1134/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:37\u001b[0m 5s/step - accuracy: 0.4325 - loss: 9.1462 getitem, batch_nr 1135 train is: True\n",
      "\u001b[1m1135/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:31\u001b[0m 5s/step - accuracy: 0.4325 - loss: 9.1466 getitem, batch_nr 1136 train is: True\n",
      "\u001b[1m1136/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:26\u001b[0m 5s/step - accuracy: 0.4325 - loss: 9.1470 getitem, batch_nr 1137 train is: True\n",
      "\u001b[1m1137/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:21\u001b[0m 5s/step - accuracy: 0.4325 - loss: 9.1474 getitem, batch_nr 1138 train is: True\n",
      "\u001b[1m1138/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:16\u001b[0m 5s/step - accuracy: 0.4324 - loss: 9.1477 getitem, batch_nr 1139 train is: True\n",
      "\u001b[1m1139/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:11\u001b[0m 5s/step - accuracy: 0.4324 - loss: 9.1481 getitem, batch_nr 1140 train is: True\n",
      "\u001b[1m1140/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:06\u001b[0m 5s/step - accuracy: 0.4324 - loss: 9.1485 getitem, batch_nr 1141 train is: True\n",
      "\u001b[1m1141/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15:00\u001b[0m 5s/step - accuracy: 0.4324 - loss: 9.1489 getitem, batch_nr 1142 train is: True\n",
      "\u001b[1m1142/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:55\u001b[0m 5s/step - accuracy: 0.4323 - loss: 9.1492 getitem, batch_nr 1143 train is: True\n",
      "\u001b[1m1143/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:50\u001b[0m 5s/step - accuracy: 0.4323 - loss: 9.1496 getitem, batch_nr 1144 train is: True\n",
      "\u001b[1m1144/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:45\u001b[0m 5s/step - accuracy: 0.4323 - loss: 9.1500 getitem, batch_nr 1145 train is: True\n",
      "\u001b[1m1145/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:40\u001b[0m 5s/step - accuracy: 0.4323 - loss: 9.1504 getitem, batch_nr 1146 train is: True\n",
      "\u001b[1m1146/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:35\u001b[0m 5s/step - accuracy: 0.4323 - loss: 9.1507 getitem, batch_nr 1147 train is: True\n",
      "fill_time_length_dimension_called\n",
      "\u001b[1m1147/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:30\u001b[0m 5s/step - accuracy: 0.4322 - loss: 9.1511 getitem, batch_nr 1148 train is: True\n",
      "\u001b[1m1148/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:24\u001b[0m 5s/step - accuracy: 0.4322 - loss: 9.1515 getitem, batch_nr 1149 train is: True\n",
      "\u001b[1m1149/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:19\u001b[0m 5s/step - accuracy: 0.4322 - loss: 9.1518 getitem, batch_nr 1150 train is: True\n",
      "\u001b[1m1150/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:14\u001b[0m 5s/step - accuracy: 0.4322 - loss: 9.1522 getitem, batch_nr 1151 train is: True\n",
      "\u001b[1m1151/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:09\u001b[0m 5s/step - accuracy: 0.4321 - loss: 9.1525 getitem, batch_nr 1152 train is: True\n",
      "\u001b[1m1152/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14:04\u001b[0m 5s/step - accuracy: 0.4321 - loss: 9.1529 getitem, batch_nr 1153 train is: True\n",
      "\u001b[1m1153/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:59\u001b[0m 5s/step - accuracy: 0.4321 - loss: 9.1532 getitem, batch_nr 1154 train is: True\n",
      "\u001b[1m1154/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:54\u001b[0m 5s/step - accuracy: 0.4321 - loss: 9.1536 getitem, batch_nr 1155 train is: True\n",
      "\u001b[1m1155/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:48\u001b[0m 5s/step - accuracy: 0.4321 - loss: 9.1539 getitem, batch_nr 1156 train is: True\n",
      "\u001b[1m1156/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:43\u001b[0m 5s/step - accuracy: 0.4320 - loss: 9.1543 getitem, batch_nr 1157 train is: True\n",
      "\u001b[1m1157/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:38\u001b[0m 5s/step - accuracy: 0.4320 - loss: 9.1546 getitem, batch_nr 1158 train is: True\n",
      "\u001b[1m1158/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:33\u001b[0m 5s/step - accuracy: 0.4320 - loss: 9.1550 getitem, batch_nr 1159 train is: True\n",
      "\u001b[1m1159/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:28\u001b[0m 5s/step - accuracy: 0.4320 - loss: 9.1553 getitem, batch_nr 1160 train is: True\n",
      "\u001b[1m1160/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:23\u001b[0m 5s/step - accuracy: 0.4320 - loss: 9.1557 getitem, batch_nr 1161 train is: True\n",
      "\u001b[1m1161/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:18\u001b[0m 5s/step - accuracy: 0.4319 - loss: 9.1560 getitem, batch_nr 1162 train is: True\n",
      "\u001b[1m1162/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:12\u001b[0m 5s/step - accuracy: 0.4319 - loss: 9.1563 getitem, batch_nr 1163 train is: True\n",
      "\u001b[1m1163/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:07\u001b[0m 5s/step - accuracy: 0.4319 - loss: 9.1567 getitem, batch_nr 1164 train is: True\n",
      "\u001b[1m1164/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13:02\u001b[0m 5s/step - accuracy: 0.4319 - loss: 9.1570 getitem, batch_nr 1165 train is: True\n",
      "\u001b[1m1165/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:57\u001b[0m 5s/step - accuracy: 0.4318 - loss: 9.1574 getitem, batch_nr 1166 train is: True\n",
      "\u001b[1m1166/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:52\u001b[0m 5s/step - accuracy: 0.4318 - loss: 9.1577 getitem, batch_nr 1167 train is: True\n",
      "\u001b[1m1167/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:47\u001b[0m 5s/step - accuracy: 0.4318 - loss: 9.1580 getitem, batch_nr 1168 train is: True\n",
      "\u001b[1m1168/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:42\u001b[0m 5s/step - accuracy: 0.4318 - loss: 9.1584 getitem, batch_nr 1169 train is: True\n",
      "\u001b[1m1169/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:36\u001b[0m 5s/step - accuracy: 0.4318 - loss: 9.1587 getitem, batch_nr 1170 train is: True\n",
      "\u001b[1m1170/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:31\u001b[0m 5s/step - accuracy: 0.4317 - loss: 9.1590 getitem, batch_nr 1171 train is: True\n",
      "\u001b[1m1171/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:26\u001b[0m 5s/step - accuracy: 0.4317 - loss: 9.1594 getitem, batch_nr 1172 train is: True\n",
      "\u001b[1m1172/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:21\u001b[0m 5s/step - accuracy: 0.4317 - loss: 9.1597 getitem, batch_nr 1173 train is: True\n",
      "\u001b[1m1173/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:16\u001b[0m 5s/step - accuracy: 0.4317 - loss: 9.1600 getitem, batch_nr 1174 train is: True\n",
      "\u001b[1m1174/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:11\u001b[0m 5s/step - accuracy: 0.4317 - loss: 9.1604 getitem, batch_nr 1175 train is: True\n",
      "\u001b[1m1175/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:06\u001b[0m 5s/step - accuracy: 0.4316 - loss: 9.1607 getitem, batch_nr 1176 train is: True\n",
      "\u001b[1m1176/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:00\u001b[0m 5s/step - accuracy: 0.4316 - loss: 9.1610 getitem, batch_nr 1177 train is: True\n",
      "\u001b[1m1177/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:55\u001b[0m 5s/step - accuracy: 0.4316 - loss: 9.1614 getitem, batch_nr 1178 train is: True\n",
      "\u001b[1m1178/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:50\u001b[0m 5s/step - accuracy: 0.4316 - loss: 9.1617 getitem, batch_nr 1179 train is: True\n",
      "\u001b[1m1179/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:45\u001b[0m 5s/step - accuracy: 0.4316 - loss: 9.1620 getitem, batch_nr 1180 train is: True\n",
      "\u001b[1m1180/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:40\u001b[0m 5s/step - accuracy: 0.4315 - loss: 9.1624 getitem, batch_nr 1181 train is: True\n",
      "\u001b[1m1181/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:35\u001b[0m 5s/step - accuracy: 0.4315 - loss: 9.1627 getitem, batch_nr 1182 train is: True\n",
      "\u001b[1m1182/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:29\u001b[0m 5s/step - accuracy: 0.4315 - loss: 9.1630 getitem, batch_nr 1183 train is: True\n",
      "\u001b[1m1183/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:24\u001b[0m 5s/step - accuracy: 0.4315 - loss: 9.1633 getitem, batch_nr 1184 train is: True\n",
      "\u001b[1m1184/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m11:19\u001b[0m 5s/step - accuracy: 0.4315 - loss: 9.1637 getitem, batch_nr 1185 train is: True\n",
      "\u001b[1m1185/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:14\u001b[0m 5s/step - accuracy: 0.4314 - loss: 9.1640 getitem, batch_nr 1186 train is: True\n",
      "\u001b[1m1186/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:09\u001b[0m 5s/step - accuracy: 0.4314 - loss: 9.1643 getitem, batch_nr 1187 train is: True\n",
      "\u001b[1m1187/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:04\u001b[0m 5s/step - accuracy: 0.4314 - loss: 9.1646 getitem, batch_nr 1188 train is: True\n",
      "\u001b[1m1188/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:59\u001b[0m 5s/step - accuracy: 0.4314 - loss: 9.1650 getitem, batch_nr 1189 train is: True\n",
      "\u001b[1m1189/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:53\u001b[0m 5s/step - accuracy: 0.4314 - loss: 9.1653 getitem, batch_nr 1190 train is: True\n",
      "\u001b[1m1190/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:48\u001b[0m 5s/step - accuracy: 0.4313 - loss: 9.1656 getitem, batch_nr 1191 train is: True\n",
      "\u001b[1m1191/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:43\u001b[0m 5s/step - accuracy: 0.4313 - loss: 9.1659 getitem, batch_nr 1192 train is: True\n",
      "\u001b[1m1192/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:38\u001b[0m 5s/step - accuracy: 0.4313 - loss: 9.1662 getitem, batch_nr 1193 train is: True\n",
      "\u001b[1m1193/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:33\u001b[0m 5s/step - accuracy: 0.4313 - loss: 9.1666 getitem, batch_nr 1194 train is: True\n",
      "\u001b[1m1194/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:28\u001b[0m 5s/step - accuracy: 0.4313 - loss: 9.1669 getitem, batch_nr 1195 train is: True\n",
      "\u001b[1m1195/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:23\u001b[0m 5s/step - accuracy: 0.4312 - loss: 9.1672 getitem, batch_nr 1196 train is: True\n",
      "\u001b[1m1196/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:17\u001b[0m 5s/step - accuracy: 0.4312 - loss: 9.1675 getitem, batch_nr 1197 train is: True\n",
      "\u001b[1m1197/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:12\u001b[0m 5s/step - accuracy: 0.4312 - loss: 9.1679 getitem, batch_nr 1198 train is: True\n",
      "\u001b[1m1198/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:07\u001b[0m 5s/step - accuracy: 0.4312 - loss: 9.1682 getitem, batch_nr 1199 train is: True\n",
      "\u001b[1m1199/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10:02\u001b[0m 5s/step - accuracy: 0.4312 - loss: 9.1685 getitem, batch_nr 1200 train is: True\n",
      "\u001b[1m1200/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:57\u001b[0m 5s/step - accuracy: 0.4311 - loss: 9.1688  getitem, batch_nr 1201 train is: True\n",
      "\u001b[1m1201/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:52\u001b[0m 5s/step - accuracy: 0.4311 - loss: 9.1691 getitem, batch_nr 1202 train is: True\n",
      "\u001b[1m1202/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:47\u001b[0m 5s/step - accuracy: 0.4311 - loss: 9.1695 getitem, batch_nr 1203 train is: True\n",
      "\u001b[1m1203/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:41\u001b[0m 5s/step - accuracy: 0.4311 - loss: 9.1698 getitem, batch_nr 1204 train is: True\n",
      "\u001b[1m1204/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:36\u001b[0m 5s/step - accuracy: 0.4311 - loss: 9.1701 getitem, batch_nr 1205 train is: True\n",
      "\u001b[1m1205/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:31\u001b[0m 5s/step - accuracy: 0.4310 - loss: 9.1704 getitem, batch_nr 1206 train is: True\n",
      "\u001b[1m1206/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:26\u001b[0m 5s/step - accuracy: 0.4310 - loss: 9.1707 getitem, batch_nr 1207 train is: True\n",
      "\u001b[1m1207/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:21\u001b[0m 5s/step - accuracy: 0.4310 - loss: 9.1710 getitem, batch_nr 1208 train is: True\n",
      "\u001b[1m1208/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:16\u001b[0m 5s/step - accuracy: 0.4310 - loss: 9.1713 getitem, batch_nr 1209 train is: True\n",
      "\u001b[1m1209/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:11\u001b[0m 5s/step - accuracy: 0.4310 - loss: 9.1717 getitem, batch_nr 1210 train is: True\n",
      "\u001b[1m1210/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:05\u001b[0m 5s/step - accuracy: 0.4309 - loss: 9.1720 getitem, batch_nr 1211 train is: True\n",
      "\u001b[1m1211/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:00\u001b[0m 5s/step - accuracy: 0.4309 - loss: 9.1723 getitem, batch_nr 1212 train is: True\n",
      "\u001b[1m1212/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:55\u001b[0m 5s/step - accuracy: 0.4309 - loss: 9.1726 getitem, batch_nr 1213 train is: True\n",
      "\u001b[1m1213/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:50\u001b[0m 5s/step - accuracy: 0.4309 - loss: 9.1729 getitem, batch_nr 1214 train is: True\n",
      "\u001b[1m1214/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:45\u001b[0m 5s/step - accuracy: 0.4309 - loss: 9.1732 getitem, batch_nr 1215 train is: True\n",
      "\u001b[1m1215/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:40\u001b[0m 5s/step - accuracy: 0.4308 - loss: 9.1735 getitem, batch_nr 1216 train is: True\n",
      "\u001b[1m1216/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:35\u001b[0m 5s/step - accuracy: 0.4308 - loss: 9.1738 getitem, batch_nr 1217 train is: True\n",
      "\u001b[1m1217/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:29\u001b[0m 5s/step - accuracy: 0.4308 - loss: 9.1741 getitem, batch_nr 1218 train is: True\n",
      "\u001b[1m1218/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:24\u001b[0m 5s/step - accuracy: 0.4308 - loss: 9.1744 getitem, batch_nr 1219 train is: True\n",
      "\u001b[1m1219/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:19\u001b[0m 5s/step - accuracy: 0.4308 - loss: 9.1748 getitem, batch_nr 1220 train is: True\n",
      "\u001b[1m1220/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:14\u001b[0m 5s/step - accuracy: 0.4307 - loss: 9.1751 getitem, batch_nr 1221 train is: True\n",
      "\u001b[1m1221/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:09\u001b[0m 5s/step - accuracy: 0.4307 - loss: 9.1754 getitem, batch_nr 1222 train is: True\n",
      "\u001b[1m1222/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8:04\u001b[0m 5s/step - accuracy: 0.4307 - loss: 9.1757 getitem, batch_nr 1223 train is: True\n",
      "\u001b[1m1223/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:58\u001b[0m 5s/step - accuracy: 0.4307 - loss: 9.1760 getitem, batch_nr 1224 train is: True\n",
      "\u001b[1m1224/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:53\u001b[0m 5s/step - accuracy: 0.4307 - loss: 9.1763 getitem, batch_nr 1225 train is: True\n",
      "\u001b[1m1225/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:48\u001b[0m 5s/step - accuracy: 0.4307 - loss: 9.1766 getitem, batch_nr 1226 train is: True\n",
      "\u001b[1m1226/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:43\u001b[0m 5s/step - accuracy: 0.4306 - loss: 9.1769 getitem, batch_nr 1227 train is: True\n",
      "\u001b[1m1227/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:38\u001b[0m 5s/step - accuracy: 0.4306 - loss: 9.1772 getitem, batch_nr 1228 train is: True\n",
      "\u001b[1m1228/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:33\u001b[0m 5s/step - accuracy: 0.4306 - loss: 9.1775 getitem, batch_nr 1229 train is: True\n",
      "\u001b[1m1229/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:28\u001b[0m 5s/step - accuracy: 0.4306 - loss: 9.1778 getitem, batch_nr 1230 train is: True\n",
      "\u001b[1m1230/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:22\u001b[0m 5s/step - accuracy: 0.4306 - loss: 9.1781 getitem, batch_nr 1231 train is: True\n",
      "\u001b[1m1231/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:17\u001b[0m 5s/step - accuracy: 0.4305 - loss: 9.1784 getitem, batch_nr 1232 train is: True\n",
      "\u001b[1m1232/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:12\u001b[0m 5s/step - accuracy: 0.4305 - loss: 9.1787 getitem, batch_nr 1233 train is: True\n",
      "\u001b[1m1233/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:07\u001b[0m 5s/step - accuracy: 0.4305 - loss: 9.1790 getitem, batch_nr 1234 train is: True\n",
      "\u001b[1m1234/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7:02\u001b[0m 5s/step - accuracy: 0.4305 - loss: 9.1793 getitem, batch_nr 1235 train is: True\n",
      "\u001b[1m1235/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:57\u001b[0m 5s/step - accuracy: 0.4305 - loss: 9.1796 getitem, batch_nr 1236 train is: True\n",
      "\u001b[1m1236/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:52\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1799 getitem, batch_nr 1237 train is: True\n",
      "\u001b[1m1237/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:46\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1802 getitem, batch_nr 1238 train is: True\n",
      "\u001b[1m1238/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:41\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1805 getitem, batch_nr 1239 train is: True\n",
      "\u001b[1m1239/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:36\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1808 getitem, batch_nr 1240 train is: True\n",
      "\u001b[1m1240/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:31\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1811 getitem, batch_nr 1241 train is: True\n",
      "\u001b[1m1241/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:26\u001b[0m 5s/step - accuracy: 0.4304 - loss: 9.1814 getitem, batch_nr 1242 train is: True\n",
      "\u001b[1m1242/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:21\u001b[0m 5s/step - accuracy: 0.4303 - loss: 9.1817 getitem, batch_nr 1243 train is: True\n",
      "\u001b[1m1243/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:15\u001b[0m 5s/step - accuracy: 0.4303 - loss: 9.1820 getitem, batch_nr 1244 train is: True\n",
      "\u001b[1m1244/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:10\u001b[0m 5s/step - accuracy: 0.4303 - loss: 9.1823 getitem, batch_nr 1245 train is: True\n",
      "\u001b[1m1245/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:05\u001b[0m 5s/step - accuracy: 0.4303 - loss: 9.1826 getitem, batch_nr 1246 train is: True\n",
      "\u001b[1m1246/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6:00\u001b[0m 5s/step - accuracy: 0.4303 - loss: 9.1829 getitem, batch_nr 1247 train is: True\n",
      "\u001b[1m1247/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:55\u001b[0m 5s/step - accuracy: 0.4302 - loss: 9.1832 getitem, batch_nr 1248 train is: True\n",
      "\u001b[1m1248/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:50\u001b[0m 5s/step - accuracy: 0.4302 - loss: 9.1835 getitem, batch_nr 1249 train is: True\n",
      "\u001b[1m1249/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:45\u001b[0m 5s/step - accuracy: 0.4302 - loss: 9.1838 getitem, batch_nr 1250 train is: True\n",
      "\u001b[1m1250/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5:39\u001b[0m 5s/step - accuracy: 0.4302 - loss: 9.1841 getitem, batch_nr 1251 train is: True\n",
      "\u001b[1m1251/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:34\u001b[0m 5s/step - accuracy: 0.4302 - loss: 9.1843 getitem, batch_nr 1252 train is: True\n",
      "\u001b[1m1252/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:29\u001b[0m 5s/step - accuracy: 0.4302 - loss: 9.1846 getitem, batch_nr 1253 train is: True\n",
      "\u001b[1m1253/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:24\u001b[0m 5s/step - accuracy: 0.4301 - loss: 9.1849 getitem, batch_nr 1254 train is: True\n",
      "\u001b[1m1254/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:19\u001b[0m 5s/step - accuracy: 0.4301 - loss: 9.1852 getitem, batch_nr 1255 train is: True\n",
      "\u001b[1m1255/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:14\u001b[0m 5s/step - accuracy: 0.4301 - loss: 9.1855 getitem, batch_nr 1256 train is: True\n",
      "\u001b[1m1256/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:09\u001b[0m 5s/step - accuracy: 0.4301 - loss: 9.1858 getitem, batch_nr 1257 train is: True\n",
      "\u001b[1m1257/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:03\u001b[0m 5s/step - accuracy: 0.4301 - loss: 9.1861 getitem, batch_nr 1258 train is: True\n",
      "\u001b[1m1258/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:58\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1864 getitem, batch_nr 1259 train is: True\n",
      "\u001b[1m1259/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:53\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1867 getitem, batch_nr 1260 train is: True\n",
      "\u001b[1m1260/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:48\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1869 getitem, batch_nr 1261 train is: True\n",
      "\u001b[1m1261/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:43\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1872 getitem, batch_nr 1262 train is: True\n",
      "\u001b[1m1262/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:38\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1875 getitem, batch_nr 1263 train is: True\n",
      "\u001b[1m1263/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:32\u001b[0m 5s/step - accuracy: 0.4300 - loss: 9.1878 getitem, batch_nr 1264 train is: True\n",
      "\u001b[1m1264/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:27\u001b[0m 5s/step - accuracy: 0.4299 - loss: 9.1881 getitem, batch_nr 1265 train is: True\n",
      "\u001b[1m1265/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:22\u001b[0m 5s/step - accuracy: 0.4299 - loss: 9.1883 getitem, batch_nr 1266 train is: True\n",
      "\u001b[1m1266/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:17\u001b[0m 5s/step - accuracy: 0.4299 - loss: 9.1886 getitem, batch_nr 1267 train is: True\n",
      "\u001b[1m1267/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:12\u001b[0m 5s/step - accuracy: 0.4299 - loss: 9.1889 getitem, batch_nr 1268 train is: True\n",
      "\u001b[1m1268/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:07\u001b[0m 5s/step - accuracy: 0.4299 - loss: 9.1892 getitem, batch_nr 1269 train is: True\n",
      "\u001b[1m1269/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4:02\u001b[0m 5s/step - accuracy: 0.4299 - loss: 9.1895 getitem, batch_nr 1270 train is: True\n",
      "\u001b[1m1270/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:56\u001b[0m 5s/step - accuracy: 0.4298 - loss: 9.1898 getitem, batch_nr 1271 train is: True\n",
      "\u001b[1m1271/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:51\u001b[0m 5s/step - accuracy: 0.4298 - loss: 9.1900 getitem, batch_nr 1272 train is: True\n",
      "\u001b[1m1272/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:46\u001b[0m 5s/step - accuracy: 0.4298 - loss: 9.1903 getitem, batch_nr 1273 train is: True\n",
      "\u001b[1m1273/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:41\u001b[0m 5s/step - accuracy: 0.4298 - loss: 9.1906 getitem, batch_nr 1274 train is: True\n",
      "\u001b[1m1274/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:36\u001b[0m 5s/step - accuracy: 0.4298 - loss: 9.1909 getitem, batch_nr 1275 train is: True\n",
      "\u001b[1m1275/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:31\u001b[0m 5s/step - accuracy: 0.4297 - loss: 9.1911 getitem, batch_nr 1276 train is: True\n",
      "\u001b[1m1276/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:26\u001b[0m 5s/step - accuracy: 0.4297 - loss: 9.1914 getitem, batch_nr 1277 train is: True\n",
      "\u001b[1m1277/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:20\u001b[0m 5s/step - accuracy: 0.4297 - loss: 9.1917 getitem, batch_nr 1278 train is: True\n",
      "\u001b[1m1278/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:15\u001b[0m 5s/step - accuracy: 0.4297 - loss: 9.1920 getitem, batch_nr 1279 train is: True\n",
      "\u001b[1m1279/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:10\u001b[0m 5s/step - accuracy: 0.4297 - loss: 9.1922 getitem, batch_nr 1280 train is: True\n",
      "\u001b[1m1280/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:05\u001b[0m 5s/step - accuracy: 0.4297 - loss: 9.1925 getitem, batch_nr 1281 train is: True\n",
      "\u001b[1m1281/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:00\u001b[0m 5s/step - accuracy: 0.4296 - loss: 9.1928 getitem, batch_nr 1282 train is: True\n",
      "\u001b[1m1282/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:55\u001b[0m 5s/step - accuracy: 0.4296 - loss: 9.1931 getitem, batch_nr 1283 train is: True\n",
      "\u001b[1m1283/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:49\u001b[0m 5s/step - accuracy: 0.4296 - loss: 9.1933 getitem, batch_nr 1284 train is: True\n",
      "\u001b[1m1284/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:44\u001b[0m 5s/step - accuracy: 0.4296 - loss: 9.1936 getitem, batch_nr 1285 train is: True\n",
      "\u001b[1m1285/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:39\u001b[0m 5s/step - accuracy: 0.4296 - loss: 9.1939 getitem, batch_nr 1286 train is: True\n",
      "\u001b[1m1286/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:34\u001b[0m 5s/step - accuracy: 0.4296 - loss: 9.1942 getitem, batch_nr 1287 train is: True\n",
      "\u001b[1m1287/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:29\u001b[0m 5s/step - accuracy: 0.4295 - loss: 9.1944 getitem, batch_nr 1288 train is: True\n",
      "\u001b[1m1288/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:24\u001b[0m 5s/step - accuracy: 0.4295 - loss: 9.1947 getitem, batch_nr 1289 train is: True\n",
      "\u001b[1m1289/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:19\u001b[0m 5s/step - accuracy: 0.4295 - loss: 9.1950 getitem, batch_nr 1290 train is: True\n",
      "\u001b[1m1290/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:13\u001b[0m 5s/step - accuracy: 0.4295 - loss: 9.1953 getitem, batch_nr 1291 train is: True\n",
      "\u001b[1m1291/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:08\u001b[0m 5s/step - accuracy: 0.4295 - loss: 9.1955 getitem, batch_nr 1292 train is: True\n",
      "\u001b[1m1292/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:03\u001b[0m 5s/step - accuracy: 0.4295 - loss: 9.1958 getitem, batch_nr 1293 train is: True\n",
      "\u001b[1m1293/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:58\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1961 getitem, batch_nr 1294 train is: True\n",
      "\u001b[1m1294/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:53\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1964 getitem, batch_nr 1295 train is: True\n",
      "\u001b[1m1295/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:48\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1966 getitem, batch_nr 1296 train is: True\n",
      "\u001b[1m1296/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:43\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1969 getitem, batch_nr 1297 train is: True\n",
      "\u001b[1m1297/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:37\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1972 getitem, batch_nr 1298 train is: True\n",
      "\u001b[1m1298/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:32\u001b[0m 5s/step - accuracy: 0.4294 - loss: 9.1974 getitem, batch_nr 1299 train is: True\n",
      "\u001b[1m1299/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:27\u001b[0m 5s/step - accuracy: 0.4293 - loss: 9.1977 getitem, batch_nr 1300 train is: True\n",
      "\u001b[1m1300/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:22\u001b[0m 5s/step - accuracy: 0.4293 - loss: 9.1980 getitem, batch_nr 1301 train is: True\n",
      "\u001b[1m1301/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:17\u001b[0m 5s/step - accuracy: 0.4293 - loss: 9.1982 getitem, batch_nr 1302 train is: True\n",
      "\u001b[1m1302/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:12\u001b[0m 5s/step - accuracy: 0.4293 - loss: 9.1985 getitem, batch_nr 1303 train is: True\n",
      "\u001b[1m1303/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:06\u001b[0m 5s/step - accuracy: 0.4293 - loss: 9.1987 getitem, batch_nr 1304 train is: True\n",
      "\u001b[1m1304/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:01\u001b[0m 5s/step - accuracy: 0.4293 - loss: 9.1990 getitem, batch_nr 1305 train is: True\n",
      "\u001b[1m1305/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m56s\u001b[0m 5s/step - accuracy: 0.4292 - loss: 9.1993  getitem, batch_nr 1306 train is: True\n",
      "\u001b[1m1306/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m51s\u001b[0m 5s/step - accuracy: 0.4292 - loss: 9.1995 getitem, batch_nr 1307 train is: True\n",
      "\u001b[1m1307/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.4292 - loss: 9.1998 getitem, batch_nr 1308 train is: True\n",
      "\u001b[1m1308/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m41s\u001b[0m 5s/step - accuracy: 0.4292 - loss: 9.2000 getitem, batch_nr 1309 train is: True\n",
      "\u001b[1m1309/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.4292 - loss: 9.2003 getitem, batch_nr 1310 train is: True\n",
      "\u001b[1m1310/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m30s\u001b[0m 5s/step - accuracy: 0.4292 - loss: 9.2005 getitem, batch_nr 1311 train is: True\n",
      "\u001b[1m1311/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.4291 - loss: 9.2008 getitem, batch_nr 1312 train is: True\n",
      "\u001b[1m1312/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m20s\u001b[0m 5s/step - accuracy: 0.4291 - loss: 9.2010 getitem, batch_nr 1313 train is: True\n",
      "\u001b[1m1313/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 5s/step - accuracy: 0.4291 - loss: 9.2013 getitem, batch_nr 1314 train is: True\n",
      "\u001b[1m1314/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 5s/step - accuracy: 0.4291 - loss: 9.2015 getitem, batch_nr 1315 train is: True\n",
      "fill_time_length_dimension_called\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4291 - loss: 9.2020on_epoch_end_called\n",
      "   videoID  batches_in_video  random_order  total_batches\n",
      "0        1                92             1             92\n",
      "1        6               112             2            204\n",
      "2        2               180             3            384\n",
      "3        3               186             4            570\n",
      "4        4               260             5            830\n",
      "5        7               168             6            998\n",
      "6        5               318             7           1316\n",
      "len called len is: 214\n",
      "len called len is: 214\n",
      " getitem, batch_nr 0 train is: False\n",
      " getitem, batch_nr 1 train is: False\n",
      " getitem, batch_nr 2 train is: False\n",
      " getitem, batch_nr 3 train is: False\n",
      " getitem, batch_nr 4 train is: False\n",
      " getitem, batch_nr 5 train is: False\n",
      " getitem, batch_nr 6 train is: False\n",
      " getitem, batch_nr 7 train is: False\n",
      " getitem, batch_nr 8 train is: False\n",
      " getitem, batch_nr 9 train is: False\n",
      " getitem, batch_nr 10 train is: False\n",
      " getitem, batch_nr 11 train is: False\n",
      " getitem, batch_nr 12 train is: False\n",
      " getitem, batch_nr 13 train is: False\n",
      " getitem, batch_nr 14 train is: False\n",
      " getitem, batch_nr 15 train is: False\n",
      " getitem, batch_nr 16 train is: False\n",
      " getitem, batch_nr 17 train is: False\n",
      " getitem, batch_nr 18 train is: False\n",
      " getitem, batch_nr 19 train is: False\n",
      " getitem, batch_nr 20 train is: False\n",
      " getitem, batch_nr 21 train is: False\n",
      " getitem, batch_nr 22 train is: False\n",
      " getitem, batch_nr 23 train is: False\n",
      " getitem, batch_nr 24 train is: False\n",
      " getitem, batch_nr 25 train is: False\n",
      " getitem, batch_nr 26 train is: False\n",
      " getitem, batch_nr 27 train is: False\n",
      " getitem, batch_nr 28 train is: False\n",
      " getitem, batch_nr 29 train is: False\n",
      " getitem, batch_nr 30 train is: False\n",
      " getitem, batch_nr 31 train is: False\n",
      " getitem, batch_nr 32 train is: False\n",
      " getitem, batch_nr 33 train is: False\n",
      " getitem, batch_nr 34 train is: False\n",
      " getitem, batch_nr 35 train is: False\n",
      " getitem, batch_nr 36 train is: False\n",
      " getitem, batch_nr 37 train is: False\n",
      " getitem, batch_nr 38 train is: False\n",
      " getitem, batch_nr 39 train is: False\n",
      " getitem, batch_nr 40 train is: False\n",
      " getitem, batch_nr 41 train is: False\n",
      " getitem, batch_nr 42 train is: False\n",
      " getitem, batch_nr 43 train is: False\n",
      " getitem, batch_nr 44 train is: False\n",
      " getitem, batch_nr 45 train is: False\n",
      " getitem, batch_nr 46 train is: False\n",
      " getitem, batch_nr 47 train is: False\n",
      " getitem, batch_nr 48 train is: False\n",
      " getitem, batch_nr 49 train is: False\n",
      " getitem, batch_nr 50 train is: False\n",
      " getitem, batch_nr 51 train is: False\n",
      " getitem, batch_nr 52 train is: False\n",
      " getitem, batch_nr 53 train is: False\n",
      " getitem, batch_nr 54 train is: False\n",
      " getitem, batch_nr 55 train is: False\n",
      " getitem, batch_nr 56 train is: False\n",
      " getitem, batch_nr 57 train is: False\n",
      " getitem, batch_nr 58 train is: False\n",
      " getitem, batch_nr 59 train is: False\n",
      " getitem, batch_nr 60 train is: False\n",
      " getitem, batch_nr 61 train is: False\n",
      " getitem, batch_nr 62 train is: False\n",
      " getitem, batch_nr 63 train is: False\n",
      " getitem, batch_nr 64 train is: False\n",
      " getitem, batch_nr 65 train is: False\n",
      " getitem, batch_nr 66 train is: False\n",
      " getitem, batch_nr 67 train is: False\n",
      " getitem, batch_nr 68 train is: False\n",
      " getitem, batch_nr 69 train is: False\n",
      " getitem, batch_nr 70 train is: False\n",
      " getitem, batch_nr 71 train is: False\n",
      " getitem, batch_nr 72 train is: False\n",
      " getitem, batch_nr 73 train is: False\n",
      " getitem, batch_nr 74 train is: False\n",
      " getitem, batch_nr 75 train is: False\n",
      " getitem, batch_nr 76 train is: False\n",
      " getitem, batch_nr 77 train is: False\n",
      " getitem, batch_nr 78 train is: False\n",
      " getitem, batch_nr 79 train is: False\n",
      " getitem, batch_nr 80 train is: False\n",
      " getitem, batch_nr 81 train is: False\n",
      " getitem, batch_nr 82 train is: False\n",
      " getitem, batch_nr 83 train is: False\n",
      " getitem, batch_nr 84 train is: False\n",
      " getitem, batch_nr 85 train is: False\n",
      " getitem, batch_nr 86 train is: False\n",
      "fill_time_length_dimension_called\n",
      " getitem, batch_nr 87 train is: False\n",
      " getitem, batch_nr 88 train is: False\n",
      " getitem, batch_nr 89 train is: False\n",
      " getitem, batch_nr 90 train is: False\n",
      " getitem, batch_nr 91 train is: False\n",
      " getitem, batch_nr 92 train is: False\n",
      " getitem, batch_nr 93 train is: False\n",
      " getitem, batch_nr 94 train is: False\n",
      " getitem, batch_nr 95 train is: False\n",
      " getitem, batch_nr 96 train is: False\n",
      " getitem, batch_nr 97 train is: False\n",
      " getitem, batch_nr 98 train is: False\n",
      " getitem, batch_nr 99 train is: False\n",
      " getitem, batch_nr 100 train is: False\n",
      " getitem, batch_nr 101 train is: False\n",
      " getitem, batch_nr 102 train is: False\n",
      " getitem, batch_nr 103 train is: False\n",
      " getitem, batch_nr 104 train is: False\n",
      " getitem, batch_nr 105 train is: False\n",
      " getitem, batch_nr 106 train is: False\n",
      " getitem, batch_nr 107 train is: False\n",
      " getitem, batch_nr 108 train is: False\n",
      " getitem, batch_nr 109 train is: False\n",
      " getitem, batch_nr 110 train is: False\n",
      " getitem, batch_nr 111 train is: False\n",
      " getitem, batch_nr 112 train is: False\n",
      " getitem, batch_nr 113 train is: False\n",
      " getitem, batch_nr 114 train is: False\n",
      " getitem, batch_nr 115 train is: False\n",
      " getitem, batch_nr 116 train is: False\n",
      " getitem, batch_nr 117 train is: False\n",
      " getitem, batch_nr 118 train is: False\n",
      " getitem, batch_nr 119 train is: False\n",
      " getitem, batch_nr 120 train is: False\n",
      " getitem, batch_nr 121 train is: False\n",
      " getitem, batch_nr 122 train is: False\n",
      " getitem, batch_nr 123 train is: False\n",
      " getitem, batch_nr 124 train is: False\n",
      " getitem, batch_nr 125 train is: False\n",
      " getitem, batch_nr 126 train is: False\n",
      " getitem, batch_nr 127 train is: False\n",
      " getitem, batch_nr 128 train is: False\n",
      " getitem, batch_nr 129 train is: False\n",
      " getitem, batch_nr 130 train is: False\n",
      " getitem, batch_nr 131 train is: False\n",
      " getitem, batch_nr 132 train is: False\n",
      " getitem, batch_nr 133 train is: False\n",
      " getitem, batch_nr 134 train is: False\n",
      " getitem, batch_nr 135 train is: False\n",
      " getitem, batch_nr 136 train is: False\n",
      " getitem, batch_nr 137 train is: False\n",
      " getitem, batch_nr 138 train is: False\n",
      " getitem, batch_nr 139 train is: False\n",
      " getitem, batch_nr 140 train is: False\n",
      " getitem, batch_nr 141 train is: False\n",
      " getitem, batch_nr 142 train is: False\n",
      " getitem, batch_nr 143 train is: False\n",
      " getitem, batch_nr 144 train is: False\n",
      " getitem, batch_nr 145 train is: False\n",
      " getitem, batch_nr 146 train is: False\n",
      " getitem, batch_nr 147 train is: False\n",
      " getitem, batch_nr 148 train is: False\n",
      " getitem, batch_nr 149 train is: False\n",
      " getitem, batch_nr 150 train is: False\n",
      " getitem, batch_nr 151 train is: False\n",
      " getitem, batch_nr 152 train is: False\n",
      " getitem, batch_nr 153 train is: False\n",
      " getitem, batch_nr 154 train is: False\n",
      " getitem, batch_nr 155 train is: False\n",
      " getitem, batch_nr 156 train is: False\n",
      " getitem, batch_nr 157 train is: False\n",
      " getitem, batch_nr 158 train is: False\n",
      " getitem, batch_nr 159 train is: False\n",
      " getitem, batch_nr 160 train is: False\n",
      " getitem, batch_nr 161 train is: False\n",
      " getitem, batch_nr 162 train is: False\n",
      " getitem, batch_nr 163 train is: False\n",
      " getitem, batch_nr 164 train is: False\n",
      " getitem, batch_nr 165 train is: False\n",
      " getitem, batch_nr 166 train is: False\n",
      " getitem, batch_nr 167 train is: False\n",
      " getitem, batch_nr 168 train is: False\n",
      " getitem, batch_nr 169 train is: False\n",
      " getitem, batch_nr 170 train is: False\n",
      " getitem, batch_nr 171 train is: False\n",
      " getitem, batch_nr 172 train is: False\n",
      " getitem, batch_nr 173 train is: False\n",
      " getitem, batch_nr 174 train is: False\n",
      " getitem, batch_nr 175 train is: False\n",
      " getitem, batch_nr 176 train is: False\n",
      " getitem, batch_nr 177 train is: False\n",
      " getitem, batch_nr 178 train is: False\n",
      " getitem, batch_nr 179 train is: False\n",
      " getitem, batch_nr 180 train is: False\n",
      " getitem, batch_nr 181 train is: False\n",
      " getitem, batch_nr 182 train is: False\n",
      " getitem, batch_nr 183 train is: False\n",
      " getitem, batch_nr 184 train is: False\n",
      " getitem, batch_nr 185 train is: False\n",
      " getitem, batch_nr 186 train is: False\n",
      " getitem, batch_nr 187 train is: False\n",
      " getitem, batch_nr 188 train is: False\n",
      " getitem, batch_nr 189 train is: False\n",
      " getitem, batch_nr 190 train is: False\n",
      " getitem, batch_nr 191 train is: False\n",
      " getitem, batch_nr 192 train is: False\n",
      " getitem, batch_nr 193 train is: False\n",
      " getitem, batch_nr 194 train is: False\n",
      " getitem, batch_nr 195 train is: False\n",
      " getitem, batch_nr 196 train is: False\n",
      " getitem, batch_nr 197 train is: False\n",
      " getitem, batch_nr 198 train is: False\n",
      " getitem, batch_nr 199 train is: False\n",
      " getitem, batch_nr 200 train is: False\n",
      " getitem, batch_nr 201 train is: False\n",
      " getitem, batch_nr 202 train is: False\n",
      " getitem, batch_nr 203 train is: False\n",
      " getitem, batch_nr 204 train is: False\n",
      " getitem, batch_nr 205 train is: False\n",
      " getitem, batch_nr 206 train is: False\n",
      " getitem, batch_nr 207 train is: False\n",
      " getitem, batch_nr 208 train is: False\n",
      " getitem, batch_nr 209 train is: False\n",
      " getitem, batch_nr 210 train is: False\n",
      " getitem, batch_nr 211 train is: False\n",
      " getitem, batch_nr 212 train is: False\n",
      " getitem, batch_nr 213 train is: False\n",
      "fill_time_length_dimension_called\n",
      "on_epoch_end_called\n",
      "   videoID  batches_in_video  random_order  total_batches\n",
      "0        9                87             1             87\n",
      "1        8               127             2            214\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7030s\u001b[0m 5s/step - accuracy: 0.4291 - loss: 9.2022 - val_accuracy: 0.4095 - val_loss: 9.5184\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_generator, epochs=2, \n",
    "                    validation_data=test_generator, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03e31c-ac8b-40fd-8699-b89181898d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed6bf2c-67fc-4771-adac-b7417ef9a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.440445</td>\n",
       "      <td>9.018946</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>9.199925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.409195</td>\n",
       "      <td>9.522095</td>\n",
       "      <td>0.409463</td>\n",
       "      <td>9.518359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss\n",
       "0  0.440445  9.018946      0.428738  9.199925\n",
       "1  0.409195  9.522095      0.409463  9.518359"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d245812-bff8-4a35-a716-34652fa466c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (dataset iterations).\n",
       "\n",
       "Args:\n",
       "    x: Input data. It could be:\n",
       "        - A NumPy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "        - A tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "        - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "        - A `tf.data.Dataset`. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "        - A `keras.utils.PyDataset` returning `(inputs,\n",
       "        targets)` or `(inputs, targets, sample_weights)`.\n",
       "    y: Target data. Like the input data `x`,\n",
       "        it could be either NumPy array(s) or backend-native tensor(s).\n",
       "        If `x` is a dataset, generator,\n",
       "        or `keras.utils.PyDataset` instance, `y` should\n",
       "        not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.PyDataset`\n",
       "        instances (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided\n",
       "        (unless the `steps_per_epoch` flag is set to\n",
       "        something other than None).\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        \"auto\" becomes 1 for most cases.\n",
       "        Note that the progress bar is not\n",
       "        particularly useful when logged to a file,\n",
       "        so `verbose=2` is recommended when not running interactively\n",
       "        (e.g., in a production environment). Defaults to `\"auto\"`.\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `keras.callbacks`. Note\n",
       "        `keras.callbacks.ProgbarLogger` and\n",
       "        `keras.callbacks.History` callbacks are created\n",
       "        automatically and need not be passed to `model.fit()`.\n",
       "        `keras.callbacks.ProgbarLogger` is created\n",
       "        or not based on the `verbose` argument in `model.fit()`.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This\n",
       "        argument is not supported when `x` is a dataset, generator or\n",
       "        `keras.utils.PyDataset` instance.\n",
       "        If both `validation_data` and `validation_split` are provided,\n",
       "        `validation_data` will override `validation_split`.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data. Thus, note the fact\n",
       "        that the validation loss of data provided using\n",
       "        `validation_split` or `validation_data` is not affected by\n",
       "        regularization layers like noise and dropout.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        It could be:\n",
       "        - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
       "        - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
       "        arrays.\n",
       "        - A `tf.data.Dataset`.\n",
       "        - A Python generator or `keras.utils.PyDataset` returning\n",
       "        `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
       "    shuffle: Boolean, whether to shuffle the training data\n",
       "        before each epoch. This argument is\n",
       "        ignored when `x` is a generator or a `tf.data.Dataset`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class. When `class_weight` is specified\n",
       "        and targets have a rank of 2 or greater, either `y` must be\n",
       "        one-hot encoded, or an explicit final dimension of `1` must\n",
       "        be included for sparse class labels.\n",
       "    sample_weight: Optional NumPy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        NumPy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample.\n",
       "        This argument is not supported when `x` is a dataset, generator,\n",
       "        or `keras.utils.PyDataset` instance, instead provide the\n",
       "        sample_weights as the third element of `x`.\n",
       "        Note that sample weighting does not apply to metrics specified\n",
       "        via the `metrics` argument in `compile()`. To apply sample\n",
       "        weighting to your metrics, you can specify them via the\n",
       "        `weighted_metrics` in `compile()` instead.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        backend-native tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If `x` is a\n",
       "        `tf.data.Dataset`, and `steps_per_epoch`\n",
       "        is `None`, the epoch will run until the input dataset is\n",
       "        exhausted.  When passing an infinitely repeating dataset, you\n",
       "        must specify the `steps_per_epoch` argument. If\n",
       "        `steps_per_epoch=-1` the training will run indefinitely with an\n",
       "        infinitely repeating dataset.\n",
       "    validation_steps: Only relevant if `validation_data` is provided.\n",
       "        Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If `validation_steps` is `None`,\n",
       "        validation will run until the `validation_data` dataset is\n",
       "        exhausted. In the case of an infinitely repeated dataset, it\n",
       "        will run into an infinite loop. If `validation_steps` is\n",
       "        specified and only part of the dataset will be consumed, the\n",
       "        evaluation will start from the beginning of the dataset at each\n",
       "        epoch. This ensures that the same validation samples are used\n",
       "        every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in\n",
       "        the form of datasets or `keras.utils.PyDataset`\n",
       "        instances (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided.\n",
       "        Specifies how many training epochs to run\n",
       "        before a new validation run is performed,\n",
       "        e.g. `validation_freq=2` runs validation every 2 epochs.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass an iterator like object such as a\n",
       "    `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
       "    which will in fact yield not only features (`x`)\n",
       "    but optionally targets (`y`) and sample weights (`sample_weight`).\n",
       "    Keras requires that the output of such iterator-likes be\n",
       "    unambiguous. The iterator should return a tuple\n",
       "    of length 1, 2, or 3, where the optional second and third elements\n",
       "    will be used for `y` and `sample_weight` respectively.\n",
       "    Any other type provided will be wrapped in\n",
       "    a length-one tuple, effectively treating everything as `x`. When\n",
       "    yielding dicts, they should still adhere to the top-level tuple\n",
       "    structure,\n",
       "    e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "    features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the `namedtuple`. The reason is\n",
       "    that it behaves like both an ordered datatype (tuple) and a mapping\n",
       "    datatype (dict). So given a namedtuple of the form:\n",
       "    `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "    it is ambiguous whether to reverse the order of the elements when\n",
       "    interpreting the value. Even worse is a tuple of the form:\n",
       "    `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "    where it is unclear if the tuple was intended to be unpacked\n",
       "    into `x`, `y`, and `sample_weight` or passed through\n",
       "    as a single element to `x`.\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0ddc2ea-006d-4501-a865-8cb56fc42deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/frames_skillborder_convLSTM_model_history.pkl', 'wb') as handle:\n",
    "    pickle.dump(history, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c2c39-50de-43df-a00f-5a445c0b5dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb492dab-1b49-42e4-a133-83e2842292b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b31e26-f5fb-4ad4-aabd-fdbf27d415ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c77033-2026-4cdf-8ffd-d92bf3561a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
