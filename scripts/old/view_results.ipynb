{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd7bfd70-7da4-451f-af7b-f21a08441e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_misc import pickle_load_or_create\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "15a49da3-8c05-4331-b1f9-ae2f45dfaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle_load_or_create('../models/last_cnn_model_history', lambda: {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f28a991-d178-4db0-97c7-7e51ad0c3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>1.322263</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>1.270124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.487847</td>\n",
       "      <td>1.267614</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>1.265558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.482639</td>\n",
       "      <td>1.236608</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>1.267687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482639</td>\n",
       "      <td>1.190585</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>1.251327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.489583</td>\n",
       "      <td>1.157687</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.191321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.505208</td>\n",
       "      <td>1.124633</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.147607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.534722</td>\n",
       "      <td>1.053638</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>1.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.983012</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>1.020759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.923050</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.922151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.618056</td>\n",
       "      <td>0.863846</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.893664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss\n",
       "0  0.468750  1.322263      0.506944  1.270124\n",
       "1  0.487847  1.267614      0.513889  1.265558\n",
       "2  0.482639  1.236608      0.513889  1.267687\n",
       "3  0.482639  1.190585      0.493056  1.251327\n",
       "4  0.489583  1.157687      0.541667  1.191321\n",
       "5  0.505208  1.124633      0.541667  1.147607\n",
       "6  0.534722  1.053638      0.569444  1.086957\n",
       "7  0.598958  0.983012      0.638889  1.020759\n",
       "8  0.614583  0.923050      0.680556  0.922151\n",
       "9  0.618056  0.863846      0.631944  0.893664"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba143115-227c-46ab-bd70-9a53d5fa5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGeneratorFrames import DataGeneratorSkillBorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aff171bc-9308-42ab-9cac-3cac6b9f1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_frame(videonames, videofolder):\n",
    "    \"\"\"\n",
    "    videos: array of video_paths\n",
    "    df_video_border_labels: panda dataframe ['path', 'frame', 'borderlabel']\n",
    "        [ 0 : ground\n",
    "          1 : heels of ground\n",
    "          2 : air ]\n",
    "    \"\"\"\n",
    "    vid_id = np.random.randint(0, len(videonames)-1)\n",
    "    vid_name = videonames[vid_id]\n",
    "    path = videofolder + vid_name\n",
    "    print(path)\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frame_nr = np.random.randint(0, video_length-1)\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_nr)\n",
    "    res, frame = cap.read()\n",
    "    cap.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    return vid_name, frame_nr, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "907f17fd-58a5-436e-b6e8-b87ca97a774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../videos/20240209_atelier_009.mp4\n"
     ]
    }
   ],
   "source": [
    "path, frame_nr, frame = get_random_frame(['20240209_atelier_009.mp4', '20240209_atelier_009.mp4'], '../videos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "176d8fd6-772e-4034-a3ae-8c7a4f9eded9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20240209_atelier_009.mp4', 39)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, frame_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d93145bc-7fa4-4de7-bcc1-61070e17afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame(frame, scale=0.4):\n",
    "    \"\"\"\n",
    "    Displays a single frame using OpenCV, waits for a key press, \n",
    "    and then closes the frame window.\n",
    "\n",
    "    Args:\n",
    "        frame (numpy.ndarray): The image frame to display.\n",
    "\n",
    "    Returns:\n",
    "        int: The ASCII value of the key pressed.\n",
    "    \"\"\"\n",
    "    if scale != 1.0:\n",
    "        frame = cv2.resize(frame, dsize=(0,0), fx=scale, fy=scale)\n",
    "    # Display the frame using OpenCV\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Wait for a key press\n",
    "    key = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "025d1bf7-e596-4076-bd68-5c97da300603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_frame(frame, scale=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8badffd-9bc6-43ad-a54d-4926924bc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame(path, frame_nr, dx, dy):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_nr)\n",
    "    res, frame = cap.read()\n",
    "    if not res:\n",
    "        raise ValueError(f\"Failed to read frame {frame_nr} from {path}\")\n",
    "    frame = cv2.resize(frame, (dx, dy))\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Uncomment if necessary\n",
    "    cap.release()\n",
    "    return frame / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "864ace1a-7b52-441e-8db6-43c920955738",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame64 = load_frame('../videos/20240209_atelier_009.mp4', frame_nr, 64, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "789fd279-2c65-4d62-94fa-46e706fbfcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame64.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "06e21546-3091-4a11-a3c6-8edcf71f6155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = np.expand_dims(frame64, axis=0)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09c1633d-9046-4c42-a024-b64bd475de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x71fc202da680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04, 0.  , 0.03, 0.  , 0.93]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# Example prediction\n",
    "logits = history.model.predict(tensor)\n",
    "\n",
    "# Convert to probabilities\n",
    "probabilities = softmax(logits)\n",
    "np.round(probabilities, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e9b53-bcba-4420-aab1-7b5f294532de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
