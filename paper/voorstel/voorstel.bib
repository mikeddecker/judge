% Encoding: UTF-8

@BOOK{Moore2002,
  title = {Introduction to the Practice of Statistics},
  publisher = {W. H. Freeman},
  year = {2002},
  author = {Moore, David and McCabe, George},
  owner = {jbuy519},
  timestamp = {2014.01.28}
}

@Online{LewisFowler2014,
  author    = {Lewis, James and Fowler, Martin},
  title     = {Microservices: a definition of this new architectural term},
  date      = {2014-03-25},
  url       = {http://martinfowler.com/articles/microservices.html},
  urldate   = {2016-09-01},
}

@Online{Hykes2013,
  author    = {Solomon Hykes},
  title     = {The future of Linux Containers (PyCon 2013)},
  date      = {2013-03-21},
  url       = {https://www.youtube.com/watch?v=wW9CAH9nSLs},
  urldate   = {2016-09-01},
}

@Article{JOBANPUTRA2019698,
  author   = {Charmi Jobanputra and Jatna Bavishi and Nishant Doshi},
  title    = {Human Activity Recognition: A Survey},
  journal  = {Procedia Computer Science},
  year     = {2019},
  volume   = {155},
  pages    = {698-703},
  note     = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
  issn     = {1877-0509},
  doi      = {https://doi.org/10.1016/j.procs.2019.08.100},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877050919310166},
  abstract = {Human Activity Recognition (HAR) has been a challenging problem yet it needs to be solved. It will mainly be used for eldercare and healthcare as an assistive technology when ensemble with other technologies like Internet of Things(IoT). HAR can be done with the help of sensors, smartphones or images. In this paper, we present various state-of-the-art methods and describe each of them by literature survey. Different datasets are used for each of the methods wherein the data are collected by different means such as sensors, images, accelerometer, gyroscopes, etc. and the placement of these devices at various locations. The results obtained by each technique and the type of dataset are then compared. Machine learning techniques like decision trees, K-nearest neighbours, support vector machines, hidden markov models are reviewed for HAR and later the survey for deep neural network techniques like artificial neural networks, convolutional neural networks and recurrent neural networks is also presented.},
  keywords = {Human Activity Recognition, Machine learning, Neural networks},
}

@Article{Singh_Gill_2022,
  author    = {Singh Gill, Harmandeep and Ibrahim Khalaf, Osamah and Alotaibi, Youseef and Alghamdi, Saleh and Alassery, Fawaz},
  title     = {Fruit Image Classification Using Deep Learning},
  journal   = {Computers, Materials \&amp; Continua},
  year      = {2022},
  date      = {2022-03-31},
  volume    = {71},
  number    = {3},
  pages     = {5135--5150},
  issn      = {1546-2226},
  doi       = {10.32604/cmc.2022.022809},
  publisher = {Computers, Materials and Continua (Tech Science Press)},
}

@Article{Ramirez_2022,
  author    = {Ramirez, Heilym and Velastin, Sergio A. and Aguayo, Paulo and Fabregas, Ernesto and Farias, Gonzalo},
  title     = {Human Activity Recognition by Sequences of Skeleton Features},
  journal   = {Sensors},
  year      = {2022},
  volume    = {22},
  number    = {11},
  month     = may,
  pages     = {3991},
  issn      = {1424-8220},
  doi       = {10.3390/s22113991},
  publisher = {MDPI AG},
}

@Article{Fujii_2021,
  author    = {Fujii, Keisuke},
  title     = {Data-Driven Analysis for Understanding Team Sports Behaviors},
  journal   = {Journal of Robotics and Mechatronics},
  year      = {2021},
  volume    = {33},
  number    = {3},
  month     = jun,
  pages     = {505--514},
  issn      = {0915-3942},
  doi       = {10.20965/jrm.2021.p0505},
  publisher = {Fuji Technology Press Ltd.},
}

@Article{Ullah_2024,
  author    = {Ullah, Shan and Pirahandeh, Mehdi and Kim, Deok-Hwan},
  title     = {Self-attention deep ConvLSTM with sparse-learned channel dependencies for wearable sensor-based human activity recognition},
  journal   = {Neurocomputing},
  year      = {2024},
  volume    = {571},
  month     = feb,
  pages     = {127157},
  issn      = {0925-2312},
  doi       = {https://doi.org/10.1016/j.neucom.2023.127157},
  publisher = {Elsevier BV},
}

@Article{Xia_2020,
  author    = {Xia, Kun and Huang, Jianguang and Wang, Hanyu},
  title     = {LSTM-CNN Architecture for Human Activity Recognition},
  journal   = {IEEE Access},
  year      = {2020},
  volume    = {8},
  pages     = {56855--56866},
  issn      = {2169-3536},
  doi       = {10.1109/ACCESS.2020.2982225},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{Bharadiya_2023,
  author    = {Bharadiya, Jasmin Praful},
  title     = {Convolutional Neural Networks for Image Classification},
  journal   = {International Journal of Innovative Science and Research Technology},
  year      = {2023},
  issn      = {ISSN No.: 2456-2165},
  doi       = {10.5281/zenodo.7952031},
  copyright = {Creative Commons Attribution 4.0 International},
  publisher = {Zenodo},
}

@Article{Sherstinsky_2020,
  author    = {Sherstinsky, Alex},
  title     = {Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network},
  journal   = {Physica D: Nonlinear Phenomena},
  year      = {2020},
  volume    = {404},
  month     = mar,
  pages     = {132306},
  issn      = {0167-2789},
  doi       = {https://doi.org/10.1016/j.physd.2019.132306},
  publisher = {Elsevier BV},
}

@Article{LUQMAN_2022,
  author    = {Luqman, Hamzah and Elalfy, Elsayed},
  title     = {Utilizing motion and spatial features for sign language gesture recognition using cascaded CNN and LSTM models},
  journal   = {Turkish Journal of Electrical Engineering and Computer Sciences},
  year      = {2022},
  volume    = {30},
  number    = {7},
  month     = nov,
  pages     = {2508--2525},
  issn      = {1300-0632},
  doi       = {10.55730/1300-0632.3952},
  publisher = {The Scientific and Technological Research Council of Turkey (TUBITAK-ULAKBIM) - DIGITAL COMMONS JOURNALS},
}

@Article{Sun_2023,
  author    = {Sun, Penghui and Wang, Jiajia and Dong, Zhilin},
  title     = {CNN–LSTM Neural Network for Identification of Pre-Cooked Pasta Products in Different Physical States Using Infrared Spectroscopy},
  journal   = {Sensors},
  year      = {2023},
  volume    = {23},
  number    = {10},
  month     = may,
  pages     = {4815},
  issn      = {1424-8220},
  doi       = {https://doi.org/10.3390/s23104815},
  publisher = {MDPI AG},
}

@Article{Aksan_2023,
  author    = {Aksan, Fachrizal and Li, Yang and Suresh, Vishnu and Janik, Przemysław},
  title     = {CNN-LSTM vs. LSTM-CNN to Predict Power Flow Direction: A Case Study of the High-Voltage Subnet of Northeast Germany},
  journal   = {Sensors},
  year      = {2023},
  volume    = {23},
  number    = {2},
  month     = jan,
  pages     = {901},
  issn      = {1424-8220},
  doi       = {https://doi.org/10.3390/s23020901},
  publisher = {MDPI AG},
}

@Article{Pareek_2020,
  author    = {Pareek, Preksha and Thakkar, Ankit},
  title     = {A survey on video-based Human Action Recognition: recent updates, datasets, challenges, and applications},
  journal   = {Artificial Intelligence Review},
  year      = {2020},
  volume    = {54},
  number    = {3},
  month     = sep,
  pages     = {2259--2322},
  issn      = {1573-7462},
  doi       = {https://doi.org/10.1007/s10462-020-09904-8},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Sharma_2023,
  author    = {Sharma, Abhilasha and Singh, Roshni},
  title     = {ConvST-LSTM-Net: convolutional spatiotemporal LSTM networks for skeleton-based human action recognition},
  journal   = {International Journal of Multimedia Information Retrieval},
  year      = {2023},
  volume    = {12},
  number    = {2},
  month     = oct,
  issn      = {2192-662X},
  doi       = {10.1007/s13735-023-00301-9},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Ellouze_2024,
  author    = {Ellouze, Ameni and Kadri, Nesrine and Alaerjan, Alaa and Ksantini, Mohamed},
  title     = {Combined CNN-LSTM Deep Learning Algorithms for Recognizing Human Physical Activities in Large and Distributed Manners: A Recommendation System},
  journal   = {Computers, Materials \&amp; Continua},
  year      = {2024},
  volume    = {79},
  number    = {1},
  pages     = {351--372},
  issn      = {1546-2226},
  doi       = {10.32604/cmc.2024.048061},
  publisher = {Tech Science Press},
}

@Misc{Zaidi_2021,
  author    = {Zaidi, Syed Sahil Abbas and Ansari, Mohammad Samar and Aslam, Asra and Kanwal, Nadia and Asghar, Mamoona and Lee, Brian},
  title     = {A Survey of Modern Deep Learning based Object Detection Models},
  year      = {2021},
  doi       = {10.48550/ARXIV.2104.11892},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
}

@Article{Gao_2022,
  author    = {Gao, Mingqi and Zheng, Feng and Yu, James J. Q. and Shan, Caifeng and Ding, Guiguang and Han, Jungong},
  title     = {Deep learning for video object segmentation: a review},
  journal   = {Artificial Intelligence Review},
  year      = {2022},
  volume    = {56},
  number    = {1},
  month     = apr,
  pages     = {457--531},
  issn      = {1573-7462},
  doi       = {10.1007/s10462-022-10176-7},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Issa_2023,
  author    = {Issa, Obada and Shanableh, Tamer},
  title     = {Video-Based Recognition of Human Activity Using Novel Feature Extraction Techniques},
  journal   = {Applied Sciences},
  year      = {2023},
  volume    = {13},
  number    = {11},
  month     = jun,
  pages     = {6856},
  issn      = {2076-3417},
  doi       = {10.3390/app13116856},
  publisher = {MDPI AG},
}

@Article{Alharthi_2019,
  author    = {Alharthi, Abdullah S. and Yunas, Syed U. and Ozanyan, Krikor B.},
  title     = {Deep Learning for Monitoring of Human Gait: A Review},
  journal   = {IEEE Sensors Journal},
  year      = {2019},
  volume    = {19},
  number    = {21},
  month     = nov,
  pages     = {9575--9591},
  issn      = {2379-9153},
  doi       = {10.1109/JSEN.2019.2928777},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{Song_2021,
  author    = {Song, Liangchen and Yu, Gang and Yuan, Junsong and Liu, Zicheng},
  title     = {Human pose estimation and its application to action recognition: A survey},
  journal   = {Journal of Visual Communication and Image Representation},
  year      = {2021},
  volume    = {76},
  month     = apr,
  pages     = {103055},
  issn      = {1047-3203},
  doi       = {10.1016/j.jvcir.2021.103055},
  publisher = {Elsevier BV},
}

@Article{Lin_2020,
  author    = {Lin, Zhihui and Li, Maomao and Zheng, Zhuobin and Cheng, Yangyang and Yuan, Chun},
  title     = {Self-Attention ConvLSTM for Spatiotemporal Prediction},
  journal   = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2020},
  volume    = {34},
  number    = {07},
  month     = apr,
  pages     = {11531--11538},
  issn      = {2159-5399},
  doi       = {10.1609/aaai.v34i07.6819},
  publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
}

@Article{Wang_2019,
  author    = {Wang, Yunbo and Zhang, Jianjin and Zhu, Hongyu and Long, Mingsheng and Wang, Jianmin and Yu, Philip S.},
  title     = {Memory in Memory: A Predictive Neural Network for Learning Higher-Order Non-Stationarity From Spatiotemporal Dynamics},
  year      = {2019},
  month     = jun,
  doi       = {10.1109/CVPR.2019.00937},
  booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
}

@Article{Zahan_2023,
  author    = {Zahan, Sania and Hassan, Ghulam Mubashar and Mian, Ajmal},
  title     = {Learning Sparse Temporal Video Mapping for Action Quality Assessment in Floor Gymnastics},
  year      = {2023},
  doi       = {10.48550/ARXIV.2301.06103},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Luo_2014,
  author    = {Luo, Wenhan and Xing, Junliang and Milan, Anton and Zhang, Xiaoqin and Liu, Wei and Kim, Tae-Kyun},
  title     = {Multiple Object Tracking: A Literature Review},
  year      = {2014},
  doi       = {10.48550/ARXIV.1409.7618},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences, I.4.8},
  publisher = {arXiv},
}

@Article{Coulibaly_2022,
  author    = {Coulibaly, Solemane and Kamsu-Foguem, Bernard and Kamissoko, Dantouma and Traore, Daouda},
  title     = {Deep Convolution Neural Network sharing for the multi-label images classification},
  journal   = {Machine Learning with Applications},
  year      = {2022},
  volume    = {10},
  month     = dec,
  pages     = {100422},
  issn      = {2666-8270},
  doi       = {10.1016/j.mlwa.2022.100422},
  publisher = {Elsevier BV},
}

@Article{Yin_2024,
  author    = {Yin, Hongwei and Sinnott, Richard O. and Jayaputera, Glenn T.},
  title     = {A survey of video-based human action recognition in team sports},
  journal   = {Artificial Intelligence Review},
  year      = {2024},
  volume    = {57},
  number    = {11},
  month     = sep,
  issn      = {1573-7462},
  doi       = {10.1007/s10462-024-10934-9},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Zou_2023,
  author    = {Zou Zhengxia and Chen Keyan and Shi Zhenwei and Guo Yuhong and Ye Jieping},
  title     = {Object Detection in 20 Years: A Survey},
  year      = {2019},
  doi       = {https://doi.org/10.48550/arXiv.1905.05055},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Cheng_2023,
  author    = {Cheng, Ho Kei and Oh, Seoung Wug and Price, Brian and Lee, Joon-Young and Schwing, Alexander},
  title     = {Putting the Object Back into Video Object Segmentation},
  year      = {2023},
  doi       = {https://doi.org/10.48550/arXiv.2310.12982},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Guler_2018,
  author    = {Güler, Rıza Alp and Neverova, Natalia and Kokkinos, Iasonas},
  title     = {DensePose: Dense Human Pose Estimation In The Wild},
  year      = {2018},
  doi       = {https://doi.org/10.48550/arXiv.1802.00434},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Jiaming_2023,
  author    = {Zhou, Jiaming and Li, Hanjun and Lin, Kun-Yu and Liang, Junwei},
  title     = {Towards Weakly Supervised End-to-end Learning for Long-video Action Recognition},
  year      = {2023},
  doi       = {https://doi.org/10.48550/arXiv.2311.17118},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Yang_2023,
  author    = {Yang, Min and Gao, Huan and Guo, Ping and Wang, Limin},
  title     = {Adapting Short-Term Transformers for Action Detection in Untrimmed Videos},
  year      = {2023},
  doi       = {https://doi.org/10.48550/arXiv.2312.01897},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Wang_2023,
  author    = {Wang, Limin and Huang, Bingkun and Zhao, Zhiyu and Tong, Zhan and He, Yinan and Wang, Yi and Wang, Yali and Qiao, Yu},
  title     = {VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking},
  year      = {2023},
  doi       = {https://doi.org/10.48550/arXiv.2303.16727},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Liu_2021,
  author    = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  title     = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  year      = {2021},
  doi       = {https://doi.org/10.48550/arXiv.2103.14030},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Wang_2021,
  author    = {Wang, Haochen and Jiang, Xiaolong and Ren, Haibing and Hu, Yao and Bai, Song},
  title     = {SwiftNet: Real-time Video Object Segmentation},
  year      = {2021},
  doi       = {https://doi.org/10.48550/arXiv.2102.04604},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Shi_2015,
  author    = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
  title     = {Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting},
  year      = {2015},
  doi       = {https://doi.org/10.48550/arXiv.1506.04214},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Qi_2020,
  author    = {Qi, Mengshi and Wang, Yunhong and Qin, Jie and Li, Annan and Luo, Jiebo and Van Gool, Luc},
  title     = {stagNet: An Attentive Semantic RNN for Group Activity and Individual Action Recognition},
  journal   = {IEEE Transactions on Circuits and Systems for Video Technology},
  year      = {2020},
  volume    = {30},
  number    = {2},
  month     = feb,
  pages     = {549--565},
  issn      = {1558-2205},
  doi       = {https://doi.org/DOI10.1109/TCSVT.2019.2894161},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Online{www_speed_30s_1999_WORLD,
  author  = {Laue, R.},
  title   = {Rope Skipping Records from all over the world.},
  year    = {1999},
  url     = {https://eherber.home.xs4all.nl/ropeskip/recordsm.htm},
  urldate = {2024-12-09},
}

@Online{www_speed_30s_2024_IJRU_WORLD,
  author  = {IJRU},
  title   = {World Records},
  year    = {2024},
  url     = {https://ijru.sport/world-records},
  urldate = {2024-12-09},
}

@Online{www_speed_30s_2024_BE,
  author  = {Gymfed},
  title   = {Offiële Records Rope Skipping},
  year    = {2017},
  url     = {https://www.gymfed.be/nieuws/officiele-records-rope-skipping},
  note    = {File updated in 2024},
  urldate = {2024-12-09},
}

@Online{IJRU_yt_2023_livestream_day1,
  author       = {IJRU},
  title        = {LIVE | World Jump Rope Championships 2023 | Day 1},
  year         = {2023},
  url          = {https://www.youtube.com/watch?v=EqczXTJliyc},
  organization = {International Jump Rope Union},
  urldate      = {2024-12-18},
}

@Online{IJRU_yt_2023_livestream_day8,
  author       = {IJRU},
  title        = {LIVE | World Jump Rope Championships 2023 | Day 8},
  year         = {2023},
  url          = {https://www.youtube.com/watch?v=PnHdv-a4yWA},
  organization = {International Jump Rope Union},
  urldate      = {2024-12-18},
}

@Article{Kay2017,
  author    = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and Suleyman, Mustafa and Zisserman, Andrew},
  title     = {The Kinetics Human Action Video Dataset},
  doi       = {https://doi.org/10.48550/arXiv.1705.06950},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  year      = {2017},
}

@Article{Bora_2023,
  author    = {Bora, Jyotishman and Dehingia, Saine and Boruah, Abhijit and Chetia, Anuraag Anuj and Gogoi, Dikhit},
  title     = {Real-time Assamese Sign Language Recognition using MediaPipe and Deep Learning},
  journal   = {Procedia Computer Science},
  year      = {2023},
  volume    = {218},
  pages     = {1384--1393},
  issn      = {1877-0509},
  doi       = {https://doi.org/10.1016/j.procs.2023.01.117},
  publisher = {Elsevier BV},
}

@Article{Diwaker_2022,
  author    = {Diwakar and Raj, Deepa},
  title     = {Recent Object Detection Techniques: A Survey},
  journal   = {International Journal of Image, Graphics and Signal Processing},
  year      = {2022},
  volume    = {14},
  number    = {2},
  month     = apr,
  pages     = {47--60},
  issn      = {2074-9082},
  doi       = {10.5815/ijigsp.2022.02.05},
  publisher = {MECS Publisher},
}

@InProceedings{MobileNetv4_2024,
  author    = {Qin, Danfeng and Leichner, Chas and Delakis, Manolis and Fornoni, Marco and Luo, Shixin and Yang, Fan and Wang, Weijun and Banbury, Colby and Ye, Chengxi and Akin, Berkin and Aggarwal, Vaibhav and Zhu, Tenghui and Moro, Daniele and Howard, Andrew},
  title     = {MobileNetV4: Universal Models for the Mobile Ecosystem},
  booktitle = {Computer Vision -- ECCV 2024},
  year      = {2024},
  editor    = {Leonardis, Ale{\v{s}} and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, G{\"u}l},
  publisher = {Springer Nature Switzerland},
  isbn      = {978-3-031-73661-2},
  pages     = {78--96},
  doi       = {https://doi.org/10.48550/arXiv.2404.10518},
  abstract  = {We present the latest generation of MobileNets: MobileNetV4 (MNv4). They feature universally-efficient architecture designs for mobile devices. We introduce the Universal Inverted Bottleneck (UIB) search block, a unified and flexible structure that merges Inverted Bottleneck (IB), ConvNext, Feed Forward Network (FFN), and a novel Extra Depthwise (ExtraDW) variant. Alongside UIB, we present Mobile MQA, an attention block for mobile accelerators, delivering a significant 39{\%} speedup. An optimized neural architecture search (NAS) recipe is also introduced which improves MNv4 search effectiveness. The integration of UIB, Mobile MQA and the refined NAS recipe results in a new suite of MNv4 models that are mostly Pareto optimal across mobile CPUs, DSPs, GPUs, as well as accelerators like Apple Neural Engine and Google Pixel EdgeTPU. This performance uniformity is not found in any other models tested. We introduce performance modeling and analysis techniques to explain how this performance is achieved. Finally, to further boost accuracy, we introduce a novel distillation technique. Enhanced by this technique, our MNv4-Hybrid-Large model delivers 87{\%} ImageNet-1K accuracy, with a Pixel 8 EdgeTPU runtime of 3.8 ms.},
  address   = {Cham},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
}

@Online{www_speed_30s_2024_USA_AMJRF,
  author  = {IJRU},
  title   = {American Records},
  year    = {2024},
  url     = {https://www.amjrf.com/page/show/8542453-us-national-records},
  urldate = {2024-12-20},
}

@Misc{Guo_2017,
  author    = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
  title     = {On Calibration of Modern Neural Networks},
  year      = {2017},
  doi       = {10.48550/ARXIV.1706.04599},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Thomas_2017,
  author    = {Thomas, Graham and Gade, Rikke and Moeslund, Thomas B. and Carr, Peter and Hilton, Adrian},
  title     = {Computer vision for sports: Current applications and research topics},
  journal   = {Computer Vision and Image Understanding},
  year      = {2017},
  volume    = {159},
  month     = jun,
  pages     = {3--18},
  issn      = {1077-3142},
  doi       = {10.1016/j.cviu.2017.04.011},
  publisher = {Elsevier BV},
}

@InBook{Soomro_2014,
  author    = {Soomro, Khurram and Zamir, Amir R.},
  title     = {Action Recognition in Realistic Sports Videos},
  booktitle = {Computer Vision in Sports},
  year      = {2014},
  publisher = {Springer International Publishing},
  isbn      = {9783319093963},
  pages     = {181--208},
  doi       = {10.1007/978-3-319-09396-3_9},
  issn      = {2191-6594},
}

@Article{Abdullah_2023,
  author  = {Abdullah, Ahmed Saadi and Alsaif, Khalil I},
  title   = {Still Rings Movements Recognition in Gymnastics Sport Based on Deep Learning},
  journal = {Wasit Journal for Pure sciences},
  year    = {2023},
  volume  = {2},
  number  = {1},
  pages   = {207--216},
}

@Comment{jabref-meta: databaseType:biblatex;}
